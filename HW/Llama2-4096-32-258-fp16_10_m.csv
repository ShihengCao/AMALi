Kernel Name,HW,Column_1,Column_2,Column_3,Column_4,Column_5,Column_6,Column_7,Column_8,Column_9,Column_10,Average,kernel id,similar_kernel_ids
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, detail::Array<char *, 2>>(int, T2, T3)",4461,4163,4339,4350,4232,4337,4366,4228,4218,4260,4150,4264.3,1,1
"void native::<unnamed>::indexSelectLargeIndex<c10::Half, long, unsigned int, 2, 2, (int)-2, 1>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<T1, T3>, cuda::TensorInfo<T2, T3>, int, int, T3, T3, long)",23485,23409,23862,24096,23640,23828,23511,23442,23373,23321,23925,23640.7,2,2
"void native::triu_tril_kernel<c10::Half, int, 1>(cuda::TensorInfo<T1, T2>, cuda::TensorInfo<T1, T2>, long, long)",5215,5868,5888,5858,5907,5999,6121,5822,6197,5816,5812,5928.8,3,3
"void native::<unnamed>::CatArrayBatchedCopy<c10::Half, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",5062,5347,5611,5605,5424,5591,5385,5398,5393,5411,5334,5449.9,4,4
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14876,16379,17398,16892,16578,16943,16595,16417,16995,16354,16938,16748.9,5,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11730,15862,15298,15095,15037,14658,15235,15258,15450,14962,15286,15214.1,6,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23960,25349,25340,25055,25146,25056,24986,24898,25481,25333,25239,25188.3,7,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3292,3995,4159,4164,4023,4177,4000,4043,3942,4022,3997,4052.2,8,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3454,4014,4215,4250,4058,4201,4153,4060,4196,4051,4011,4120.9,9,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13728,17893,17647,17585,17587,18195,17376,17447,17589,17694,17648,17666.1,10,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14195,16068,16473,16082,16242,15987,16281,16761,16419,15984,16008,16230.5,11,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12682,14068,14119,13820,14172,14183,14945,14397,14119,13955,14002,14178.0,12,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282373,282309,282112,282921,283864,282032,283503,284749,282030,283789,283340,283064.9,13,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282387,281859,282513,283244,283391,282540,282469,282722,282345,281726,283198,282600.7,14,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281810,283199,282783,282719,282440,282131,282377,284127,282508,283232,282102,282761.8,15,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14915,16274,17066,17554,16784,17159,16656,17132,17017,16587,16697,16892.6,16,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14508,16218,16957,17465,16452,17034,16527,16513,16351,16342,17073,16693.2,17,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13002,17603,17378,17885,17530,18026,17613,17689,17809,17978,17726,17723.7,18,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12559,17882,17694,17895,17483,18102,17574,17907,17645,17954,17615,17775.1,19,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14183,15705,16166,16214,15873,16160,16055,15907,15790,15901,15783,15955.4,20,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14142,15892,16339,16494,16281,16531,15888,16002,16156,15858,16166,16160.7,21,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29542,30215,30428,30328,30418,30309,30351,30415,30657,30194,30359,30367.4,22,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11476,14760,15308,14593,14904,15129,15028,14469,15092,14922,14530,14873.5,23,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",20855,21699,21725,21782,21605,22022,21722,21856,21804,21700,21732,21764.7,24,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25359,27629,28063,28167,27539,28039,27217,27560,27617,27593,27251,27667.5,25,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26255,29740,30032,30161,30673,29310,31218,30690,30320,30804,30901,30384.9,26,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23431,26032,26618,26427,25853,26370,25900,25865,26021,26072,26201,26135.9,27,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,27135,28553,28248,28768,28474,28317,28683,28612,28704,28570,28632,28556.1,28,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12591,13529,13731,13716,13893,13598,13465,13418,13685,13509,13411,13595.5,29,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282570,282414,282410,282821,281394,285181,282774,283821,283323,284038,282429,283060.5,30,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10105,12147,12009,11826,11799,11657,11565,11935,11652,11720,12719,11902.9,31,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14896,17314,17514,17851,16780,17620,16813,16920,17199,16928,16950,17188.9,32,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11354,14332,15152,15371,14791,15016,14629,14317,15124,15536,14452,14872.0,33,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24217,25019,25870,25576,25153,25597,25095,25087,25228,24953,25063,25264.1,34,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3347,3948,4607,4603,4061,4642,3951,3999,4017,4003,3973,4180.4,35,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3437,4025,4709,4869,4059,4738,4148,4088,4180,4094,4009,4291.9,36,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14231,18344,19119,18636,18272,18853,17826,18612,17492,17907,18380,18344.1,37,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14225,16365,16495,16341,15947,16586,15865,16257,15775,16241,15926,16179.8,38,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13481,13930,14420,14308,13908,14378,13966,14056,13960,13887,13928,14074.1,39,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598337,598466,598660,598111,598455,598115,601193,598203,598196,597805,598824,598602.8,40,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16166,20200,20293,20832,21130,19985,20866,19930,20060,20746,21378,20542.0,41,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597770,597109,599619,599041,599611,599707,598546,598233,597389,598756,598524,598653.5,42,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25807,30063,30000,30440,29965,30231,30133,30014,30132,30641,30203,30182.2,43,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735772,733871,732510,731489,734358,735557,739107,734041,737975,735999,734696,734960.3,44,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9896,12588,12665,12853,13009,12517,13075,12772,12740,12742,12835,12779.6,45,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14912,16919,17522,17664,17453,17727,17208,16784,17081,17291,16784,17243.3,46,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11468,14722,14917,16349,15077,15909,15511,14323,15351,15355,15801,15331.5,47,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24042,25349,25538,25631,25181,26044,25394,25205,25199,25400,25246,25418.7,48,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3310,3941,4614,4609,3991,4663,3925,4000,3942,3992,4025,4170.2,49,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3464,4005,4680,4684,4077,4699,4181,4095,4123,4055,4006,4260.5,50,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",15081,17807,18936,18954,18196,18724,18238,18623,18234,17919,18339,18397.0,51,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14670,16099,16304,16557,16142,16435,16418,15900,15811,16020,16064,16175.0,52,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12930,14833,14557,14734,14168,14759,13977,14141,13941,14476,14070,14365.6,53,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282548,282672,282785,282282,285183,283372,284548,282232,283033,283160,283964,283323.1,54,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282084,283343,285572,286178,282934,285810,284010,282526,284686,284225,282558,284184.2,55,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282421,284194,284104,284409,282652,283197,283659,282773,282675,282974,282576,283321.3,56,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14441,16863,17179,16977,16396,17582,16411,16411,16552,16333,16434,16713.8,57,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15057,16444,16815,17364,16697,16733,16708,16611,16455,16412,16445,16668.4,58,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12807,18026,17691,17536,17207,17325,17699,17484,17660,17525,17557,17571.0,59,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13893,17122,17247,17599,17561,17437,18057,17709,17356,17422,17123,17463.3,60,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14018,16042,16402,16426,15947,16576,15923,15697,15841,16089,16667,16161.0,61,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14035,16129,16314,16344,16040,16703,16069,15902,15775,15920,16021,16121.7,62,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29603,30376,30436,30555,30366,30416,30217,30279,30272,30457,30526,30390.0,63,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11525,14244,14469,14367,14947,15331,14685,14725,14392,14676,14783,14661.9,64,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19814,21563,21515,21637,21696,21689,21785,21619,21655,21603,21574,21633.6,65,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25380,27830,28414,28276,27677,27879,27552,27215,27343,27519,27824,27752.9,66,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25575,30221,29892,30253,30028,31679,29815,30448,30038,31140,30451,30396.5,67,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23423,25753,26140,26462,26135,26539,26133,25910,25892,25849,26185,26099.8,68,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26928,28969,28899,28653,28986,28709,28724,28503,34827,29006,28768,28801.88889,69,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12706,14075,14020,13988,14245,14241,14289,14008,13908,13966,13950,14069.0,70,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283017,282361,282923,282334,281767,282891,282641,281499,282646,281842,283056,282396.0,71,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9925,12325,12416,12492,13492,13462,12824,12382,13015,12519,12568,12749.5,72,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14614,17117,16979,17014,16352,17133,16357,16575,16563,16969,16648,16770.7,73,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11558,14327,15338,15256,15123,15115,15472,14588,14420,14931,14849,14941.9,74,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23791,25013,25423,25748,25868,25719,25068,24967,25031,25087,25019,25294.3,75,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3396,3998,4668,4645,4031,4634,3956,4049,3959,3996,4040,4197.6,76,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3431,4001,4666,4704,4070,4639,4156,3994,4102,4049,3984,4236.5,77,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14579,18182,18588,18291,18947,18375,17956,18156,17716,18177,17838,18222.6,78,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14015,15780,16319,16865,16305,16425,16060,15688,15777,16440,15764,16142.3,79,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12633,14121,15128,14764,14679,14648,14232,14617,15294,14411,14332,14622.6,80,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598111,598446,598376,598538,599028,597839,597954,598964,599251,598711,597987,598509.4,81,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15909,20407,19993,19637,19776,20183,20078,19986,20303,20287,20327,20097.7,82,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598555,598219,597781,598277,598373,599110,598657,597382,599073,598216,598603,598369.1,83,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25942,30158,30419,30253,30142,30705,30249,29940,30027,30269,30309,30247.1,84,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733688,731855,734105,737258,735888,737028,736241,735555,734555,734959,737237,735468.1,85,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10034,12744,12720,12658,12605,12492,12418,12653,12694,12745,12526,12625.5,86,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14734,16995,17086,16828,16454,17168,16476,16501,16702,16838,16702,16775.0,87,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11616,15515,15404,15027,15290,14951,15271,14728,15210,15716,15363,15247.5,88,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23896,25146,25718,25703,25614,25464,25399,25015,25149,25100,25413,25372.1,89,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3324,3952,4581,4586,4058,4753,3945,3942,3914,3984,3937,4165.2,90,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3362,4025,4671,4655,4095,4682,4173,4049,4233,4045,4119,4274.7,91,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14523,18037,18740,18535,18021,18709,17648,18040,18023,18317,18983,18305.3,92,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14206,16244,16457,16670,16070,16389,15873,15847,15608,15911,16142,16121.1,93,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12528,14367,14989,15126,14488,15115,14213,14514,14515,14497,14409,14623.3,94,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284038,281949,282967,282392,282832,284971,283367,282876,282747,282812,282130,282904.3,95,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282797,284590,285817,283964,285623,283386,284495,284335,282896,287149,282136,284439.1,96,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282097,283575,286163,286081,282791,282965,282519,285443,282983,283292,285087,284089.9,97,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15020,17202,17859,17495,17296,17488,17579,17204,17110,17125,16906,17326.4,98,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14646,16634,17058,16936,16678,17172,16962,16540,16717,16623,16551,16787.1,99,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13133,17618,17406,17237,17261,17111,17484,17739,17621,17366,17280,17412.3,100,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13055,17815,17295,18180,18018,17842,17697,18140,17883,17722,17756,17834.8,101,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13935,15905,16340,16442,15943,16387,16554,15649,15839,15680,16025,16076.4,102,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13856,15669,16246,16757,15771,16558,16230,16039,16157,16080,15717,16122.4,103,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29728,30227,30283,30155,30285,30205,30195,30196,30227,30709,30373,30285.5,104,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11338,14593,14468,14773,15336,14616,14959,14711,15521,14410,14934,14832.1,105,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",20131,21657,21762,21568,21680,21632,21475,21564,21702,21556,21633,21622.9,106,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25391,27593,27759,27861,27483,28246,27409,27376,27398,27528,27484,27613.7,107,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26175,30173,31300,29998,31592,30306,29846,30553,31022,30459,29896,30514.5,108,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23229,26326,26660,26577,26109,26727,26158,25885,26247,25833,26068,26259.0,109,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26819,28763,28583,28835,28674,28700,28969,28693,28498,28485,28439,28663.9,110,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12617,14643,14566,14506,14421,14532,14434,14702,14319,14368,14373,14486.4,111,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281728,283416,282664,283353,283312,286030,282780,282836,282995,284399,282435,283422.0,112,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10538,12636,13274,13349,13034,12580,12552,12489,12482,12719,13426,12854.1,113,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14711,17193,17615,17400,16864,17503,17004,16682,16669,16799,16994,17072.3,114,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11416,14428,14496,15239,15359,15112,15124,14705,14980,15278,15668,15038.9,115,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23926,25197,25594,25420,24877,25641,25099,24993,25000,25380,25161,25236.2,116,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3274,3936,4598,4592,4005,4596,3947,4010,3916,4006,3991,4159.7,117,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3386,4068,4737,4705,4128,4775,4242,4118,4262,4064,4122,4322.1,118,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13595,17742,18557,18128,18225,18141,17496,18436,17612,18206,17810,18035.3,119,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13851,15967,16359,16565,15877,16889,16413,15963,16099,16261,16185,16257.8,120,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12597,14433,15009,15041,14617,14913,14820,14658,14430,14390,15222,14753.3,121,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598380,598335,597985,598360,598126,597906,598920,597674,598595,596854,598785,598154.0,122,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15966,20042,20401,21776,20259,19889,20159,21097,20466,20617,20554,20526.0,123,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598589,598383,599423,598697,598241,598168,600291,598249,598328,598283,598040,598610.3,124,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25971,30426,30137,29991,30002,30155,30396,30431,30530,30198,30334,30260.0,125,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,732607,731816,736950,734022,738070,736314,735804,735289,736442,736768,736282,735775.7,126,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9868,13009,12792,12787,12478,12830,13060,12761,12790,12732,12714,12795.3,127,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14777,17112,17933,17185,17361,17512,17306,17179,16900,16938,16957,17238.3,128,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11351,14284,14928,14630,15422,15055,14497,14401,15846,14413,14684,14816.0,129,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23794,25245,25671,25696,25001,25797,25100,24971,25294,25096,25369,25324.0,130,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3239,3981,4642,4643,4063,4672,3992,3996,3937,4030,3997,4195.3,131,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3380,4040,4715,4687,4119,4748,4257,4089,4175,4085,4098,4301.3,132,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14348,18052,18654,19025,17888,18408,18102,17965,17891,18052,18506,18254.3,133,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14487,16122,16254,16430,16017,16317,16098,15956,15697,15970,15895,16075.6,134,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13021,14190,14667,14769,14591,14739,14440,14373,14512,14419,14443,14514.3,135,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283620,283120,285078,285426,283042,282698,282186,283745,282974,283366,282876,283451.1,136,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282504,282459,282473,283326,284653,283881,283196,283427,282223,284052,284039,283372.9,137,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282152,282391,285010,284463,283027,282752,283491,282267,283815,283956,282426,283359.8,138,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14821,17098,17451,17308,17147,17338,16902,17394,16855,16821,16911,17122.5,139,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14510,16439,16961,16834,16928,16916,16897,16742,16702,16721,16679,16781.9,140,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13041,17431,17805,17456,17128,17499,18112,17731,17754,17485,17803,17620.4,141,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12510,18005,18317,17633,17884,18375,17818,17502,17854,17607,17750,17874.5,142,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13990,16073,16497,16331,15922,16682,15988,15718,16031,15787,15806,16083.5,143,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14031,15679,16819,16127,16198,16815,16393,16091,16059,16359,15881,16242.1,144,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29770,30353,30250,30355,30315,30439,30357,30357,30374,30298,30284,30338.2,145,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11774,14934,15046,14812,14560,14533,14755,14659,14584,15196,14725,14780.4,146,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19884,21772,21750,21917,21584,21806,21803,22170,21877,21968,21740,21838.7,147,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25238,27899,27940,28276,27338,28549,27651,27498,27959,27457,27926,27849.3,148,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26347,30191,30421,30705,30600,30185,30092,30321,29728,30370,30516,30312.9,149,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23060,26215,26619,26313,26114,26263,26427,26326,26065,25905,25878,26212.5,150,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26780,28612,28683,28789,28590,28909,28726,28821,28685,28611,28953,28737.9,151,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12621,14754,14594,14474,14479,14476,14743,14435,14548,14328,14486,14531.7,152,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281842,282936,281663,283052,283106,283174,282823,282456,282922,284841,282595,282956.8,153,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9923,12797,13226,12790,13376,13046,12799,12947,13440,12817,13144,13038.2,154,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14407,16865,17459,17649,17063,17376,16858,17106,16955,17106,16951,17138.8,155,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11457,15044,15022,14867,15724,15780,15098,14981,14991,14627,14557,15069.1,156,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24289,25020,26007,25501,25180,25838,25173,24885,25185,25109,24984,25288.2,157,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3263,4064,4629,4641,4066,4637,3989,4020,3949,4127,3968,4209.0,158,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3385,4058,4677,4664,4083,4704,4163,4055,4106,4083,4052,4264.5,159,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13917,17642,19014,18414,17875,18282,17422,17919,17686,17952,17395,17960.1,160,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14111,15888,16474,16265,15821,16299,16294,16075,16070,15957,15841,16098.4,161,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12618,14475,14939,14906,14265,15201,14197,14460,14369,14640,14540,14599.2,162,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599175,597913,599162,597158,597766,598338,598427,598069,598631,598975,599050,598348.9,163,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15845,20675,20611,20155,20959,20415,21055,20476,21406,20477,20574,20680.3,164,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598123,598044,598264,599113,598715,597658,599045,599108,598987,599085,599249,598726.8,165,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25917,30426,30728,30274,30473,30406,30523,30276,30477,30177,30183,30394.3,166,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735012,736934,735517,733719,735032,735481,737505,738201,733407,735257,733312,735436.5,167,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9895,12810,13007,12737,12871,12573,12811,12835,12689,12841,12981,12815.5,168,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14781,17453,17895,17668,17553,17469,17078,17387,17289,16819,17248,17385.9,169,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11610,14340,16236,15644,14605,15036,15112,14925,15062,14702,15035,15069.7,170,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23916,25465,25765,25655,25783,26133,25314,25279,25174,25260,25248,25507.6,171,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3308,3976,4739,4590,4021,4618,3956,3999,3946,4014,3994,4185.3,172,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3434,4007,4641,4621,4037,4656,4187,4024,4110,4031,4002,4231.6,173,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14135,17349,18401,18306,17576,17845,17785,17771,17902,17794,18176,17890.5,174,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14346,15971,16568,16335,16092,16504,16143,15995,16116,16338,15779,16184.1,175,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12691,14418,14810,14888,14275,15096,14364,14295,14156,14264,14373,14493.9,176,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281972,282860,282571,284155,283603,283400,282265,282853,281589,282197,283692,282918.5,177,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281811,283633,283128,282757,282887,282509,282145,283526,282587,283155,284698,283102.5,178,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281509,284236,283164,283347,283487,283036,283400,283229,282627,282532,282352,283141.0,179,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14838,17086,17591,17510,16965,17661,17430,16969,17244,17105,16957,17251.8,180,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14588,16991,18191,17609,17297,17406,17609,16717,17082,17083,17164,17314.9,181,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12564,17382,17850,17592,17976,17958,18334,17506,17986,17621,17184,17738.9,182,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13510,17315,17419,17303,17747,17592,17472,17430,17189,17540,17340,17434.7,183,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14086,15777,16424,16783,16167,16432,15805,16100,16457,16027,15582,16155.4,184,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13904,16051,16715,17038,16119,16478,16021,15803,16071,16170,15899,16236.5,185,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29503,30234,30372,30546,30288,30192,30399,30397,30319,30432,30603,30378.2,186,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11258,14608,14742,14856,14819,15179,14619,15538,15929,15500,15210,15100.0,187,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19873,22148,22101,22193,22321,22080,22320,22231,22004,22123,22225,22174.6,188,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25116,27610,27969,28411,27594,27929,27626,27167,27675,27399,27615,27699.5,189,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25782,30024,30096,30327,30901,31128,30545,31156,31544,30308,30191,30622.0,190,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23493,25969,26767,26423,25842,26388,26242,26168,26375,25947,26188,26230.9,191,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26655,28876,28773,28574,28804,28586,28639,28874,28839,28907,28673,28754.5,192,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12624,14711,14557,14565,14380,14485,14522,14451,14572,14370,15585,14619.8,193,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282591,284430,282769,283062,283098,282711,284690,283482,283824,283507,283764,283533.7,194,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9885,12700,12922,12805,12698,12682,12899,12923,12742,12879,12743,12799.3,195,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14722,16975,18006,17635,17342,17870,17162,16905,16871,17050,16982,17279.8,196,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11390,15148,14864,14470,14888,14802,14588,14524,15095,14813,14648,14784.0,197,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23800,25066,25563,25790,24984,25590,24860,24965,25240,25114,24928,25210.0,198,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3318,3922,4580,4582,4028,4589,3925,4054,3934,3983,3913,4151.0,199,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3405,4031,4674,4798,4021,4644,4171,4061,4092,4053,4035,4258.0,200,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14031,17547,18347,18242,18331,18737,18033,17854,17630,17613,17700,18003.4,201,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14090,16239,16415,16404,16007,16326,16067,16031,16419,16325,15796,16202.9,202,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12735,14234,14948,14813,14481,15118,14443,14478,14570,14554,14221,14586.0,203,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598286,598048,597512,599204,598509,598423,598439,598811,598665,598292,598403,598430.6,204,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16347,20433,20363,21666,20864,19976,21237,19982,21303,20706,20827,20735.7,205,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597383,598661,598386,599467,598835,597994,598598,598881,598252,598023,599022,598611.9,206,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25786,29945,30527,30184,30178,30213,30125,29703,30164,30011,30478,30152.8,207,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,736727,739656,737336,737199,737318,739817,738930,735037,734627,736373,732006,736829.9,208,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10112,12701,12530,12708,12466,12516,12611,12733,12630,12828,12511,12623.4,209,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15083,16525,17172,16924,17022,17216,16750,16873,16847,16661,16571,16856.1,210,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",12258,15139,15073,15835,14249,15581,14675,14537,14931,14664,14955,14963.9,211,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23664,25199,25868,25869,25728,25982,25752,25345,25930,25593,25704,25697.0,212,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3312,3933,4582,4742,4022,4574,3974,3942,3875,3982,3947,4157.3,213,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3408,4001,4680,4659,4123,4664,4110,4035,4113,4019,3997,4240.1,214,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14534,17706,18003,18423,17833,18545,17971,17432,17555,17734,17762,17896.4,215,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14382,15622,16356,16564,15900,16816,16162,16109,16783,16047,15804,16216.3,216,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12405,14290,14750,14790,14307,14903,14289,14406,14349,14259,14185,14452.8,217,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282559,282668,282089,283551,282603,282506,282442,282486,282933,284099,282379,282775.6,218,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282385,283124,282405,282134,283326,283342,282443,284097,282268,283518,283709,283036.6,219,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282311,283189,282714,283688,285748,283303,285375,283344,284463,285940,283648,284141.2,220,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14595,17024,17882,17471,17345,17680,17163,17026,17334,17621,17359,17390.5,221,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14647,16863,17849,18012,16794,17245,17004,17054,17547,17069,17246,17268.3,222,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13181,17925,17199,17469,17268,17237,17455,17442,18191,17690,17457,17533.3,223,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12562,17258,18023,17387,17254,17286,17757,17425,17233,17968,17199,17479.0,224,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14045,15931,16654,16674,15973,16368,15860,15819,15708,16060,15909,16095.6,225,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13815,15813,16298,16188,16349,16336,15860,16054,15824,15782,15845,16034.9,226,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29773,30414,30466,30355,30349,30179,30479,30471,30256,30446,30233,30364.8,227,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11270,14878,14446,14525,14597,14943,14541,15165,14526,15104,14314,14703.9,228,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19995,21817,21609,21743,21846,21895,21761,21879,21734,21805,22046,21813.5,229,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25701,27764,27899,27914,27907,28562,27728,27370,28005,27837,27514,27850.0,230,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25800,30738,30481,29923,30061,30808,30864,29867,30112,30468,30512,30383.4,231,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23191,25693,26807,26435,25999,26467,26377,25912,25964,26278,26089,26202.1,232,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26797,28776,28545,28319,28461,28408,28810,28503,28606,29271,28704,28640.3,233,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12586,14404,14714,14398,14425,14395,14577,14646,14943,14863,14533,14589.8,234,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282897,284168,283972,282145,282258,283295,283617,282952,283048,283524,284108,283308.7,235,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10624,12907,12813,12945,12926,12778,12906,13000,13027,12901,13236,12943.9,236,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14507,16844,17590,17474,17163,17887,17012,17235,17179,17283,16867,17253.4,237,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11523,15292,14986,15443,14358,15794,15270,15238,15052,15186,14980,15159.9,238,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24107,24871,25493,25409,25028,25627,25262,25102,24855,25171,25050,25186.8,239,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3313,3914,4610,4571,3987,4619,3917,3969,3924,3950,3931,4139.2,240,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3425,3989,4680,4635,4059,4624,4155,4064,4114,4071,4004,4239.5,241,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14251,17990,18466,18559,17896,19161,17964,18142,18184,17631,17854,18184.7,242,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14213,15702,16241,16595,16039,16291,16055,16423,16185,15830,15892,16125.3,243,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12623,14376,14974,15072,14517,14906,14437,14478,14305,14537,14350,14595.2,244,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598427,598946,599142,598645,598916,599474,599346,598492,598447,598643,598650,598870.1,245,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15682,20704,20457,21091,20225,20455,20526,20087,20732,20172,20544,20499.3,246,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597724,599173,600401,598864,598665,598897,598387,599526,598955,598653,599569,599109.0,247,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25845,30248,30085,30244,30369,30168,30279,30367,30170,30012,30053,30199.5,248,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733284,737216,736460,734640,734266,733715,737653,738089,733940,734931,732192,735310.2,249,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10498,12473,12525,12622,12776,12759,12641,12593,12543,12495,12754,12618.1,250,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14641,17238,17423,17691,16960,18076,17098,17074,17230,17333,17429,17355.2,251,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11337,14810,14756,14927,14466,15300,14276,15342,14282,14507,14640,14730.6,252,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23769,25453,25626,25704,25178,25598,25219,25419,25007,25339,25510,25405.3,253,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3291,3911,4579,4540,4005,4579,3929,3943,3881,4043,3943,4135.3,254,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3381,4021,4686,4681,4084,4697,4151,4085,4169,4076,4063,4271.3,255,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14139,18161,18827,18715,18482,18674,18448,18765,17930,17915,18519,18443.6,256,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14244,15881,16423,16722,16193,16408,15912,15955,15910,15904,16048,16135.6,257,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12576,14248,14755,14747,14385,14977,14427,14451,14423,14427,14132,14497.2,258,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283214,284200,283800,282639,284174,282629,282825,282946,283013,282945,282741,283191.2,259,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282498,283368,284156,283460,283605,282108,283060,283391,283389,283732,281655,283192.4,260,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284868,283317,283097,282635,282997,282705,283868,283789,283010,284071,282748,283223.7,261,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14254,16969,17711,17780,17260,17653,16800,17039,17301,17235,17331,17307.9,262,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15044,16252,16833,16883,16532,17151,16282,16632,16236,17019,16447,16626.7,263,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12637,17636,18014,18147,17489,17865,17685,17367,18184,17435,18150,17797.2,264,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12585,18059,17568,17804,18269,17737,17836,17828,17599,17832,17467,17799.9,265,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13909,16043,16354,16533,15807,16839,15936,15943,15885,16024,15914,16127.8,266,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13972,15965,16238,16745,16136,16652,15977,15805,16657,16033,15879,16208.7,267,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,30037,30344,30118,30512,30566,30585,30345,30640,30481,30518,30827,30493.6,268,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11403,14452,15644,14683,14369,14807,15066,14694,14639,15541,14537,14843.2,269,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19907,21640,21846,21847,21810,22021,21718,21698,21869,21767,21969,21818.5,270,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25484,27672,27982,27607,27777,28142,27482,27622,27889,27622,27566,27736.1,271,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25808,30393,30030,31007,30759,29768,30790,30892,30289,30118,31112,30515.8,272,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23466,25833,26573,26316,25980,26579,26142,25936,26100,25975,26255,26168.9,273,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26797,28658,28738,28488,28511,28653,28480,28667,28606,28487,28810,28609.8,274,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12602,14478,14311,14515,14636,14415,14219,14466,14415,14702,14429,14458.6,275,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283808,283752,282598,282811,285340,283268,283468,285607,282227,282463,283121,283465.5,276,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9816,12744,12729,13341,12807,13322,12853,13204,12970,13074,13007,13005.1,277,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14595,16697,17023,17220,16877,17512,16935,16613,16472,16370,17127,16884.6,278,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11393,15073,15411,15575,15046,15129,14509,14493,15081,14697,14726,14974.0,279,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24383,24877,25530,25295,24932,25532,24929,25052,25033,25169,25081,25143.0,280,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3291,3945,4587,4601,3998,4587,3931,3986,3917,4068,3932,4155.2,281,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3357,4083,4776,4685,4137,4721,4208,4098,4205,4067,4050,4303.0,282,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14176,17788,18359,18962,18659,18697,18058,17962,17818,18305,17694,18230.2,283,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13919,15993,16405,16237,16162,16262,16099,16158,16032,15963,16045,16135.6,284,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12507,14493,15045,15117,14797,14975,14441,14350,14458,15049,14477,14720.2,285,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598509,598540,598358,598695,598660,598119,598383,598252,599448,598197,599269,598592.1,286,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15752,20194,20552,21605,20281,19888,20153,20725,21175,20459,21108,20614.0,287,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598239,597892,598243,598046,599708,598269,597693,597835,598770,597652,598438,598254.6,288,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",27173,30390,30284,30587,30881,30567,30636,30109,30625,30514,30479,30507.2,289,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733467,736871,735417,732132,734172,735043,740206,730395,737691,735490,735027,735244.4,290,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10003,12431,12620,12581,12327,12697,12421,12546,12322,12714,12538,12519.7,291,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14959,16566,17312,17612,16677,17371,16464,16671,16856,17010,16866,16940.5,292,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11323,14595,15138,15147,14903,15013,14317,14699,14531,14821,14714,14787.8,293,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23758,25033,25571,25685,25378,25909,25359,25317,25450,25131,25585,25441.8,294,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3315,4021,4666,4627,4170,4713,4120,4062,4058,4026,4061,4252.4,295,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3369,4086,4810,4723,4135,4739,4262,4104,4170,4123,4066,4321.8,296,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13953,18127,18738,19559,18229,18816,18119,17990,19113,18523,18265,18547.9,297,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14203,16045,16359,16629,16101,16468,15906,16197,16110,15769,16080,16166.4,298,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12524,15036,14925,14967,14390,14756,14408,14413,14344,14258,14266,14576.3,299,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282286,282930,283064,283712,283534,283802,283279,283429,283041,284143,282329,283326.3,300,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282705,283599,282281,282783,283720,286049,283451,283208,284457,282311,284181,283604.0,301,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282291,282376,283356,282598,282449,284526,282036,283517,282794,283197,282236,282908.5,302,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14928,17471,17325,18117,16768,17779,16992,17032,17596,17000,17317,17339.7,303,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15394,16909,17040,17164,16972,16956,16676,16742,16872,16541,16723,16859.5,304,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13207,17801,17722,17468,17248,17723,17745,17791,17419,17368,17250,17553.5,305,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13284,17763,18360,17635,17662,17635,18002,18104,17327,17695,18126,17830.9,306,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13856,16424,16204,16520,15765,16416,15807,16349,16027,15912,15959,16138.3,307,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13906,16030,16295,16426,15914,16440,16264,16520,15904,16156,15920,16186.9,308,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29705,30577,30437,30383,30287,30499,30475,30408,30640,30754,30537,30499.7,309,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11247,15380,15164,15679,15208,15133,14929,15490,15197,15262,15963,15340.5,310,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19980,21732,21624,21662,21837,21708,21714,21923,21674,21496,22026,21739.6,311,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25012,27439,27910,28113,27069,28448,27385,27616,27818,27449,27400,27664.7,312,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26904,30415,30333,30029,30137,30728,30324,31003,30010,31346,30548,30487.3,313,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23298,25977,26026,26842,26022,26386,26074,26103,26174,26006,26151,26176.1,314,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26817,28804,28722,28449,28854,28653,28772,28428,28961,28571,28866,28708.0,315,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12607,14547,14837,14393,14681,14577,14436,14553,14762,14843,14685,14631.4,316,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281248,282266,282379,283051,282591,282741,282559,282430,283740,282573,282126,282645.6,317,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10799,12933,13211,13194,12918,12770,13060,12999,13148,12786,12825,12984.4,318,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14759,25571,17772,17638,17291,17607,17349,16931,17023,17474,17262,17371.88889,319,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11417,15654,16176,15312,14575,16076,15193,15123,15115,15762,15017,15400.3,320,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24245,25065,25708,25875,25072,25525,25220,25262,25493,25363,25277,25386.0,321,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3272,3982,4627,4629,4059,4647,4018,4075,3992,4054,4031,4211.4,322,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3441,4066,4701,4694,4123,4736,4154,4079,4168,4075,4127,4292.3,323,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14556,18281,19123,18392,17752,18610,17309,17902,17919,18178,18418,18188.4,324,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14230,16024,16235,16189,15566,16391,15850,15705,15782,16250,15841,15983.3,325,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12598,14610,14988,15049,14631,15052,14333,14339,14550,14416,14356,14632.4,326,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598114,597402,599348,598735,598810,598604,599058,598797,599287,599778,598659,598847.8,327,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15795,20671,20128,21713,21018,20232,20039,20628,20728,20029,21767,20695.3,328,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598679,598747,598384,598651,598849,598251,599520,598615,598659,598109,599309,598709.4,329,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25955,30365,29981,30065,30767,30496,30335,30241,30359,30683,30421,30371.3,330,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735037,736534,736719,732877,735367,737227,736831,734497,732759,734553,738357,735572.1,331,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9832,12557,12293,12506,12716,12714,12314,12712,12908,12428,12492,12564.0,332,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14813,16986,17656,17760,17005,17542,16991,16724,17007,17163,17011,17184.5,333,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11882,14607,14869,15626,14629,14961,15278,14528,15363,15105,14390,14935.6,334,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23901,25398,25709,25474,25012,25515,25286,24897,25425,25064,25195,25297.5,335,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3490,3997,4622,4614,4058,4666,3984,4056,3977,4012,3980,4196.6,336,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3469,4036,4709,4665,4060,4677,4160,4074,4137,4075,4006,4259.9,337,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14011,17432,18407,18325,17483,18240,17427,17874,17835,17806,18045,17887.4,338,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14249,16107,16245,16466,16029,16625,15996,15824,15982,16092,16070,16143.6,339,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12505,14405,14915,14873,14242,15255,14419,14560,14220,14263,14344,14549.6,340,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283259,285092,282597,284832,283790,284785,282005,282990,282794,283990,285341,283821.6,341,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282945,283849,283348,283981,282705,282470,283853,282738,283730,284940,283431,283504.5,342,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282550,282730,283292,284124,283022,284536,283065,285361,283958,282198,284865,283715.1,343,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14619,17257,17406,17656,17025,17506,16925,17364,16907,16974,17041,17206.1,344,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14578,16553,17441,17051,16492,17109,16707,16807,16568,16782,16563,16807.3,345,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13063,17975,18128,17773,18233,17780,17883,17793,17413,17652,17444,17807.4,346,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12479,17553,18102,17653,17449,17519,17214,17356,17483,17513,17671,17551.3,347,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13849,15816,16161,16271,15788,16624,15747,15742,16054,15725,15817,15974.5,348,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14039,15824,16287,16398,15716,16208,15954,15824,15938,16072,16160,16038.1,349,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29617,30481,30434,30208,30361,30425,30333,30385,30655,30360,30518,30416.0,350,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11249,15255,14570,15968,14792,14615,15139,14804,14461,14678,14954,14923.6,351,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19796,21634,21748,21610,21859,21916,21697,21514,21816,21718,21975,21748.7,352,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25850,27792,27899,28029,27333,28045,27261,27653,27241,27806,27319,27637.8,353,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26101,30991,29464,30462,30846,30053,30692,30483,31748,30458,30146,30534.3,354,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23154,25989,26109,26804,25979,26542,26010,26121,26030,26119,26275,26197.8,355,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26934,28632,28551,28704,28560,28958,28546,28418,29144,28963,29015,28749.1,356,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12639,14678,14747,15112,14456,14541,14471,14629,14577,14531,14735,14647.7,357,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,286139,283820,283732,282375,283410,283583,285288,283480,283867,283945,283826,283732.6,358,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9879,12694,12410,12512,12637,12770,13475,12427,12832,12810,12574,12714.1,359,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14433,17338,17878,17640,17129,17608,17394,17315,17499,17091,17098,17399.0,360,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11452,14854,14834,15737,14286,15561,14396,15012,14553,15061,14473,14876.7,361,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23977,25153,25312,25761,24895,25497,25364,25013,25122,25305,25052,25247.4,362,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3363,3958,4601,4594,4012,4623,3960,3961,3918,4000,3946,4157.3,363,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3413,4027,4691,4697,4139,4766,4201,4139,4189,4081,4076,4300.6,364,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13888,17700,18412,18333,17588,18197,17568,17286,17853,17606,17862,17840.5,365,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13918,16136,16359,16514,16024,16244,15804,15838,16053,16064,16063,16109.9,366,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12500,14367,14922,14933,14474,15011,14398,14816,14353,14483,14275,14603.2,367,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598989,598014,598199,598845,597322,597925,597161,598390,598905,599290,598901,598295.2,368,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15843,19896,19930,21017,20808,20681,20993,20868,21012,20048,20657,20591.0,369,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597903,598735,599091,598133,598966,597724,599441,598354,599091,597990,597836,598536.1,370,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25857,29674,30041,29992,29866,30132,30369,29894,30358,30315,30410,30105.1,371,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735767,735290,733208,734399,735731,734722,737665,733774,735319,734950,734728,734978.6,372,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9826,12762,12912,13185,12883,12658,12939,12877,12880,12997,12819,12891.2,373,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14543,17030,17736,17656,17128,17971,16991,16763,16843,16759,17142,17201.9,374,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11480,14346,16775,15851,15377,14885,14424,14069,15207,15149,14822,15090.5,375,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23939,24922,25711,25707,25368,25623,25201,25156,25002,25002,25352,25304.4,376,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3312,4024,4672,4814,4076,4651,4003,4028,3978,4026,4038,4231.0,377,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3381,4058,4708,4701,4098,4704,4190,4073,4147,4090,4044,4281.3,378,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14157,17535,18510,18591,17878,18730,18013,18189,17778,17842,17998,18106.4,379,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15167,16042,16342,16485,16338,16824,16511,16167,15833,16224,16206,16297.2,380,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12715,14373,14813,14823,14197,14911,14229,14633,14312,14291,14662,14524.4,381,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282985,284330,284336,282780,283550,283499,285050,282639,282392,282917,283142,283463.5,382,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282513,285051,282532,282965,283752,282927,282745,281745,283031,283837,282352,283093.7,383,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281453,282411,283165,282497,284493,283319,281925,282130,283660,282371,282906,282887.7,384,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14712,16944,17725,17897,17195,18303,17439,16823,16791,16716,17401,17323.4,385,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14931,17113,17122,17602,16714,17577,16919,17244,16914,17121,17211,17153.7,386,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12489,17509,17605,17312,18250,17657,18209,17846,17371,17642,17434,17683.5,387,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12183,18365,17624,17223,17532,17773,17310,17735,17793,17818,17551,17672.4,388,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14263,15717,16261,16206,15730,16332,15845,16292,15943,15887,16075,16028.8,389,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13839,15802,16084,16092,15915,16421,16550,15961,15822,15958,15868,16047.3,390,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29451,30703,30360,30433,30342,30344,30212,30263,30384,30214,30267,30352.2,391,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11370,15128,15093,14627,15387,15248,15666,15101,14685,14915,15163,15101.3,392,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19926,22324,22047,22177,22163,22333,22315,22074,22122,22356,22064,22197.5,393,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25003,27623,27805,28341,27508,28415,27949,27836,27570,27738,27819,27860.4,394,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25837,31032,30126,30285,30148,30026,30989,29875,31786,30416,31105,30578.8,395,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23248,26365,26520,26752,25886,26605,26173,26098,26016,26162,26325,26290.2,396,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26685,28616,29038,28459,28790,28654,28491,28613,28745,28548,28454,28640.8,397,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12627,14547,14436,14475,14536,14509,14901,14371,14396,14505,14671,14534.7,398,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284102,282929,282724,284593,283877,283936,286420,286000,283269,283174,282741,283966.3,399,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9934,12619,13170,13453,12582,12462,12813,12510,13497,12570,13145,12882.1,400,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14669,17295,17445,17669,17280,17536,17367,16775,17336,17191,17373,17326.7,401,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11588,14221,15118,15106,15291,15124,14272,14678,15152,14397,14928,14828.7,402,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24481,25454,25924,25520,24805,25458,25511,25040,24944,25119,25016,25279.1,403,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3253,4004,4636,4661,4057,4661,3981,4051,3995,4030,3987,4206.3,404,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3371,4007,4703,4661,4083,4689,4185,4079,4117,4044,4180,4274.8,405,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14002,17816,18824,18616,17741,19471,18043,18613,17720,18145,17844,18283.3,406,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14140,16295,16684,16386,16004,16396,16116,16201,16437,15934,15995,16244.8,407,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12780,14409,14581,14798,14172,14792,14400,14502,14411,14336,14408,14480.9,408,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598510,598028,598098,598695,600068,599085,599400,598645,597724,598465,598378,598658.6,409,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15921,20657,20636,20700,20896,19712,20836,20044,21077,20469,20978,20600.5,410,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597837,598189,598266,598927,598208,598344,599012,598018,599094,598016,598771,598484.5,411,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25827,30090,30108,30454,30771,30407,30271,29808,30021,30355,30309,30259.4,412,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733830,737062,735619,742291,740304,739754,733846,736043,735107,734416,737786,737222.8,413,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9906,12817,13028,12348,12893,12606,12467,12586,12666,12572,12825,12680.8,414,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15283,16490,17006,17339,16458,17097,16758,16995,16499,16660,16546,16784.8,415,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11331,14983,15707,15172,14573,14916,15181,14755,14565,15161,14544,14955.7,416,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24194,24883,25846,25691,25530,26331,25194,24978,25460,25261,25112,25428.6,417,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3247,3954,4595,4576,4023,4601,3977,4008,3943,4113,3967,4175.7,418,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3470,4014,4677,4638,4039,4641,4172,4104,4130,4012,4025,4245.2,419,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13626,17365,17906,17751,17808,17973,17695,17792,17515,17474,17656,17693.5,420,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14217,15772,16176,16194,15812,16312,15648,15667,15840,15864,15749,15903.4,421,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12319,14437,14923,15121,15014,14989,14352,14580,14330,14395,14299,14644.0,422,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281634,285009,284501,283521,283513,282003,283359,283094,282119,282157,283277,283255.3,423,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282203,283952,283476,283950,282645,283150,283632,284163,283939,283885,283527,283631.9,424,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282288,282615,283184,284384,283000,283713,283302,282389,284524,282833,284636,283458.0,425,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14730,17241,17826,17814,16874,17651,17137,16890,17238,17260,17309,17324.0,426,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14551,17151,17921,17373,16749,17646,16843,17121,16975,17251,17260,17229.0,427,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12948,17271,17844,17602,17468,17352,18475,17865,17721,17410,17392,17640.0,428,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12843,17753,17612,17648,17510,17795,17506,17424,17796,17411,17594,17604.9,429,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14097,15875,16523,16367,15927,16415,15895,16115,15939,16071,16061,16118.8,430,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13972,15691,16116,16249,15802,16523,15769,16279,15951,15655,16065,16010.0,431,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29649,30352,30485,30172,30465,30708,30275,30552,30531,30335,30360,30423.5,432,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11518,14749,14923,14481,14392,14953,15279,14480,14474,15394,15261,14838.6,433,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19872,21995,21814,21674,21725,21692,21676,21585,21645,21621,21817,21724.4,434,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25034,27249,27527,28266,27094,28037,27524,27174,27575,27782,27330,27555.8,435,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26592,29678,30574,30854,29465,30023,30452,30185,30281,30817,30804,30313.3,436,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23285,25914,26592,26504,26232,26450,25767,26110,26022,25985,26095,26167.1,437,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26777,28527,28584,28673,28562,28885,28597,28668,29000,29242,28476,28721.4,438,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12558,14460,14672,14451,14517,14734,14577,14537,14544,14258,14449,14519.9,439,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282844,283681,282288,284298,281680,282584,284291,282614,282995,283242,284369,283204.2,440,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9949,12651,12782,12773,12835,12598,12514,12747,13325,12548,12663,12743.6,441,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14723,17155,17301,17235,16772,17858,17950,16954,17195,17206,17118,17274.4,442,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11559,14785,15029,15113,15091,15329,14834,14954,14727,13966,14547,14837.5,443,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24156,24992,25465,25290,25080,26080,24922,24917,25061,25197,24958,25196.2,444,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3299,3952,4597,4572,3993,4571,3952,3994,3888,3959,3930,4140.8,445,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3409,3971,4672,4626,4071,4758,4133,4037,4110,4024,3991,4239.3,446,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14121,17429,19011,18705,17935,18218,17570,18048,17603,17792,17794,18010.5,447,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14624,16143,16325,16357,16204,16372,15979,15951,16147,15919,16004,16140.1,448,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13341,14167,14905,14854,14568,14912,14348,14369,14460,14202,14301,14508.6,449,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599473,597233,599072,598283,597853,598872,598199,598649,598035,598223,598072,598249.1,450,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16279,19523,20613,20396,19742,20091,20924,19836,19960,20688,20037,20181.0,451,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598346,598243,598055,598199,598352,598914,599036,598735,597471,598089,599306,598440.0,452,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",26008,30263,30307,30933,30378,29940,30169,30075,29875,30070,30092,30210.2,453,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,732857,732200,736380,731939,737149,734950,738047,732029,734802,739727,734243,735146.6,454,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9778,12685,12425,12397,12586,12513,12862,12601,12626,12775,12701,12617.1,455,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14812,16568,17586,17380,17016,17417,16880,17077,16789,17032,17397,17114.2,456,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11444,14490,15261,15594,14378,15497,14661,14938,14711,14341,14636,14850.7,457,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23785,24896,25479,25742,25355,25624,25302,25046,25091,25078,25096,25270.9,458,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3304,3934,4626,4561,3986,4572,3915,3960,3901,3974,3918,4134.7,459,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3454,4033,4688,4679,4058,4687,4169,4054,4153,4064,4050,4263.5,460,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14608,17523,18690,18775,18445,18776,17583,18482,17826,17617,17651,18136.8,461,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14335,15658,16428,16846,15801,16226,15879,15854,16187,16113,15657,16064.9,462,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12591,14502,15225,15396,14450,15084,14800,14354,14253,14257,14480,14680.1,463,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281607,283392,282745,283855,282868,282333,284496,282632,282047,282757,282238,282936.3,464,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282143,282134,282950,282535,283965,284105,283634,283892,283028,282782,283193,283221.8,465,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282707,283864,283320,283313,281831,282537,282600,281784,283126,283443,282506,282832.4,466,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14709,16708,17940,17342,17175,17924,16876,17452,16736,16991,16819,17196.3,467,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15091,16488,16894,16956,17063,17126,16405,16915,16693,16290,16835,16766.5,468,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13046,17024,17344,17447,17678,17625,17822,17780,17808,17330,17317,17517.5,469,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12754,17400,17056,17523,17209,17420,17152,17167,17206,17537,17441,17311.1,470,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13812,15465,16419,16353,15818,16785,15828,15945,16392,15805,15820,16063.0,471,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13798,16052,16408,16342,16055,16614,16124,15864,15910,15775,15872,16101.6,472,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29442,30358,30528,30395,30291,30372,30279,30532,30221,30507,30405,30388.8,473,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",12014,14906,15536,15078,14996,15420,15188,15480,15116,15128,15307,15215.5,474,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19732,21491,22033,22101,21834,21654,21686,21680,21532,21788,21564,21736.3,475,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25361,27631,27991,27708,27248,27938,27730,27503,27471,27467,27433,27612.0,476,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25597,30501,30318,31324,30321,30443,31277,30779,31447,30527,30513,30745.0,477,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23131,25824,26354,26337,26235,26548,25990,25927,26146,26369,25948,26167.8,478,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26947,28398,28604,28322,28949,29041,28785,28564,28593,28439,28503,28619.8,479,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12608,14465,14415,15166,14428,14257,14532,14524,14421,14380,15099,14568.7,480,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283558,284141,282451,283339,283550,282295,283790,284011,283942,283351,283770,283464.0,481,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10856,12576,12425,12520,12583,12550,12515,12630,12645,12568,12592,12560.4,482,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14821,16810,16788,16914,16601,17245,16263,16876,16648,16682,16812,16763.9,483,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11683,14869,15590,14974,14575,15165,15016,14576,14642,14500,14650,14855.7,484,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23866,25214,25702,25864,25123,25587,24942,25331,25447,25237,25420,25386.7,485,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3322,3935,4593,4595,3998,4605,3955,4018,3974,4011,4013,4169.7,486,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3606,4091,4737,4710,4146,4719,4200,4165,4189,4127,4058,4314.2,487,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14351,18563,18815,18583,18178,18765,17890,18141,17898,18741,17897,18347.1,488,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13944,16116,16354,16377,16138,16301,15981,16061,15981,16093,15930,16133.2,489,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12563,14425,14917,15020,14296,14943,14281,14298,14416,14339,14282,14521.7,490,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598376,599232,600277,600850,600189,599490,598719,599800,598884,598992,600998,599743.1,491,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16185,19831,20845,20673,19714,20450,20102,20452,20158,20539,20593,20335.7,492,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598316,599204,598210,596715,598139,598378,598297,599023,598816,597374,599358,598351.4,493,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",27241,30240,30142,30166,30135,30558,30408,30024,30038,30960,30264,30293.5,494,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735159,736674,735818,735400,738340,735476,737601,731674,731883,731947,733531,734834.4,495,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9872,12852,12680,12804,12798,12674,12974,12887,12775,12698,13065,12820.7,496,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15482,17011,17297,17480,16479,17059,16792,16428,16848,16965,16578,16893.7,497,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11944,13645,15686,15315,15721,15497,14383,15119,14413,14210,14692,14868.1,498,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23675,24912,25362,25420,25171,25440,25332,24977,25009,24992,25097,25171.2,499,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3308,4019,4656,4655,4081,4703,4020,4084,3992,4017,3990,4221.7,500,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3402,4068,4739,4712,4102,4750,4233,4085,4283,4130,4095,4319.7,501,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14474,18162,18821,19401,18956,19463,18460,18125,18758,18226,18659,18703.1,502,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14225,16217,16617,16164,16146,16305,16273,16267,16211,15870,15862,16193.2,503,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13355,14170,14916,15322,14373,15051,14540,14220,14464,14543,14588,14618.7,504,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282662,283612,283393,283159,282951,282390,283637,282740,282378,283061,282691,283001.2,505,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282937,281490,284419,282363,281341,282385,284996,282833,282742,282532,283778,282887.9,506,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283918,283280,282478,283724,283578,284055,282572,283024,282556,282758,282939,283096.4,507,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15238,16936,17429,17698,16791,17247,16847,17167,16699,17409,17120,17134.3,508,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14724,16319,17282,16978,16353,16821,16447,16872,16368,16894,16955,16728.9,509,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12653,17463,17396,17803,17574,17580,17527,17595,17756,17529,17936,17615.9,510,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12651,17961,17736,18378,18669,18522,17665,18684,18016,18117,17934,18168.2,511,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13919,16303,16241,16503,15874,16436,16078,15806,16007,15837,15893,16097.8,512,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14075,16274,16666,16336,15982,16678,15844,15829,16167,16039,16198,16201.3,513,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29652,30342,30269,30258,30292,30345,30220,30436,30337,30376,30395,30327.0,514,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11601,15321,15355,15484,15121,14406,15320,15069,15239,15249,15390,15195.4,515,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19753,21486,21782,21765,21606,21635,21750,21922,21616,21820,21835,21721.7,516,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25287,27322,27842,28048,27169,27822,27896,27552,27679,27264,27921,27651.5,517,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26183,30307,30323,30229,30296,31371,29701,29749,30760,30365,31566,30466.7,518,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23561,26214,26284,26434,26452,26701,26002,26219,26540,26310,26086,26324.2,519,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26926,28316,28836,28619,28617,28584,28552,29156,28493,28429,28653,28625.5,520,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12582,14465,14704,14524,14804,14474,14615,14649,14474,14427,14519,14565.5,521,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282908,284458,282824,285851,282468,283972,284090,282005,283482,283728,282557,283543.5,522,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10080,13335,12352,12310,12505,12455,12619,12926,12332,12430,13369,12663.3,523,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14749,17034,17362,17363,16845,17506,17472,16726,17221,16686,16968,17118.3,524,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11427,14460,14738,15017,15041,15888,15073,15063,15066,15470,14680,15049.6,525,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23977,24961,25389,25633,25192,25515,25195,25074,24977,24988,25068,25199.2,526,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3284,4029,4655,4641,4082,4670,4003,4053,4075,4050,3994,4225.2,527,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3399,4078,4738,4729,4134,4760,4202,4109,4191,4099,4099,4313.9,528,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14228,18114,19049,18912,18343,18894,18034,18251,18129,17860,18253,18383.9,529,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14170,15801,16326,16406,15887,16700,16142,16123,16063,16370,15751,16156.9,530,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12906,14500,14978,14932,14312,14951,14797,14456,14558,14302,14178,14596.4,531,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598612,599599,598983,599343,599652,599614,599343,599393,598796,598415,600276,599341.4,532,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15933,20324,20834,20853,20719,21374,19743,19934,20114,21174,20471,20554.0,533,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,596530,599218,598635,598791,599019,598825,598864,597987,598387,598843,599037,598760.6,534,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",26066,30126,30214,30053,29890,30783,30032,30188,30128,30061,30017,30149.2,535,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733550,733256,734622,734461,733243,733556,732321,738009,736318,733644,734774,734420.4,536,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9831,12441,12662,12567,12809,12665,12846,12833,12421,12818,12521,12658.3,537,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14888,16861,17382,17804,16898,17777,16901,17253,17407,16952,17238,17247.3,538,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11297,14670,14676,14960,14743,14999,14915,16139,14537,14735,15095,14946.9,539,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23685,24997,25995,25597,25143,25782,24998,25395,25069,25297,25190,25346.3,540,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3306,4013,4651,4657,4067,4637,3990,4050,3999,4050,4041,4215.5,541,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3423,4079,4727,4761,4153,4745,4311,4111,4213,4142,4087,4332.9,542,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14411,17698,18613,18907,17725,18906,17446,18460,17790,17969,18310,18182.4,543,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14352,16046,16472,16467,16216,16487,16851,15837,15957,16328,16046,16270.7,544,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12720,14576,15172,14956,14422,14963,14260,14363,14536,14641,14533,14642.2,545,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283789,282299,284106,283289,283025,283524,283009,282987,284306,283893,282406,283284.4,546,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282492,283119,282584,283027,283106,282961,282275,283418,283563,284760,284286,283309.9,547,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283777,282293,282533,282242,282946,282515,282798,284137,282739,283404,282398,282800.5,548,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14557,17512,17383,17484,17518,17733,17395,16977,17067,17247,17091,17340.7,549,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15437,16440,16977,17102,16261,17339,16909,17152,16348,16566,16350,16744.4,550,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13035,17511,17846,18731,17800,17798,18435,17738,17255,17431,17361,17790.6,551,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13598,17484,18340,17554,17604,17924,17403,17544,17354,17244,17924,17637.5,552,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13943,16291,16487,17498,16070,16701,15971,16181,15867,16049,15835,16295.0,553,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14028,15909,16525,16288,15901,16191,16018,15866,15978,15880,16171,16072.7,554,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29747,30495,30431,30318,30437,30201,30264,30200,30680,30309,30571,30390.6,555,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11379,14407,14606,14812,15046,14654,14641,14718,14392,15397,14551,14722.4,556,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19997,21463,21618,21451,21806,21580,21631,21410,21736,21585,21419,21569.9,557,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25435,27440,28189,28015,27457,27843,27539,27616,27588,27813,27652,27715.2,558,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25199,29859,30863,30768,30499,30878,30489,30630,30748,30190,30277,30520.1,559,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23280,26027,26328,26652,25890,26764,26096,26047,25872,26277,25985,26193.8,560,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26661,28846,28653,28509,28683,28767,28211,28472,28270,28648,28497,28555.6,561,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12588,14529,14218,14642,14405,14326,14478,14408,15074,14399,14540,14501.9,562,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282172,282858,283405,282944,283228,285523,282309,281469,283806,282541,283856,283193.9,563,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9929,13182,13421,12876,13146,13072,13162,12895,12846,13327,13283,13121.0,564,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14713,17273,17414,17604,16951,17194,16954,16740,16987,16945,16843,17090.5,565,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11452,15415,14901,15020,14717,14958,14117,15475,14736,15002,14586,14892.7,566,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24273,25036,25290,25217,24912,25601,24971,24952,24892,24878,24963,25071.2,567,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3276,4018,4644,4631,4053,4685,3992,4160,3986,4018,4064,4225.1,568,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3377,4056,4702,4724,4081,4700,4186,4128,4159,4159,4056,4295.1,569,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14084,17945,18462,18776,18009,18527,17513,17909,17678,17931,18405,18115.5,570,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14379,15980,16387,16259,15771,16157,16170,15985,15926,15905,15882,16042.2,571,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12673,14288,14900,14852,14680,15131,14844,14321,14388,14841,14396,14664.1,572,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598732,597455,598774,598886,599515,598947,599229,598739,598140,598297,598540,598652.2,573,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16051,21473,21181,19923,20709,20844,20583,20685,20404,20856,20731,20738.9,574,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599149,599443,598682,600186,598692,598022,598969,599492,598247,598774,598926,598943.3,575,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25854,30113,30118,30282,29833,30110,30070,30402,30371,30372,30259,30193.0,576,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,734530,739736,736653,736248,735198,738206,737357,733635,740115,741512,736718,737537.8,577,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10979,12948,12706,12863,12801,12962,12561,13053,12862,12739,12741,12823.6,578,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14869,17136,18056,17519,17220,17890,16809,17515,16956,16830,16880,17281.1,579,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11572,14304,16265,14832,15203,15279,14883,14759,14306,14566,15361,14975.8,580,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23879,25217,26156,25279,25072,25292,24974,25173,25093,25123,25403,25278.2,581,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3254,3994,4666,4635,4031,4623,3970,4030,4034,4039,4024,4204.6,582,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3436,4048,4676,4678,4107,4701,4144,4081,4146,4050,4010,4264.1,583,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14263,17616,18147,18712,17353,18272,17278,17567,17314,17584,17736,17757.9,584,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14148,16040,16543,16208,16152,16493,15958,15991,16625,16078,16396,16248.4,585,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12638,14542,14989,14770,14388,15160,14314,14423,14524,14631,14399,14614.0,586,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282641,282388,283427,283560,282961,283498,282831,283782,282607,282497,282417,282996.8,587,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281337,282595,283424,283243,283894,283765,283200,283981,283095,283656,282851,283370.4,588,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282580,283989,283172,282771,282666,282250,283038,282854,282467,282756,282005,282796.8,589,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14859,17280,17352,17441,16780,17868,17050,17016,16852,16821,17025,17148.5,590,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14566,16843,17320,17312,17270,17491,17034,16952,16821,16850,16737,17063.0,591,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12717,17351,17493,17399,17356,18076,17501,17920,17597,17596,17626,17591.5,592,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12494,17271,17802,17430,17502,17302,18003,17496,17917,17395,17545,17566.3,593,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13761,16044,16676,16355,15912,16554,16325,15907,16001,16191,15968,16193.3,594,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13792,15744,16458,16413,16029,16319,16060,15669,15834,15850,15959,16033.5,595,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29457,30555,30261,30417,30135,30270,30812,30464,30110,30416,30116,30355.6,596,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11413,15311,15118,15230,14868,15261,15211,15158,14587,15473,15134,15135.1,597,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",20189,22389,22495,22204,22657,22227,22204,22141,22252,22262,22171,22300.2,598,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25092,27731,28304,27889,27468,27904,27527,27371,27080,27537,27696,27650.7,599,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25432,29744,30043,30988,30943,30494,30606,30400,30344,30183,30770,30451.5,600,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23518,25964,26512,26371,25865,26269,25737,26118,26548,25987,26115,26148.6,601,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,27102,28816,28904,28713,28865,28746,28567,28686,28684,28723,28548,28725.2,602,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12581,14553,14264,14681,14458,14329,14558,14543,14395,14639,14584,14500.4,603,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281797,281376,282450,282108,283378,283030,283580,283704,282471,283396,281981,282747.4,604,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9959,13056,12954,13067,12971,12736,12923,13051,12824,13161,13749,13049.2,605,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14904,16767,17464,17452,17159,17388,16938,16739,17160,17078,16879,17102.4,606,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",12046,15280,15691,14632,15383,15249,15176,14679,14348,14687,14489,14961.4,607,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23945,25341,25554,25472,25318,25918,24866,25566,25509,25330,25506,25438.0,608,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3331,3967,4618,4628,4053,4600,4020,4029,4041,3952,3951,4185.9,609,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3402,4000,4644,4676,4082,4745,4178,4040,4102,4029,4007,4250.3,610,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14154,17498,18248,18453,17767,18606,17671,17721,17771,18265,17932,17993.2,611,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13789,16053,16400,16455,15916,16213,16064,16125,15953,15900,15794,16087.3,612,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12363,14187,14826,14676,14388,14803,14474,14206,14394,14383,14194,14453.1,613,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598850,597756,598549,597812,598483,599609,598346,597098,597992,597816,597569,598103.0,614,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16037,21100,20353,21278,20567,20972,20247,20647,20397,20871,20159,20659.1,615,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597490,598693,597784,598289,599280,598395,598320,598165,599197,597896,598202,598422.1,616,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25902,30074,30249,30257,30375,30314,30074,30740,30329,30265,30014,30269.1,617,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735551,732358,733956,733343,733371,739506,735666,733819,735526,737694,740184,735542.3,618,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9935,12743,12660,12619,12841,12661,12541,12576,12638,12666,12619,12656.4,619,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15238,16454,17291,16909,16708,17106,16745,16382,16325,16484,16581,16698.5,620,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11632,14464,14888,15131,14772,15126,14645,14198,15691,14470,14585,14797.0,621,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23739,25460,25706,25508,25086,25829,25197,25328,25224,25222,25074,25363.4,622,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3302,3942,4598,4545,3986,4579,3919,3958,3883,3974,3913,4129.7,623,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3425,4021,4648,4662,4077,4730,4126,4330,4178,4042,4019,4283.3,624,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14032,17386,18114,18276,17919,18064,17903,17508,17249,17912,17843,17817.4,625,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14262,16296,16733,16520,16037,16531,16048,16124,15946,15936,16166,16233.7,626,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12508,14579,14811,15057,14228,14814,14638,14326,14414,14311,14271,14544.9,627,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284523,284437,284994,283871,282600,282972,283502,284224,283301,282397,282669,283496.7,628,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282950,286094,284483,284288,282160,282677,283693,283404,284107,284188,283605,283869.9,629,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282305,282347,282518,282978,282825,282434,282287,282090,283438,282889,282594,282640.0,630,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14565,17049,17992,17928,16867,17612,17152,17423,17015,17090,17366,17349.4,631,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14889,17182,17353,17518,16906,17735,16936,16705,17040,16871,16763,17100.9,632,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12645,17346,18182,17253,17993,17933,17828,17247,17250,17160,17430,17562.2,633,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12632,17512,17479,17961,17457,18042,18247,17698,17865,17626,18068,17795.5,634,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13850,16104,16248,16110,15769,16172,15840,15684,15891,15688,15819,15932.5,635,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13935,16134,16412,16388,15660,16542,15830,15754,15768,16535,15946,16096.9,636,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29563,30817,30294,30459,30327,30332,30224,30303,30262,30608,30228,30385.4,637,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11833,14289,14509,14551,15402,14410,14630,14625,14451,14211,14649,14572.7,638,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19739,21530,21806,21664,21707,21726,21750,21874,21610,21836,21912,21741.5,639,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25508,27411,28037,28106,27413,28286,27253,27291,27602,27663,27406,27646.8,640,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25621,30107,30489,30655,30306,29881,31203,29893,30459,31282,30161,30443.6,641,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23221,26081,26690,26457,26058,26667,26198,25947,26170,26224,26070,26256.2,642,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,27179,28464,28293,28740,28535,28568,28534,28900,28422,29738,28257,28645.1,643,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12749,14540,14777,14231,14463,15212,14549,14368,14553,14350,14439,14548.2,644,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282153,285763,283626,283588,283797,284674,283147,283363,283324,283882,285944,284110.8,645,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10601,12441,12848,12629,12490,12648,12609,12702,12500,13379,12650,12689.6,646,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14625,17438,17788,17265,17126,17673,17547,17227,16935,16774,17007,17278.0,647,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11451,14809,14807,14937,14987,15754,14355,14721,14259,13863,14444,14693.6,648,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23923,24998,25851,25544,25010,26130,25601,25170,25161,25323,25219,25400.7,649,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3306,3974,4571,4598,4024,4582,3953,3971,3935,3991,4061,4166.0,650,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3432,4057,4756,4707,4095,4723,4169,4105,4180,4175,4039,4300.6,651,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14230,17913,18729,18644,18409,18449,17936,18200,18119,18356,18194,18294.9,652,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14047,15777,16243,16308,15939,16319,16180,15932,16093,15928,15757,16047.6,653,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12723,14371,15480,14948,14405,15048,14277,14492,14340,14557,14061,14597.9,654,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599155,598471,597568,597964,600597,599689,597936,598434,600754,598604,598837,598885.4,655,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16376,20498,20068,20023,20794,20045,20132,20769,20586,20326,20227,20346.8,656,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598844,597551,598260,598535,599045,598705,598710,598712,598441,599120,598764,598584.3,657,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25844,30488,30265,29880,30641,30052,30225,30381,30164,29888,29999,30198.3,658,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735163,737213,733811,732351,733183,735433,737830,732731,734729,732942,737711,734793.4,659,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9788,12646,12751,12481,12557,12576,12858,12787,12799,12531,12730,12671.6,660,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14885,16924,17358,17499,17136,17798,16952,17338,16940,17105,16728,17177.8,661,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11710,14136,15396,14312,14616,14814,14967,14333,14552,14701,14155,14598.2,662,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23744,25321,25882,25631,25539,25585,25368,25120,25119,25262,24937,25376.4,663,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3309,3984,4632,4611,4196,4638,3958,4148,3951,4047,3993,4215.8,664,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3408,4046,4716,4696,4119,4727,4187,4148,4155,4099,4070,4296.3,665,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14038,18568,19349,19598,19128,19384,18465,18968,18159,17992,17697,18730.8,666,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14091,15822,16838,16305,16173,16768,16082,16058,16030,16180,16194,16245.0,667,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12561,14496,14994,14948,14311,14825,14293,15175,14143,14395,14385,14596.5,668,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283469,283538,282186,283214,282932,282338,282506,282930,282698,282828,284257,282942.7,669,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282366,282516,282428,282088,282650,282257,283766,282544,282267,283532,283717,282776.5,670,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282720,283560,283865,282935,283799,283106,283129,286144,282961,282019,282776,283429.4,671,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14408,17091,17559,17162,17104,17293,17515,17000,17070,17183,17131,17210.8,672,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15131,16954,17535,16799,16215,16916,16682,16704,16621,16971,16699,16809.6,673,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13074,17549,17430,17683,17954,17357,17646,17379,17573,17418,17264,17525.3,674,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12550,17824,18420,17389,17516,18329,18068,17330,17659,17712,17335,17758.2,675,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14103,16000,16470,16338,16506,17026,16006,15895,16494,16173,15990,16289.8,676,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13859,16044,16402,16235,16069,16872,16232,16159,16064,16212,15740,16202.9,677,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29464,30346,30442,30259,30680,30224,30295,30357,30346,30610,30295,30385.4,678,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11266,14496,15016,14141,14439,15299,14336,15067,14401,14578,14854,14662.7,679,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19942,21465,21664,21676,21564,21626,21619,21661,21388,21820,21577,21606.0,680,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25391,27575,27882,27676,27321,27875,27492,27374,27736,27856,27628,27641.5,681,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26156,30687,30401,30629,29866,30267,30229,30474,29972,30320,30328,30317.3,682,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23190,25850,26609,26395,25951,26380,26281,25837,25949,26361,25745,26135.8,683,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26740,28831,28721,28861,28639,28614,28644,28672,28652,29019,28828,28748.1,684,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12746,14642,14557,14398,14433,14508,14568,14709,14578,14707,14449,14554.9,685,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283278,282648,283716,283687,283764,282813,284314,283533,282763,283068,283451,283375.7,686,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9921,12816,12934,13604,12718,13508,13504,12852,12773,12724,13198,13063.1,687,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14523,16666,17754,17375,16472,17373,16429,16670,16367,16704,16355,16816.5,688,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11336,15003,15553,16437,15072,15863,14489,14528,15427,15413,14724,15250.9,689,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23977,25015,25601,25569,25576,25540,25224,25278,25424,25686,25034,25394.7,690,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3291,3991,4625,4634,4054,4681,3985,4040,4021,4033,3996,4206.0,691,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3369,4049,4733,4718,4069,4685,4174,4063,4146,4063,4128,4282.8,692,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13753,17726,19174,19127,18308,18587,18378,18232,18004,18040,18322,18389.8,693,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13980,16095,16554,16444,16028,16195,15802,16304,15938,16023,15934,16131.7,694,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12618,14364,15147,14798,14886,14965,14620,14243,14281,14509,14395,14620.8,695,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598431,597862,598776,598139,598537,598298,598449,597981,598603,598430,598614,598368.9,696,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16374,20002,19686,20359,20394,19813,19976,20247,20623,20284,20388,20177.2,697,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598320,598231,599018,598668,597858,598163,597950,598179,599051,598260,598572,598395.0,698,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",27491,30301,30240,30096,30418,30194,29840,30245,30162,30222,29872,30159.0,699,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,735593,733274,735684,737863,730995,734772,732197,735691,731780,734612,734367,734123.5,700,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9851,12537,12523,12744,12762,12631,12594,12617,12439,12559,12661,12606.7,701,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14637,16519,17011,17550,16671,16983,16731,17307,16525,16556,16630,16848.3,702,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11559,14422,15009,16207,15624,15773,14491,15838,15211,15229,14591,15239.5,703,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24019,24969,25424,25514,25018,25485,25041,24977,24774,25080,25040,25132.2,704,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3281,4012,4648,4652,4028,4657,3951,4037,3973,4040,3998,4199.6,705,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3358,4183,4848,4718,4095,4733,4211,4091,4189,4080,4062,4321.0,706,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14049,18394,18801,19617,18907,24470,17563,18353,19040,18805,18749,19269.9,707,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14052,15923,16524,16462,15985,16614,15942,15935,16132,16391,15818,16172.6,708,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12577,14244,14981,14914,14444,14940,15165,14357,14364,14590,14538,14653.7,709,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281891,283489,283571,283471,282497,283352,282605,282335,282738,283186,283370,283061.4,710,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281859,286153,282126,286044,283147,283954,283273,283536,282849,283182,282046,283631.0,711,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281842,282439,283071,282633,282912,282503,282855,284021,282816,282438,284213,282990.1,712,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15140,16983,18019,17459,17296,17742,16746,17220,17236,17220,17065,17298.6,713,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14398,16868,17081,17199,16368,17558,16167,16448,16691,16525,16433,16733.8,714,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12717,17945,17455,17596,17845,17803,17601,17551,17271,17351,18080,17649.8,715,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12890,17888,18005,18104,17636,18499,17678,17688,18110,17921,17934,17946.3,716,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13890,15908,16359,16343,15866,16239,15937,16161,16055,15802,16093,16076.3,717,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13921,15773,16449,16194,15828,16532,15875,15801,15837,16115,15670,16007.4,718,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29890,30297,30275,30355,30181,30120,30696,30640,30470,30239,30309,30358.2,719,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11396,14655,14593,14357,14358,15241,14529,14541,15164,14891,14681,14701.0,720,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19815,21502,21468,21597,21699,21626,21527,21562,21764,21779,21564,21608.8,721,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25206,27259,27835,27994,27494,28025,27817,27599,27410,27584,27583,27660.0,722,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25896,31188,29915,29915,30819,29819,30303,30056,30526,30504,30170,30321.5,723,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23299,26247,26301,26667,25810,26678,26351,25962,25959,25824,25863,26166.2,724,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26752,28502,28597,29085,28783,28509,28434,28639,28871,28773,29000,28719.3,725,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12607,14585,14450,14645,14278,14326,14475,14321,14329,14516,14664,14458.9,726,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281908,283722,283669,282338,282706,281900,282212,282380,282041,284436,283497,282890.1,727,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9878,12810,12607,12810,12654,13301,12904,13014,12601,12897,12785,12838.3,728,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14551,16515,17418,17483,16885,17409,16905,17315,16857,17096,17209,17109.2,729,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11350,15198,15324,15598,14659,16044,14677,14999,14612,14449,14685,15024.5,730,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24292,24892,25762,25356,25561,25938,25378,25084,25309,25093,25331,25370.4,731,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3275,3974,4656,4612,4056,4666,3963,4031,3970,3997,4070,4199.5,732,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3372,4028,4663,4685,4115,4681,4169,4024,4143,4057,4034,4259.9,733,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13482,17692,18142,18731,17827,18364,17578,18035,17672,18090,18600,18073.1,734,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14069,16306,16507,16606,16227,16831,16277,16045,15959,16030,16044,16283.2,735,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12490,14366,14829,14982,14329,14988,14435,14460,14403,14470,14417,14567.9,736,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597879,598044,598149,597711,597943,597839,598427,599044,597116,598329,597122,597972.4,737,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15651,20449,21223,20015,19749,20554,20315,20480,20143,20460,20028,20341.6,738,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597453,598046,597132,597901,597800,598357,600763,598186,598758,597898,598602,598344.3,739,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25828,30294,30124,30043,30307,30362,30072,29946,29949,30512,30241,30185.0,740,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733572,732683,733282,735155,735351,737002,736404,736268,737935,735558,734157,735379.5,741,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9839,12735,12825,12735,12594,12823,12788,12981,12667,12664,12803,12761.5,742,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14771,17001,17315,17641,16907,17450,17266,17562,16944,17141,17145,17237.2,743,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11662,14486,15170,14848,14476,14886,14151,15170,14681,14385,14748,14700.1,744,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23924,25153,25779,25636,24810,25540,25037,25001,24831,25090,25013,25189.0,745,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3254,3931,4619,4590,4003,4606,3975,3995,3926,4003,3962,4161.0,746,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3378,4015,4668,4662,4068,4877,4146,4069,4147,4024,4009,4268.5,747,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14281,17693,18249,18420,17932,18376,17527,17411,17628,17772,17843,17885.1,748,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14182,15776,17034,16234,15960,16498,15888,16160,16254,15916,15840,16156.0,749,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12611,14216,15043,14823,14439,14801,14472,14489,14463,14229,14189,14516.4,750,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282332,283292,283048,282976,283023,285213,284268,284007,283053,283060,282300,283424.0,751,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284046,282883,283216,282226,283942,283657,283629,283142,282954,286081,283330,283506.0,752,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282429,285090,283205,282336,281365,283126,281749,283855,283486,283098,283850,283116.0,753,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14537,16815,17361,17945,16937,17412,17075,17158,16837,17056,17394,17199.0,754,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14564,16607,16992,17004,16616,16951,16946,16502,16918,16582,17026,16814.4,755,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12635,17330,17304,17914,17774,18091,17766,17264,17816,17267,17234,17576.0,756,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12714,18075,17639,17968,18131,17649,17679,17907,17686,17772,17622,17812.8,757,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13853,16012,16363,16260,16237,16037,16030,15749,15928,16352,15800,16076.8,758,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13843,15939,16326,16568,16206,16718,15893,16244,15936,16223,15783,16183.6,759,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29325,30594,30235,30276,30623,30413,30362,30428,30267,30230,30277,30370.5,760,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11540,14373,15920,14682,14417,14987,15602,14688,14717,14428,14666,14848.0,761,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19845,21750,21750,21730,21994,21666,21698,21912,21743,21918,21614,21777.5,762,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25623,27543,27884,28095,27828,27813,27580,27542,27770,27509,27512,27707.6,763,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26093,30740,30288,30247,30981,31610,30847,30350,29965,30101,31174,30630.3,764,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23259,26132,26275,26358,25678,26445,26329,26156,26147,25970,26614,26210.4,765,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26843,28691,28552,28637,28674,28547,28815,28648,28761,28474,28458,28625.7,766,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12578,14601,14399,14346,14601,14848,14584,14598,14536,14520,15014,14604.7,767,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283149,284634,282492,282496,281998,283695,282386,284638,282978,283447,281457,283022.1,768,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9826,12940,12592,13280,13077,13025,12552,12736,12861,12372,12844,12827.9,769,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14633,17047,17192,17476,16790,17465,17090,17207,16863,17158,16937,17122.5,770,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11777,14535,15858,15320,14990,15857,15321,15110,14262,14593,15165,15101.1,771,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24102,25190,25232,26045,25103,26238,25199,25032,25331,25007,25430,25380.7,772,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3294,4034,4571,4584,4018,4597,3934,4003,3943,3958,3925,4156.7,773,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3424,3959,4643,4625,4065,4681,4150,4062,4135,4041,4023,4238.4,774,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13937,17174,18007,18169,17235,17753,17232,17416,17755,17433,17496,17567.0,775,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14286,15620,16302,16471,15876,16463,16107,15927,16183,16285,16064,16129.8,776,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12424,14684,15327,15188,14417,15276,14406,14440,14552,14194,14176,14666.0,777,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598822,599256,599350,598021,598403,598711,598639,598987,598814,597521,598781,598648.3,778,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16101,20829,20652,20515,20816,20588,20921,20711,21524,21371,20907,20883.4,779,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598502,598729,598612,598642,597965,598174,599213,598324,598650,598349,598747,598540.5,780,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25861,30050,30043,30311,30452,30458,30189,30472,30186,30282,30449,30289.2,781,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,732969,738920,741364,732474,734832,731449,735788,733523,735981,734809,740321,735946.1,782,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10631,12756,12599,12898,12677,12679,12506,13028,12794,12944,12759,12764.0,783,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14946,17189,17540,17664,16974,17814,17118,17584,17390,17297,17166,17373.6,784,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11771,14936,15261,14880,14440,15798,15327,14423,14516,15577,15179,15033.7,785,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23838,25191,25583,25850,24981,25719,24900,25300,25174,24884,25045,25262.7,786,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3335,3928,4546,4566,3957,4562,3928,3987,3874,3984,3927,4125.9,787,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3447,4024,4789,4693,4094,4673,4171,4078,4158,4080,4023,4278.3,788,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13661,17328,18005,18387,17973,18244,17454,17466,17666,17458,17398,17737.9,789,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14351,15991,16320,16393,16264,16456,16433,15950,16231,16083,16206,16232.7,790,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12744,14621,15103,15120,14778,15062,14403,14318,15060,14228,14204,14689.7,791,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,285098,282621,283070,283670,283991,282268,282871,282798,282470,283411,282981,283015.1,792,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282286,282709,282075,281754,282553,282148,282913,281662,282502,283705,282520,282454.1,793,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282590,283715,282266,283300,282449,282636,283063,282013,283381,282955,282880,282865.8,794,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14624,17383,17232,17918,16907,17423,17042,17014,17472,17345,17043,17277.9,795,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14607,16778,17303,17708,16850,17572,17211,16953,16831,17055,17470,17173.1,796,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12701,17910,17623,17951,17602,17689,18082,17524,18229,17955,18039,17860.4,797,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12867,17319,17595,17524,17718,17491,17520,17641,17419,17469,17650,17534.6,798,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13902,16660,16648,16615,15904,16226,16069,16136,16136,15710,15802,16190.6,799,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14036,15808,16264,16493,15945,16273,16080,15927,16123,15687,15675,16027.5,800,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29619,30423,30414,30615,30451,30284,30543,30504,30502,30616,30188,30454.0,801,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11261,14602,15427,15210,15318,15238,15217,15086,14804,15208,14686,15079.6,802,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19925,22246,21942,22039,22060,21950,22197,21958,22122,21861,22158,22053.3,803,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25287,27406,28483,28307,27649,28499,27439,27646,27678,27189,27647,27794.3,804,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26510,29869,30370,30234,30770,30313,30678,30599,30273,29926,30679,30371.1,805,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23407,26050,26336,26598,25940,26678,25947,26166,26174,26132,26045,26206.6,806,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26755,29103,28515,28784,28495,28804,28546,28636,28678,28504,28831,28689.6,807,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12934,14640,14728,15421,14367,14339,14404,14765,14450,14629,14359,14610.2,808,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282416,284258,282119,283609,283849,283049,282939,283017,282897,284140,282335,283221.2,809,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9984,12798,12484,12796,13384,12546,13188,12528,13190,13041,12395,12835.0,810,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14779,16820,17314,17369,16984,17568,17120,17004,17215,17036,16800,17123.0,811,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11573,14556,15088,16079,14553,15018,14751,14191,14508,14551,14444,14773.9,812,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23887,25277,25479,25380,25149,25843,25122,25448,24959,25366,25183,25320.6,813,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3334,3973,4597,4596,4017,4600,3927,4004,3909,4056,4008,4168.7,814,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3452,4054,4865,4689,4180,4752,4215,4222,4234,4092,4036,4333.9,815,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14392,18086,18771,18529,18136,18954,17861,17754,18095,18270,18293,18274.9,816,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14073,16092,16595,16253,16087,16582,15963,15802,15997,15993,16096,16146.0,817,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12560,14284,14757,15420,14737,14921,14498,14431,14455,14275,15296,14707.4,818,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597787,598871,598027,598312,598047,599113,598124,597869,598330,598881,598845,598441.9,819,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16437,21237,20970,21180,21493,20081,21180,20669,21675,20640,20775,20990.0,820,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598021,597863,599059,597980,598100,598489,598353,597709,598260,599147,599552,598451.2,821,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25840,30057,30209,30095,30286,30178,30200,30216,29883,30277,30082,30148.3,822,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,738618,732869,732926,735792,735862,735998,735518,736910,733483,737546,731405,734830.9,823,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10066,12833,12769,12740,12502,12658,12553,12797,12593,12693,12562,12670.0,824,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14941,16796,16997,17526,16754,16827,16762,16819,16928,17029,16365,16880.3,825,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11404,14367,15797,14927,14259,15094,15048,14649,14436,14546,14989,14811.2,826,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23701,25259,25689,25684,25268,25871,25158,24801,24908,25259,25062,25295.9,827,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3324,4023,4656,4623,4058,4672,4020,4058,4005,4033,4053,4220.1,828,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3387,4094,4710,4710,4115,4857,4222,4127,4215,4149,4067,4326.6,829,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14521,17961,18505,19052,17719,19394,17912,18011,17521,17773,18573,18242.1,830,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14206,16189,16386,16514,16189,16749,15939,16247,16245,15935,16169,16256.2,831,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12665,14404,15036,15052,14378,15055,14486,14630,14377,14298,14404,14612.0,832,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282584,283128,283812,284248,281943,285959,282837,285856,282980,283141,284023,283792.7,833,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282086,282066,282776,282422,282479,283459,283031,282727,283223,282607,282564,282735.4,834,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282069,283482,283437,283417,282949,282956,283078,283784,283568,282995,283520,283318.6,835,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14690,16979,17698,18003,17095,17674,17423,17166,17535,17276,17617,17446.6,836,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14571,16736,17608,17615,17839,17936,16983,16923,17124,17103,17205,17307.2,837,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12926,17357,17260,17376,17676,17572,17385,17753,17154,17462,17139,17413.4,838,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12553,17133,17250,17092,17221,17487,17382,17797,18193,17507,17499,17456.1,839,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13762,15748,16303,16350,16012,16216,15998,15930,15928,16016,16034,16053.5,840,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13985,15799,16125,16569,15742,16316,15871,16076,16036,15765,15712,16001.1,841,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29708,30267,30330,30330,30112,30077,30657,30315,30126,30335,30255,30280.4,842,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11214,15376,14690,15044,14539,15432,15200,14444,15851,14556,15225,15035.7,843,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19799,21423,21817,21972,21756,21916,22014,21651,21810,21820,21793,21797.2,844,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25514,27068,28491,28042,27821,28374,27605,27241,27651,27859,27796,27794.8,845,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26126,30457,30776,30115,29966,30590,30245,30102,29602,31315,30849,30401.7,846,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23058,26502,26622,26350,26146,26324,26080,25887,25924,26036,26237,26210.8,847,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26963,28697,28590,28867,28668,39584,28388,28349,28698,28573,28529,28595.44444,848,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12650,14462,14745,14633,14512,14871,14309,14411,14735,14615,14427,14572.0,849,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281890,283599,282577,283746,283221,283271,283204,283249,282286,283679,285771,283460.3,850,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9951,13181,13159,13054,12929,12950,13047,12609,12761,13490,13219,13039.9,851,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14801,16908,17577,17575,17374,17839,17275,17039,17136,16886,17188,17279.7,852,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",12229,14162,15025,15593,14778,15365,14827,14551,14707,14814,14526,14834.8,853,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24068,24889,25405,25408,25079,25810,24990,24878,25258,24959,25016,25169.2,854,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3291,4015,4641,4650,4030,4638,4010,4062,3983,4042,4000,4207.1,855,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3394,4101,4757,4731,4104,4743,4195,4150,4206,4101,4085,4317.3,856,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13803,18347,18882,19053,18485,18989,18687,18859,18321,18239,18385,18624.7,857,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13978,15910,16384,16600,16075,16460,15883,15889,15949,15965,16216,16133.1,858,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12933,14363,14925,14793,14205,14875,14323,14410,14615,14337,14319,14516.5,859,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597983,597484,597734,598521,598894,599316,598974,598762,597713,598257,597917,598357.2,860,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15889,20032,20705,20898,21078,20480,20613,20249,19890,20438,21194,20557.7,861,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598238,598090,599562,598417,598855,597807,598779,599957,599402,598016,598644,598752.9,862,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25965,30346,30370,30514,30344,30274,30220,30752,30437,30219,30392,30386.8,863,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,734401,732913,731261,734516,737419,731033,735965,736262,733367,735480,735047,734326.3,864,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9856,12706,12786,12844,12789,12865,13016,13306,12587,12762,12756,12841.7,865,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14699,16796,17639,18005,17529,17959,16861,17459,17079,16970,17479,17377.6,866,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11544,15116,15090,15105,14096,15897,15022,14302,14493,14296,14439,14785.6,867,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23762,25037,25575,26002,25126,25775,25565,24925,24966,24910,24926,25280.7,868,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3291,4022,4654,4649,4117,4679,4034,4100,3976,4107,4021,4235.9,869,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3365,4186,4757,4760,4170,4808,4208,4109,4194,4119,4094,4340.5,870,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13708,18112,19200,19005,18365,19088,18118,18321,18536,18775,18188,18570.8,871,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14161,15814,16289,16395,16693,16596,15997,16384,15904,15796,16387,16225.5,872,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12601,14548,14932,14808,15334,14832,14450,14590,14606,14307,14591,14699.8,873,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281829,284254,285704,284628,285477,282616,283038,282892,283821,281593,283871,283789.4,874,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284036,283928,283726,283546,283383,284205,283395,283017,282616,283010,283896,283472.2,875,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282513,282367,282011,282209,281977,283663,282620,284061,283035,283423,282862,282822.8,876,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14515,17007,33458,17228,17035,17689,16851,17003,17265,16961,17023,17118.0,877,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14858,16687,17004,16977,16411,17218,16587,16616,16593,16712,16868,16767.3,878,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12735,17290,17903,17291,17328,17798,17815,17880,17575,17550,17374,17580.4,879,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12918,17683,17482,17892,17707,17875,17593,17785,19004,17864,17551,17843.6,880,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13927,15948,16244,16264,16039,16944,15885,16176,15882,15889,15700,16097.1,881,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13924,16248,16423,16322,16143,16299,15990,16079,15917,16161,15916,16149.8,882,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29395,30267,30587,30230,30524,30565,30474,30300,30144,30459,30329,30387.9,883,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11399,15119,14486,14385,14599,14816,14499,14379,14468,14581,14556,14588.8,884,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19991,21681,21757,21695,21749,21803,22046,21992,21737,21796,21784,21804.0,885,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25211,27685,27643,28058,27797,28070,27300,27417,27516,27411,27781,27667.8,886,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25553,31130,30749,29866,30017,30462,30097,30477,30356,30660,30198,30401.2,887,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23199,26029,26495,26578,26080,26559,25992,26089,25892,25991,26026,26173.1,888,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26946,28507,28612,28649,28501,28592,28607,28727,28382,28519,28807,28590.3,889,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12639,14525,14540,14335,14610,14581,14380,14694,14849,14664,14800,14597.8,890,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282018,282167,283730,283315,283255,285859,283906,282784,283871,283715,282225,283482.7,891,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10008,13225,12439,13607,12523,13312,12431,13218,13521,12496,13485,13025.7,892,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14595,16366,16934,17212,16479,17140,16310,16551,16468,16720,16820,16700.0,893,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11474,14929,15643,14882,15190,15844,14455,14500,14568,14646,15045,14970.2,894,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23889,25368,25350,25388,25058,25551,25451,25147,25187,24931,25157,25258.8,895,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3261,4015,4757,4683,4060,4649,4015,4068,3958,4038,4012,4225.5,896,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3366,4031,4733,4681,4120,4734,4225,4100,4191,4088,4083,4298.6,897,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13997,18014,18938,19119,18282,18607,17986,18544,18227,18562,18712,18499.1,898,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14116,16527,16399,16381,15698,16303,15955,16146,15904,15599,16069,16098.1,899,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12684,14611,15625,15072,14483,14791,14296,14612,14323,14377,14343,14653.3,900,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598038,597573,598358,598805,599491,598221,597667,598094,598744,598389,597853,598319.5,901,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15922,20019,20026,20592,20204,20266,20468,21212,20875,21018,20691,20537.1,902,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598452,597874,598492,598531,598321,598438,598706,598001,597918,598059,599092,598343.2,903,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",27103,30323,30182,30519,30174,30421,30250,30575,30177,30549,30727,30389.7,904,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,737604,737642,736788,734665,733861,734970,735416,735051,732296,734428,734265,734938.2,905,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10638,12584,12476,12580,12283,12329,12292,12344,12566,12450,12563,12446.7,906,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15113,16938,17209,17111,17066,16954,17051,16550,16769,16403,17194,16924.5,907,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11531,14087,14985,14698,14986,15268,14487,14704,14564,14627,14696,14710.2,908,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23897,25161,25557,25837,25148,25498,25165,25620,25177,25161,25039,25336.3,909,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3262,4119,4669,4613,4079,4665,4017,4066,4047,4022,3970,4226.7,910,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3414,4011,4682,4681,4056,4727,4154,4050,4134,4089,4067,4265.1,911,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14158,17895,18201,19037,18061,19006,17829,18871,17740,18426,17932,18299.8,912,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14241,16072,16499,16557,15952,16158,15947,15757,16092,17057,16279,16237.0,913,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12650,14331,15008,15189,14453,14960,14849,14408,14626,14274,14334,14643.2,914,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281816,282823,283159,282830,281939,283107,282954,282192,282782,283503,282337,282762.6,915,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282476,284243,283572,283602,283178,282678,282631,283148,282431,283254,282961,283169.8,916,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281806,282739,282779,282970,284403,282865,285338,282532,283131,283349,281664,283177.0,917,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14980,17030,17490,17504,17445,18148,17238,17259,17057,16943,17256,17337.0,918,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14342,16598,17266,16950,16510,16919,16664,16416,16350,16266,16820,16675.9,919,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13366,17246,17506,17810,17696,17624,17280,17310,17744,17427,17692,17533.5,920,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12409,17794,17363,17663,17371,17547,17757,17760,17646,17436,17344,17568.1,921,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14038,16129,16525,16546,16155,16261,16485,16180,15856,16096,16073,16230.6,922,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13977,15629,16473,16335,16148,16420,15886,16513,16193,15959,16301,16185.7,923,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29679,30154,30351,30628,30727,30404,30334,30832,30822,30761,30508,30552.1,924,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11269,14671,14551,15701,15414,15297,15412,15504,15652,15144,14537,15188.3,925,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19913,21962,22081,21662,21808,21837,21920,21656,22008,21657,21652,21824.3,926,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25304,27725,28466,27957,27373,28418,27602,27673,27398,27657,27483,27775.2,927,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26238,30426,30734,30378,30111,30019,30192,29986,31187,30614,30358,30400.5,928,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23021,26001,26573,26362,26490,26573,26136,26158,26078,25694,25990,26205.5,929,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,27095,28576,28968,28497,29044,29091,28689,28789,28785,28709,28862,28801.0,930,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12553,14593,14449,14461,14636,14298,14420,14490,14505,14533,14606,14499.1,931,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284372,282190,282124,282626,282983,283105,283203,281972,282780,286039,282961,282998.3,932,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9869,13211,12952,13050,13266,12725,12782,12980,12603,13196,13191,12995.6,933,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14579,17166,17813,17825,17322,17596,17031,16860,17119,17124,16899,17275.5,934,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11432,15116,15464,15413,14398,15857,14541,14927,15088,15058,15122,15098.4,935,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24287,25257,25421,25412,25086,25319,25050,24897,24917,24920,24752,25103.1,936,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3300,3993,4585,4622,4007,4617,3929,4019,3946,3988,3952,4165.8,937,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3399,3999,4731,4633,4013,4675,4130,4073,4101,4020,4019,4239.4,938,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13661,17322,18501,18056,17827,18216,17181,17461,17591,17662,17698,17751.5,939,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14053,15923,16643,16802,16020,16403,16133,15644,16455,15767,15908,16169.8,940,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12489,14195,14723,15034,14306,14906,14263,14525,14194,14389,14461,14499.6,941,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598508,598054,598441,598198,598858,599153,598552,597774,598560,598554,598359,598450.3,942,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15787,20947,20965,20279,20661,20575,20828,21460,20963,21230,21486,20939.4,943,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599183,598773,598409,598419,598609,598258,599106,597841,598577,598607,598303,598490.2,944,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",26083,30822,30282,30494,30514,30221,30033,30736,30203,30359,30026,30369.0,945,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,734020,737189,734330,731353,735129,737522,732400,739059,732784,737174,735098,735203.8,946,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10010,12904,12997,12696,12943,12577,12858,12795,12566,12786,12734,12785.6,947,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14722,16915,17656,17284,16973,17925,16706,16637,16746,16845,17081,17076.8,948,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11749,14284,15331,14991,14376,15632,14376,14982,15471,14424,14378,14824.5,949,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23887,24896,25646,25667,25080,25259,25038,24941,25322,25498,24999,25234.6,950,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3299,3964,4581,4569,4019,4625,3943,3951,3936,3995,3943,4152.6,951,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3420,4033,4682,4700,4232,4677,4240,4050,4184,4037,4024,4285.9,952,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14570,17126,17955,18479,17696,17732,17721,17564,17916,17493,17453,17713.5,953,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14171,15888,16393,16300,15788,16559,16128,16070,15710,15981,15917,16073.4,954,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12541,14535,14907,14900,14284,14979,14254,14291,14587,14440,14609,14578.6,955,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282063,282424,283481,283118,282719,285239,282348,282540,283674,282554,282142,283023.9,956,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281514,284915,284115,285040,283325,282319,283648,284048,283494,283072,283703,283767.9,957,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283213,282487,282283,282656,282508,282292,282950,282300,282946,284822,281370,282661.4,958,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14731,16676,17614,17732,17222,17258,16935,16689,16814,16928,16438,17030.6,959,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14605,16245,17270,16872,16904,17081,16437,16824,16545,16787,17151,16811.6,960,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12703,17692,17392,17779,17223,17449,17839,17009,17521,17874,17615,17539.3,961,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12605,17859,17555,17687,17309,17821,18173,17847,17729,17610,17263,17685.3,962,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13798,16313,16416,16376,15855,16462,16278,16136,16028,15712,15979,16155.5,963,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14110,16092,16162,16418,15908,16392,15633,15802,15728,16057,15892,16008.4,964,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29767,30110,30029,30220,30081,30140,30307,30249,30333,30358,30139,30196.6,965,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11343,15101,14700,15217,15477,14600,14906,14702,15114,14706,15435,14995.8,966,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19860,21708,21841,21720,21779,21642,21979,21843,21517,21787,21655,21747.1,967,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25721,27637,27747,27772,27764,28481,27662,27635,27127,27201,27612,27663.8,968,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25602,30197,30573,29844,30622,29728,29837,30449,30351,30967,30429,30299.7,969,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23330,26283,26510,26476,26314,26432,26121,26470,26189,25784,25746,26232.5,970,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26807,28406,28436,28476,28683,28626,28668,28453,28491,28390,28467,28509.6,971,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12553,14429,14649,14768,14669,14351,14675,14479,14465,14628,14573,14568.6,972,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281719,282381,282750,285002,283116,284072,283906,283801,283481,284812,284706,283802.7,973,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9936,12636,12686,12356,13080,13145,12257,13352,12531,12562,12975,12758.0,974,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14495,17461,18171,17375,17453,17522,17372,17318,17236,17255,16889,17405.2,975,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11604,14229,15639,14943,14444,15943,14203,14988,14547,14932,14564,14843.2,976,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23997,25083,25810,25839,25351,25468,25276,25562,25412,25475,25304,25458.0,977,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3311,3951,4600,4590,3948,4588,3918,3979,3912,3977,3947,4141.0,978,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3437,4049,4735,4717,4116,4849,4199,4117,4154,4077,4027,4304.0,979,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14110,17732,18263,18421,18013,17932,17499,17364,17679,17605,17686,17819.4,980,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13890,16258,16484,16360,15928,16350,15761,16056,15917,15882,16002,16099.8,981,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12615,14529,15110,15041,14720,15316,15311,14401,14245,14467,14742,14788.2,982,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599525,598764,598948,597929,598214,598629,598397,598330,597518,598518,598880,598412.7,983,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15866,20562,20674,20923,19884,20923,20044,20403,20402,19777,20474,20406.6,984,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,600156,597935,598350,597673,598283,597257,598892,598250,597717,598623,598320,598130.0,985,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25906,30532,30423,30091,30681,30828,30146,30113,30532,30353,30301,30400.0,986,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,734139,737158,736310,735123,734165,731815,735094,735189,735722,734901,736541,735201.8,987,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9950,12896,12796,12682,12815,12638,12568,12717,12891,12695,12925,12762.3,988,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15294,16991,17802,17604,17120,17425,17450,16683,16769,16848,16926,17161.8,989,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11489,14652,14919,14691,14641,15275,14492,15324,15003,14694,15316,14900.7,990,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23988,25090,25666,25670,25256,25428,25974,25292,25075,25150,24955,25355.6,991,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3305,3964,4668,4624,4086,4689,4050,4030,3948,4052,3974,4208.5,992,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3453,4065,4712,4736,4090,4730,4224,4102,4148,4138,4068,4301.3,993,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13842,17963,18323,18505,17947,18411,18112,18167,17727,17885,18098,18113.8,994,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14212,16029,16262,16374,15996,16373,16010,15927,16446,16037,15927,16138.1,995,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12668,14320,15173,15328,14268,14986,14638,14488,14385,14495,14503,14658.4,996,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282117,282245,282698,282714,284445,282564,283117,284860,284394,282808,282594,283243.9,997,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283699,282289,283306,282186,284934,282752,282774,282751,283709,283784,282771,283125.6,998,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283075,284051,282465,284248,285451,283420,285061,286077,285425,286065,283678,284594.1,999,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14602,17355,17608,17635,17282,17829,16899,17076,17252,17640,17307,17388.3,1000,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14624,17095,17841,17277,17336,17977,17031,17108,17348,16966,17064,17304.3,1001,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12955,17434,17683,17531,17399,17297,18338,17615,17587,17525,17566,17597.5,1002,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12418,17801,17742,17512,18062,17905,17975,17609,17847,17496,17276,17722.5,1003,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14160,16033,16257,16293,15986,16503,15779,16045,16171,16124,15894,16108.5,1004,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14312,15847,16799,16611,15872,16427,16195,15929,16294,16257,16111,16234.2,1005,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29368,30444,30049,30353,30247,30214,30368,30681,30263,30529,30191,30333.9,1006,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11163,15463,14511,14901,14395,15058,14496,15137,15264,14495,15219,14893.9,1007,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19786,22334,22227,22397,22143,22127,22198,22100,22256,22306,22078,22216.6,1008,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25073,27485,27980,28450,27280,28022,27463,27553,27601,27464,27680,27697.8,1009,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26521,30905,30324,30172,30716,31032,30840,30741,30974,29720,30576,30600.0,1010,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23148,26312,26413,26367,25967,26843,26512,25891,26063,26019,26132,26251.9,1011,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,27111,28888,28708,28797,28438,28474,28511,28677,28773,28608,29024,28689.8,1012,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12726,14399,14557,14596,14624,14360,14341,14366,14460,14426,14277,14440.6,1013,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281803,283192,282655,282917,282660,282321,282607,282263,283753,282874,282059,282730.1,1014,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10861,12909,13153,13137,12573,13446,12279,12598,13051,12409,12415,12797.0,1015,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14603,17402,17502,17841,17065,17833,16956,17409,16894,17013,17121,17303.6,1016,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11947,14678,22586,14914,15123,16227,13743,14387,14708,14321,14652,15533.9,1017,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24031,25006,25692,25356,25141,25691,25107,25234,24902,24893,25165,25218.7,1018,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3289,3957,4676,4608,4010,4645,4005,4029,3948,4055,4008,4194.1,1019,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3435,4047,4765,4685,4098,4704,4140,4119,4270,4075,4033,4293.6,1020,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13967,18547,18606,19378,18190,19426,18441,18781,18252,18057,18041,18571.9,1021,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14082,16202,16303,16608,15927,16625,16242,15814,16012,15965,16043,16174.1,1022,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12541,14389,14933,15016,14418,14860,14664,14359,14531,14468,14326,14596.4,1023,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,600471,597957,598702,597902,598980,597848,600497,597614,598307,598574,598370,598475.1,1024,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15611,20605,20501,20605,20509,20587,20930,20550,20221,19968,20122,20459.8,1025,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598468,598313,598643,597699,598665,598374,599015,598535,597718,598670,598522,598415.4,1026,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",26090,30338,30676,30190,30545,30545,30344,30030,29949,30206,30693,30351.6,1027,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,736489,734271,734588,735432,733255,737050,732775,734397,738185,737745,738705,735640.3,1028,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9969,12514,12866,12464,13015,12732,12654,13001,12592,12894,12535,12726.7,1029,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15066,16372,17343,17308,16881,17122,16606,16271,16481,16606,16838,16782.8,1030,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11719,14923,15332,15744,15261,16187,15071,14427,15341,14775,15074,15213.5,1031,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23776,25122,25749,25795,25046,25645,25002,25369,25021,25190,25263,25320.2,1032,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3318,4071,4609,4704,4050,4630,3969,4034,3957,4030,3969,4202.3,1033,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3417,4040,4711,4707,4173,4720,4189,4089,4154,4113,4173,4306.9,1034,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14139,18248,18505,18575,18297,18098,17875,17567,17731,18830,17750,18147.6,1035,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14300,16190,16277,16629,16140,16384,15970,15988,15999,15970,15737,16128.4,1036,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12542,14519,14682,14791,14481,14694,14288,14388,14405,14526,14333,14510.7,1037,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284257,283317,282819,283619,283152,282880,282361,283844,282675,283768,282228,283066.3,1038,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,285148,285446,283629,284099,283349,282552,282503,283118,283272,282263,282728,283295.9,1039,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282815,283495,281968,282850,284452,281511,284245,283710,281846,282527,283571,283017.5,1040,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14653,17439,17684,17521,17032,17387,16825,16992,17292,16971,17355,17249.8,1041,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14486,17137,17447,17467,17166,17419,17382,17102,17467,17984,17307,17387.8,1042,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12439,17782,18358,17636,17713,17795,17916,17736,17811,17749,17828,17832.4,1043,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12923,17528,17314,17468,17663,17579,17386,17675,17742,17724,17386,17546.5,1044,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13981,16063,17000,16448,16204,16433,16214,16069,15864,15706,16186,16218.7,1045,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13876,15769,16450,16214,16059,16213,15905,15732,16033,15917,16125,16041.7,1046,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29858,30583,30707,30677,30501,30329,30603,30595,30595,30337,30552,30547.9,1047,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11334,14717,15672,14441,14415,14659,15236,14628,14907,15624,15171,14947.0,1048,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",20028,21644,21839,22018,21912,21595,21849,21688,21660,21775,21676,21765.6,1049,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25212,27410,27613,28422,27343,27857,27354,27393,27370,27491,27197,27545.0,1050,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25550,31226,30490,30934,30716,30204,30114,30738,30601,31027,30283,30633.3,1051,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23130,26512,26663,26463,26266,26147,26272,26123,25954,25933,26063,26239.6,1052,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26982,28417,28914,28740,28526,28598,28862,28731,28652,28681,28568,28668.9,1053,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12542,14566,14506,14412,14381,14911,14501,14528,14556,14313,14552,14522.6,1054,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283923,281934,281790,283120,282864,283054,283151,282580,283778,282198,282937,282740.6,1055,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9809,13107,13293,12578,12943,12456,12637,13436,12915,13338,12763,12946.6,1056,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14800,16880,17998,17362,17277,17241,17244,16888,17116,16969,17141,17211.6,1057,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11427,14496,14910,15208,14304,14795,14634,14270,15283,14468,14855,14722.3,1058,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24007,25437,25525,25295,25297,25685,25203,25104,24981,24943,25396,25286.6,1059,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3313,3973,4628,4637,4033,4869,4000,4009,3940,4001,4039,4212.9,1060,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3393,4061,4721,4727,4129,4736,4177,4202,4167,4131,4152,4320.3,1061,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14168,18309,19172,19170,18236,18942,18267,18223,17847,19116,18397,18567.9,1062,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14027,16165,17496,16318,15808,16079,15946,16259,16100,15983,16359,16251.3,1063,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12688,14399,14904,14885,14320,15083,14234,14366,14281,14313,14296,14508.1,1064,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598079,598162,598809,599416,599629,598562,598907,598416,599418,598344,598918,598858.1,1065,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16159,20592,19967,20259,20099,20160,20375,19909,19942,20039,19817,20115.9,1066,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597225,597708,598085,598127,598923,598226,599098,597866,598760,598648,597529,598297.0,1067,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25977,29917,30090,30180,30194,30160,30010,30161,30262,30131,30264,30136.9,1068,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,740439,732416,734333,735375,733703,731473,735587,733093,736167,735989,735584,734372.0,1069,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9875,12730,12760,12445,12593,12589,12787,12699,12558,12710,12755,12662.6,1070,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15088,17073,17028,17437,16723,17538,16964,17530,16883,16950,17091,17121.7,1071,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11255,14831,15258,14944,14287,15189,14811,15537,14364,14536,15103,14886.0,1072,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23844,25121,25427,25532,25043,25476,25033,25145,25780,25136,25092,25278.5,1073,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3279,3986,4721,4632,4042,4662,3985,4030,3930,4046,3998,4203.2,1074,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3360,3990,4676,4637,4066,4700,4156,4128,4136,4082,4039,4261.0,1075,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14157,18677,18858,19065,18364,18872,18315,17951,18191,18013,18459,18476.5,1076,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14375,16222,16489,16296,15908,16384,15822,16231,16040,16191,16022,16160.5,1077,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13230,14245,15048,15528,14405,14862,14314,14509,14249,14103,14300,14556.3,1078,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282704,282467,284095,284120,282572,282348,283001,282850,283463,284515,283690,283312.1,1079,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282548,281650,283331,284133,282523,284400,285419,282867,283716,282691,283687,283441.7,1080,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282019,283089,282351,283424,284733,285087,283050,282610,283033,286221,285246,283884.4,1081,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14675,17162,17182,17750,17572,17587,16762,17161,17023,16877,17505,17258.1,1082,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14902,16310,16783,16971,16865,16867,16353,16401,16341,17162,16699,16675.2,1083,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13396,17588,17393,17873,17358,17587,17605,17677,17298,17487,17428,17529.4,1084,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13047,17554,17316,17292,17507,17491,18032,17557,17761,17953,17959,17642.2,1085,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13872,16270,16649,16285,16331,16642,15759,15889,16289,15946,16025,16208.5,1086,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13876,15738,16361,15946,16133,16388,15736,15927,15716,16007,15990,15994.2,1087,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29603,30223,30543,30280,30107,30298,30747,30709,30278,30191,30320,30369.6,1088,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11677,15344,15095,15174,15171,14880,14648,15317,14849,14441,15316,15023.5,1089,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19936,21344,21597,21851,21614,21607,21589,21706,21440,21745,21615,21610.8,1090,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",26106,27222,28414,27883,27401,27779,27228,27308,27357,27542,27604,27573.8,1091,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25294,30672,31349,30146,30613,31375,30536,31088,29934,30559,30620,30689.2,1092,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23134,26515,26449,26529,26426,26284,26183,26351,26241,26163,26223,26336.4,1093,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26980,28433,28443,28723,28642,28645,28528,29000,28673,28779,29005,28687.1,1094,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12728,14507,14447,14524,14746,14856,14528,14442,14418,14431,14369,14526.8,1095,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281993,282297,283418,282479,283011,284119,282681,282554,283041,284618,282760,283097.8,1096,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9895,12658,12705,12577,12824,12586,12499,13104,12691,13100,12438,12718.2,1097,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14967,16356,17337,16862,16804,17128,16446,16681,16805,16720,16569,16770.8,1098,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11640,14392,15456,15704,15146,15690,15246,15133,14555,14516,14301,15013.9,1099,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23911,25465,25342,26134,25607,25928,25128,25385,25395,25011,25237,25463.2,1100,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3282,3935,4631,4588,3986,4624,3935,3983,4061,3993,3979,4171.5,1101,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3398,4020,4693,4662,4050,4699,4168,4052,4108,4073,4003,4252.8,1102,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13615,17832,19083,18531,18016,18629,17620,18552,18440,17984,18772,18345.9,1103,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14034,15870,16764,16151,16067,16478,15781,15937,15968,16000,16062,16107.8,1104,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12541,14269,15029,15144,14332,15179,14613,14205,14144,14288,14471,14567.4,1105,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599747,598307,598684,599457,598914,597506,598493,598417,598683,597696,598130,598428.7,1106,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16000,20127,19673,19767,20398,20612,20414,20120,19997,19977,20915,20200.0,1107,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598630,597686,597861,598024,597239,598167,599053,597975,598000,597712,598575,598029.2,1108,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",27244,30122,30191,29863,30087,30216,30125,29852,30336,30376,30027,30119.5,1109,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,732507,738085,733234,734651,740674,734497,733553,736364,733801,730854,733430,734914.3,1110,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9879,12750,13519,12722,12580,12979,12732,12681,12761,12798,12624,12814.6,1111,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14805,16846,17273,17012,16939,17336,16820,16566,16991,16834,16501,16911.8,1112,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11429,15216,15071,15196,15964,15197,15075,14768,14674,14566,14580,15030.7,1113,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24052,25006,25437,25608,24946,25876,25064,25013,25416,25001,24900,25226.7,1114,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3288,3973,4615,4606,4057,4660,3926,3949,3907,4003,4030,4172.6,1115,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3378,4021,4662,4644,4061,4701,4170,4130,4160,4028,4050,4262.7,1116,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14062,18198,18829,18958,18437,19476,18446,18707,17805,18937,18510,18630.3,1117,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14348,16045,16130,16553,15908,17424,16049,15810,16094,15936,15736,16168.5,1118,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12669,14357,14959,15364,14558,14675,14386,14748,14419,14963,14292,14672.1,1119,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282332,285822,283660,283185,283443,282786,282321,282362,285589,283697,283368,283623.3,1120,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282015,282252,283820,282557,283066,282527,282308,282809,282625,283351,282334,282764.9,1121,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282349,282617,282035,282322,283067,282950,283502,283195,283272,283802,283374,283013.6,1122,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15154,16989,17541,17585,17178,17303,17048,17504,17106,16861,16956,17207.1,1123,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14466,16415,17139,17098,16599,16936,16766,16189,16514,16379,16538,16657.3,1124,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12706,17630,17384,17846,17576,17396,17254,17425,17471,18012,17092,17508.6,1125,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12723,17642,17791,17995,17984,17610,17856,17960,17534,17840,17689,17790.1,1126,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13822,16078,16249,16585,15728,16400,16029,15946,16166,16157,16134,16147.2,1127,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13868,15936,16676,16755,16260,16180,15896,15927,15872,16199,15903,16160.4,1128,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29561,30432,30539,30187,30078,30452,30307,30236,30450,30640,30743,30406.4,1129,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11309,14557,15030,14537,14354,15502,14809,14500,14954,14731,14636,14761.0,1130,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19790,21575,21563,21736,21715,21678,21530,21568,21838,21548,21640,21639.1,1131,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25247,27834,27760,28109,27275,28021,27531,27488,27918,27445,27759,27714.0,1132,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",26100,30929,29919,30417,30329,30074,30957,30227,30258,30867,30263,30424.0,1133,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23219,25932,26130,26568,26387,26454,25981,26134,26167,26146,26380,26227.9,1134,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26902,28386,28283,28577,28953,28360,28398,28301,28432,28777,28483,28495.0,1135,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12756,14560,14273,14770,14569,14574,14547,14528,14725,14488,14537,14557.1,1136,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283330,282769,283237,281752,284916,283721,283991,282558,283485,285065,284213,283570.7,1137,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10527,12684,13534,12632,12628,13064,12418,13091,13207,13519,12584,12936.1,1138,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14482,17167,17527,17890,17063,17362,16897,16895,17609,17159,16960,17252.9,1139,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11493,14912,15727,15189,15019,15243,14638,15372,14815,15005,15214,15113.4,1140,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24003,25165,25627,25794,25164,25554,25001,24874,25349,25022,25052,25260.2,1141,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3271,4018,4666,4617,4005,4718,3956,4026,3935,4148,4000,4208.9,1142,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3362,4057,4647,4630,4035,4625,4160,4035,4105,4044,3989,4232.7,1143,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14112,17772,19106,18197,17766,18473,17321,18018,17459,17893,17217,17922.2,1144,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14264,15780,16540,16803,15902,16453,15841,15747,16276,16218,16082,16164.2,1145,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12663,14542,14793,14980,14529,14944,14524,14444,14306,14405,14309,14577.6,1146,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598872,597991,598367,598336,599089,597268,598559,598199,598869,598224,598805,598370.7,1147,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16225,20728,20572,20822,20898,20771,20214,20627,20222,21263,21686,20780.3,1148,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597387,598585,598689,598595,600020,598218,598145,598680,598661,599428,599168,598818.9,1149,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25991,30109,30184,30384,29933,30333,30064,30140,30174,30261,29894,30147.6,1150,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,732895,734896,731571,737057,732787,734398,735053,735881,733320,736593,733789,734534.5,1151,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9865,12467,12414,13359,12626,12606,12536,12698,12766,12722,12711,12690.5,1152,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15019,16973,17914,17416,17057,17845,16666,17117,16987,17036,17042,17205.3,1153,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11343,15157,15517,15220,14440,15640,15080,14923,15598,15505,15387,15246.7,1154,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24081,25033,25656,25911,25232,25462,25183,25307,25136,25153,25377,25345.0,1155,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3290,4039,4592,4677,3977,4573,3939,3933,3983,3997,3910,4162.0,1156,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3417,4029,4669,4669,4075,4794,4124,4062,4135,4033,4020,4261.0,1157,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14156,17673,18701,17753,17692,18191,17242,17246,17353,17409,17450,17671.0,1158,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15356,15944,16280,16434,15937,16790,16064,16107,16249,16173,16522,16250.0,1159,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12530,14437,15075,14862,14543,14954,14375,14580,14419,14404,14497,14614.6,1160,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,284980,282931,282653,283589,282944,284184,282283,282854,283605,282734,282573,283035.0,1161,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283153,285797,283373,283621,283034,283098,283459,283141,282985,282301,284111,283492.0,1162,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283500,282062,282353,283966,281183,281798,283103,282232,283371,284289,283510,282786.7,1163,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14517,17290,17385,17598,17173,17907,17282,17108,17126,17172,17559,17360.0,1164,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14588,16473,17056,17082,16382,17034,16501,16623,16507,16515,16350,16652.3,1165,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12886,17687,17946,17836,18372,17899,18244,17708,18001,17839,17660,17919.2,1166,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12620,17653,18357,17724,18040,17382,17351,17567,17433,18388,17679,17757.4,1167,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13960,15798,16271,16287,15869,16419,15728,16022,16213,16320,16191,16111.8,1168,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13841,16071,16594,16621,15841,16505,15640,16015,15923,16059,16420,16168.9,1169,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29759,30500,30396,30489,30318,30399,30290,30350,30180,30393,30395,30371.0,1170,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11421,14879,14510,14802,15018,14699,14383,15216,14415,14394,14198,14651.4,1171,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19988,21493,21624,21541,21969,21575,21714,21621,21593,21881,21595,21660.6,1172,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25537,27851,28034,28381,27468,28205,27657,27472,27450,27520,27813,27785.1,1173,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25950,31385,29854,29855,30596,30338,30505,30344,30235,30217,29921,30325.0,1174,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23272,26237,26766,27154,25901,26773,25894,26264,26117,26135,26083,26332.4,1175,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26826,28572,28372,28795,28537,28523,28458,28994,28988,28699,28853,28679.1,1176,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12578,14567,14486,14826,14300,14621,14402,14452,14927,14685,14515,14578.1,1177,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282679,284201,282379,283015,283555,283284,282790,284121,282716,282787,283332,283218.0,1178,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10000,13409,12810,13995,12927,13297,13097,13207,12797,13714,13152,13240.5,1179,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14768,17302,17571,17790,16693,17456,17080,17089,17038,16892,16862,17177.3,1180,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11534,14948,15264,15315,15237,15061,15826,14675,14979,14403,14771,15047.9,1181,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23943,25465,25337,25470,25055,25618,25106,24997,25146,24967,25170,25233.1,1182,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3292,3946,4655,4613,3983,4680,4014,4001,3929,4034,4044,4189.9,1183,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3433,4072,4704,4714,4109,4729,4189,4115,4175,4087,4054,4294.8,1184,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13633,17214,18397,18119,17552,18093,17344,18016,17422,17645,17982,17778.4,1185,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14040,16016,16301,16315,16124,16206,15789,15943,15870,15508,15890,15996.2,1186,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12517,14574,15172,14772,14245,15047,14317,14429,14525,14360,14301,14574.2,1187,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599206,598592,597770,598952,598248,598393,597943,598589,597736,598360,596978,598156.1,1188,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16605,20399,20511,20358,20337,19969,19914,19674,20684,21129,20628,20360.3,1189,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597903,598048,597620,598350,598633,599857,597801,598379,597775,598424,598096,598298.3,1190,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25695,30444,30246,30169,30445,29882,30041,30304,30294,30189,30760,30277.4,1191,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,737239,733630,733203,734157,736499,737661,732035,736306,736741,733460,735112,734880.4,1192,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9734,12452,12529,12610,12760,12807,12778,12776,12660,12865,13005,12724.2,1193,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14603,16931,17528,17384,16992,17869,16833,17664,17185,17186,17410,17298.2,1194,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11604,14829,15274,14971,14617,15241,15431,15325,14889,14564,14748,14988.9,1195,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23904,25121,25733,25485,25092,25825,25113,25090,25361,25007,25033,25286.0,1196,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3333,3964,4620,4612,4030,4638,3946,4033,3957,4056,3975,4183.1,1197,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3439,4054,4772,4709,4137,4768,4261,4120,4219,4102,4092,4323.4,1198,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14458,17784,18176,18193,17501,18022,17676,17208,17881,18138,17555,17813.4,1199,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14308,15986,16602,16430,16034,16649,15868,16052,15735,15911,16146,16141.3,1200,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12697,14362,14750,14824,14284,14774,14280,15356,14211,14128,14397,14536.6,1201,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282348,283562,282615,283498,282580,283765,282557,283038,282973,283956,283148,283169.2,1202,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283409,282570,282664,283220,282825,282343,283374,283840,283045,282240,283922,283004.3,1203,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283246,282187,282244,284249,283183,282770,283183,282518,285838,283204,285235,283461.1,1204,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14700,17025,17700,17634,17486,17546,17441,17280,17001,16869,16793,17277.5,1205,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14496,16711,17477,17751,17143,17538,16881,17041,17458,17599,17035,17263.4,1206,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12643,17806,17377,17158,17562,18102,17266,17397,17203,17170,17225,17426.6,1207,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12888,17475,17533,17213,17557,17503,17323,17465,17524,17776,17501,17487.0,1208,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13959,15983,16063,16125,15866,16678,15843,15898,15862,15726,15945,15998.9,1209,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13966,16176,16171,16313,15829,16213,16141,15557,15790,15704,15830,15972.4,1210,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29651,30449,30384,30496,30220,30420,30451,30497,30249,30422,30425,30401.3,1211,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11454,15477,15395,15110,15929,15289,15320,15310,15244,14858,14899,15283.1,1212,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",20163,22158,22562,22020,22216,22064,21998,22081,21887,22197,22448,22163.1,1213,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25202,27577,27864,28044,27552,27877,27615,27817,27537,27506,27722,27711.1,1214,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25442,31335,29868,30207,31783,30432,30529,30615,29652,30331,31060,30581.2,1215,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23269,26149,26533,26523,25980,26643,26308,26455,26088,26119,26361,26315.9,1216,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26743,28839,28677,28643,29115,28964,28550,28986,28579,28335,29014,28770.2,1217,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12614,14382,14530,14513,14409,14439,14467,14346,14239,14413,14469,14420.7,1218,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282919,282528,282790,283942,283297,282712,283607,282525,282230,286086,285946,283566.3,1219,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9892,13086,13136,13211,13099,12995,12850,12893,13311,13136,13115,13083.2,1220,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14536,17271,17866,17287,17231,17279,16839,16945,16748,16980,17385,17183.1,1221,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11464,15272,15822,15325,14518,14940,14067,14563,15185,15041,15208,14994.1,1222,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24084,25336,25856,25591,25501,25439,25238,25035,25030,25045,25138,25320.9,1223,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3309,4016,4652,4626,4061,4669,4043,4084,3988,4049,4009,4219.7,1224,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3418,4157,4896,4751,4120,4718,4197,4114,4298,4153,4105,4350.9,1225,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14320,17939,19434,19369,18634,18556,18186,18656,18275,18466,18573,18608.8,1226,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14065,15817,16572,16358,15992,16160,15959,15675,15751,15862,16346,16049.2,1227,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12447,14317,15003,14943,14433,15048,14325,14069,14387,14440,14385,14535.0,1228,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,597471,598718,598478,600209,598716,597867,599715,599109,599103,598894,599437,599024.6,1229,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16240,20834,20455,20292,21179,21335,21372,20788,20762,20055,20359,20743.1,1230,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,599001,598930,599169,598271,598233,598655,598933,598847,597893,599009,598261,598620.1,1231,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",26075,30116,30116,30305,30429,30131,30439,30227,30266,30149,30263,30244.1,1232,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,733319,733961,733493,734888,738032,733276,737147,735328,733632,735560,731088,734640.5,1233,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9931,12780,12401,12650,12370,12613,12807,12872,13192,12687,12775,12714.7,1234,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15026,16650,17534,17203,16642,16949,16697,16963,16518,16812,16247,16821.5,1235,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11563,14293,15173,15692,15479,14958,15098,15050,14557,14418,15164,14988.2,1236,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23762,24962,25506,25810,25136,25818,25502,25232,24913,24913,24956,25274.8,1237,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3302,3989,4659,4656,4099,4660,3983,4114,3973,4044,4050,4222.7,1238,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3399,4027,4695,4689,4045,4681,4193,4030,4219,4033,4002,4261.4,1239,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13769,17787,18379,18530,18129,18896,17645,18121,17389,17709,17693,18027.8,1240,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14139,15766,16305,16306,15757,16526,16053,16069,15932,15956,16039,16070.9,1241,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12447,14136,15158,15065,14493,14995,14380,14391,14392,14326,14372,14570.8,1242,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282878,282654,284135,283181,282570,282600,285394,282781,282386,283634,283627,283296.2,1243,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282952,282832,283159,282470,282160,283902,282399,283103,283560,283614,283907,283110.6,1244,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282202,284351,282887,286023,282677,283623,283576,283040,282644,283632,283033,283548.6,1245,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14391,16979,17476,17296,17097,17247,16990,17206,17103,17368,16931,17169.3,1246,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14678,16984,17320,17438,17388,17939,16844,17325,16917,16940,16779,17187.4,1247,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12744,17705,21942,17342,17309,17695,17717,17359,17263,17303,17692,17487.22222,1248,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12618,17957,17664,17655,17682,17981,17971,17913,17542,18078,17712,17815.5,1249,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",13816,16016,16549,16597,16652,16112,15649,16012,16281,16030,16204,16210.2,1250,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14091,16056,16483,16307,16140,16353,15860,16420,15811,16046,15825,16130.1,1251,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29487,30557,30506,30371,30319,30387,30251,30456,30258,30274,30573,30395.2,1252,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11441,14706,15613,14920,15280,15174,15807,15058,15809,15373,14612,15235.2,1253,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",20061,21699,21588,21525,21571,21845,21762,21605,21652,21899,21698,21684.4,1254,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25605,27864,27741,27976,27467,28247,27418,28091,27960,27608,27460,27783.2,1255,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25364,29788,30173,30528,30639,29760,30936,30396,29767,30788,30269,30304.4,1256,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23148,25870,26226,26438,25822,26450,25814,26331,26040,26037,26221,26124.9,1257,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26792,28574,28597,28591,28754,28524,28712,28555,28822,28506,28501,28613.6,1258,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12554,14443,14442,14526,14308,14209,14340,14352,14342,14651,14473,14408.6,1259,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282550,284148,282652,282867,282931,282932,286314,282826,284930,283748,283222,283657.0,1260,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",10099,12953,12737,12938,13354,12869,13617,13509,12716,12960,13198,13085.1,1261,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14697,16927,17204,17545,17227,17577,16745,16891,16992,17369,16787,17126.4,1262,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11648,15408,15247,15461,14545,15814,15230,14848,14471,14472,14199,14969.5,1263,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23907,25114,25647,25587,24983,25475,25530,25361,25227,25265,25388,25357.7,1264,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3292,3976,4593,4596,4031,4611,3938,4001,3958,4011,3954,4166.9,1265,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3371,4034,4680,4842,4052,4691,4155,4058,4171,4061,4012,4275.6,1266,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13902,17676,18730,18769,17994,19001,18138,18544,17930,18807,18253,18384.2,1267,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14269,15918,16290,16308,16065,16640,15860,16013,16104,15999,16020,16121.7,1268,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12809,14457,14830,14803,14447,15034,14422,14387,14181,14542,14507,14561.0,1269,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598090,598298,598716,598402,599463,597990,598670,598314,599741,598358,599481,598743.3,1270,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",16390,19900,20174,20785,20094,20939,20478,20643,20934,21076,20916,20593.9,1271,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598063,598714,599269,599059,599271,598753,598287,600339,598946,599508,598794,599094.0,1272,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",25838,30106,30235,30435,30121,30039,30041,30032,30113,29874,29920,30091.6,1273,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,736762,737146,733270,732465,735018,732257,733873,734615,735914,735829,737792,734817.9,1274,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9831,12810,12508,12509,12558,13394,12722,12724,12746,13077,12501,12754.9,1275,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14938,17501,17665,17605,16817,17273,17279,17175,17365,17218,16788,17268.6,1276,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11611,14370,14430,14924,15259,15525,14550,14493,14659,15060,14544,14781.4,1277,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23967,25391,25536,25678,25195,25806,25184,25303,25230,25169,25472,25396.4,1278,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3287,3942,4586,4579,3985,4666,4039,3963,3897,4003,4103,4176.3,1279,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3363,4038,4706,4674,4085,4694,4127,4045,4152,4021,4023,4256.5,1280,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13998,18303,19649,19056,18338,18967,18129,17848,17927,18302,18705,18522.4,1281,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14320,15711,16326,16588,15900,16455,16195,16369,16134,15820,15853,16135.1,1282,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12847,14127,14998,14826,14376,14901,14343,14413,14736,14459,14357,14553.6,1283,12
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,282796,281422,282445,283312,283252,283366,282035,281771,283148,283187,282258,282619.6,1284,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281941,285523,283303,285761,282626,282359,282344,283259,283515,282499,283521,283471.0,1285,13
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,283496,283556,283812,283111,283226,283336,283502,283509,282797,282927,284156,283393.2,1286,13
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14557,17034,17366,17851,16897,17181,16931,17379,16910,17148,16891,17158.8,1287,5
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",15061,16250,16675,17421,16365,18160,16491,16778,16433,16772,16332,16767.7,1288,5
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12563,17856,17421,17038,17355,17932,18191,17465,17349,17590,17386,17558.3,1289,18
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12437,17400,18021,17598,17644,17364,17453,17974,17922,17245,17277,17589.8,1290,18
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14028,15694,16614,16347,16177,16554,16039,15776,15897,16288,15822,16120.8,1291,11
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14039,16187,16320,16682,15987,16436,15765,15968,16086,15900,16002,16133.3,1292,11
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_tn,29585,30516,30522,30487,30572,30311,30264,30599,30310,30296,30277,30415.4,1293,22
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",11475,15244,14622,14556,14682,14411,14433,14721,15185,14436,14924,14721.4,1294,23
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",19655,21605,21562,21549,21674,21583,21760,21547,21722,21786,21615,21640.3,1295,24
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",25174,27348,27824,28290,27242,28056,27512,27707,27506,27716,27826,27702.7,1296,25
"void <unnamed>::softmax_warp_forward<float, float, float, 8, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",25647,29803,30113,30053,29595,30387,30500,30510,30519,30668,30333,30248.1,1297,26
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",23125,25899,26324,26391,25720,26324,25809,25757,26263,25799,25624,25991.0,1298,27
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,26623,28705,28516,28504,28590,28555,29002,28788,28530,28535,28857,28658.2,1299,28
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12613,14467,14584,14526,14436,14292,14483,14632,14461,14501,14347,14472.9,1300,29
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,281939,282853,283891,282946,283240,282816,283978,283341,282179,283060,282864,283116.8,1301,13
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9918,12947,12970,13087,13346,12868,13032,13315,13266,13473,13140,13144.4,1302,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14755,16472,17052,17160,16617,16848,16551,16692,16619,16676,16448,16713.5,1303,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11626,15338,15998,15294,14873,15185,15292,15420,14688,15286,14831,15220.5,1304,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",24173,25383,25336,25599,25005,25756,25767,24922,25503,25090,25032,25339.3,1305,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3254,3992,4591,4600,4023,4627,3929,4048,3920,3994,4031,4175.5,1306,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3369,4005,4660,4623,4055,4658,4156,4043,4152,4040,4005,4239.7,1307,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",13996,17627,18826,18499,18655,19020,17897,17778,17932,18014,17742,18199.0,1308,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14095,15879,16069,16572,15922,16729,16015,15756,16215,16194,15696,16104.7,1309,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12660,14246,14745,14766,14479,14873,14207,14235,14186,14230,14083,14405.0,1310,12
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598722,598472,598348,597852,597730,597790,598910,598482,598006,598193,598404,598218.7,1311,40
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",15669,20401,20224,19758,20289,20891,19792,19764,19835,19804,21168,20192.6,1312,41
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_tn,598091,597969,597585,600407,598945,597951,599170,597992,598636,598221,597991,598486.7,1313,40
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",27123,30089,30122,30278,30113,30269,30231,30787,30014,30234,30342,30247.9,1314,43
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_tn,737296,737765,732770,732947,731235,738713,730797,732815,733685,733762,732062,733655.1,1315,44
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",9960,12960,12486,12488,12653,12609,13039,12557,13232,12840,12555,12741.9,1316,31
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14614,16756,17464,17138,16499,16934,16603,17060,16760,17199,16571,16898.4,1317,5
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",11472,15753,15104,16035,15381,16002,15350,14503,14628,15096,14915,15276.7,1318,6
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",23540,25058,25366,25608,25024,25732,24881,25043,25025,25134,25220,25209.1,1319,7
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3249,3934,4540,4559,4044,4567,3936,4012,3884,3941,3985,4140.2,1320,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3399,4006,4677,4667,4076,4750,4130,4040,4133,4102,3999,4258.0,1321,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",14065,17884,19248,18274,18298,18392,18271,18129,18129,17776,18011,18241.2,1322,10
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",14068,16007,16357,16626,15927,16487,15817,15850,15973,16050,16241,16133.5,1323,11
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl<native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",12716,14519,15256,14822,14702,14976,14278,14499,14428,14378,14452,14631.0,1324,12
ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_tn,1857944,1858159,1857037,1857671,1858904,1857433,1858225,1857623,1857176,1857723,1858634,1857858.5,1325,1325
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",88548,90522,91122,90775,90389,90809,90325,90563,90270,90511,90606,90589.2,1326,1326
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3513,4508,4536,4512,4540,4512,4515,4471,4512,4507,4452,4506.5,1327,1327
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, T2 *, int)",36131,35590,36097,35787,35330,35998,35375,35961,35762,36088,35696,35768.4,1328,1328
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, cuda::IntDivider<unsigned int>)",3518,4126,4161,4188,4318,4154,4153,4148,4133,4155,4127,4166.3,1329,1329
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, int>(T4 *, const T3 *, T4, int, int)",6707,7406,7401,7450,7404,7467,7376,7383,7325,7396,7388,7399.6,1330,1330
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, int>(T2 *)",3719,4401,4421,4443,4459,4428,4433,4472,4479,4445,4393,4437.4,1331,1331
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",19956,20560,20673,20536,20606,20819,20693,20773,20368,20628,20583,20623.9,1332,1332
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",19030,20616,20728,20754,20557,20718,20736,20678,20804,20623,20705,20691.9,1333,1332
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",18833,20396,20288,20480,20490,20331,20676,20495,20436,20437,20462,20449.1,1334,1332
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",17649,19591,19494,19521,19586,19553,19622,19716,19434,19593,19597,19570.7,1335,1332
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",2816,3471,3508,3493,3501,3475,3494,3467,3459,3487,3622,3497.7,1336,1336
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float>::Policy600, float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, int>(T2, T3, T4, int, T5, T6, T7)",7012,7147,7258,7285,7425,7626,7202,7461,7388,7444,7425,7366.1,1337,1337
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, detail::Array<char *, 3>>(int, T2, T3)",3911,4556,4625,4519,4557,4561,4625,4545,4538,4762,4590,4587.8,1338,1338
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3704,4356,4420,4639,4584,4373,4366,4393,4425,4395,4356,4430.7,1339,1339
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::masked_fill_kernel<bool>(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float, bool) (instance 1)], detail::Array<char *, 3>>(int, T2, T3)",4010,4647,4740,4711,4724,4726,4723,4659,4702,4663,4692,4698.7,1340,1340
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4>>(T3)",15138,15810,15639,15792,15670,15653,15683,15581,15542,15617,15604,15659.1,1341,1341
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",5309,6138,6055,6134,6216,6066,6093,6056,6016,6049,6047,6087.0,1342,1342
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4>>(T3)",15179,15861,16014,15976,15997,15936,15868,16717,15944,15981,15921,16021.5,1343,1343
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3434,4233,4266,4281,4302,4235,4296,4287,4228,4302,4205,4263.5,1344,1339
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4>>(T3)",15162,15925,16044,15875,15928,15843,15923,15902,15982,15959,15977,15935.8,1345,1345
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3383,4243,4307,4337,4434,4332,4399,4323,4284,4286,4279,4322.4,1346,1339
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, detail::Array<char *, 3>>(int, T2, T3)",3356,4255,4300,4300,4363,4255,4299,4279,4403,4444,4227,4312.5,1347,1347
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4>>(T3)",14991,15648,15685,15730,15790,15806,16021,16004,15719,15704,15642,15774.9,1348,1341
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3282,4171,4234,4193,4241,4199,4195,4312,4172,4191,4175,4208.3,1349,1349
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(long) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",3979,4770,4852,4810,4825,4797,5215,4797,4781,4813,4767,4842.7,1350,1350
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4>>(T3)",5998,7261,7274,7256,7292,7241,7208,7207,7249,7273,7210,7247.1,1351,1351
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, 4, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, T5)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, 4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, 4, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, T5)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(int, at::PhiloxCudaState, T3, T4)",4426,4563,4556,4527,4545,4569,4534,4543,4550,4551,4539,4547.7,1352,1352
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",4832,6316,6233,6361,6351,6268,6277,6204,6351,6422,6186,6296.9,1353,1353
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4>>(T3)",22298,23520,23517,23859,23944,23844,23124,23666,24046,23175,23788,23648.3,1354,1354
"void native::_scatter_gather_elementwise_kernel<128, 4, void native::_cuda_scatter_gather_internal_kernel<0, native::OpaqueType<8>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4659,5719,5821,5774,5848,5796,5742,5775,5788,5816,5762,5784.1,1355,1355
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::where_kernel_impl(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(bool, long, long) (instance 1)], detail::Array<char *, 4>>(int, T2, T3)",3457,4694,4794,4775,4761,4747,4838,4709,4775,4790,4662,4754.5,1356,1356
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3337,4674,4831,4724,4722,4728,4792,4725,4722,4702,4649,4726.9,1357,1357
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, detail::Array<char *, 2>>(int, T2, T3)",3424,4210,4780,4744,4263,4787,4254,4176,4247,4172,4176,4380.9,1358,1
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, detail::Array<char *, 3>>(int, T2, T3)",3398,4751,4836,4853,4896,4799,4876,4832,4792,4807,4778,4822.0,1359,1347
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, detail::Array<char *, 3>>(int, T2, T3)",3417,4175,4214,4260,4220,4214,4232,4211,4210,4234,4185,4215.5,1360,1360
"void native::<unnamed>::indexSelectSmallIndex<c10::Half, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<T1, T3>, cuda::TensorInfo<T2, T3>, int, int, T3, long)",5539,6581,6541,6509,6519,6558,6437,6502,6506,6453,6448,6505.4,1361,1361
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6552,7181,7736,7714,7282,7657,7317,7185,7282,7215,7294,7386.3,1362,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3371,4029,4603,4549,4027,4571,4147,4070,4049,4099,4089,4223.3,1363,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7569,8125,8632,8618,8154,8635,8075,8101,8046,8181,8153,8272.0,1364,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3198,3984,4628,4656,4051,4665,3997,4039,4024,4004,3981,4202.9,1365,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3319,4119,4679,4657,4089,4738,4188,4086,4148,4085,4075,4286.4,1366,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4550,5278,6090,6024,5417,6012,5257,5418,5216,5538,5361,5561.1,1367,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6617,7444,7930,7879,7498,7893,7461,7590,7460,7453,7436,7604.4,1368,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4641,4734,4725,4811,4723,4740,4706,4709,4714,4642,4714.5,1369,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76431,79915,79119,79343,79246,79411,83891,78876,79371,79060,79228,79746.0,1370,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76743,77527,77532,77257,77322,77113,77423,77026,77496,77123,77197,77301.6,1371,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76120,77449,77644,77974,77627,77597,77738,77458,77547,77613,77519,77616.6,1372,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5876,7336,7728,7720,7397,7745,7315,7208,7304,7253,7221,7422.7,1373,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5792,7231,7713,7836,7247,7706,7349,7305,7492,7307,7324,7451.0,1374,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4717,6243,6289,6220,6344,6337,6273,6263,6333,6175,6165,6264.2,1375,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4490,6305,6285,6269,6239,6100,6236,6211,6230,6267,6136,6227.8,1376,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5914,7341,7796,7817,7412,7822,7331,7340,7329,7314,7343,7484.5,1377,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5929,7323,7881,7907,7414,7845,7406,7436,7383,7449,7364,7540.8,1378,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11219,12315,12313,12297,12872,12331,12419,12342,12084,12315,12354,12364.2,1379,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3324,4545,4726,4601,4568,4554,4795,4568,4585,4563,4520,4602.5,1380,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6669,7346,7693,7725,7174,7681,7256,7178,7221,7196,7166,7363.6,1381,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5432,6108,6211,6162,6129,6166,6191,6163,6123,6300,6100,6165.3,1382,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6660,7318,7825,7793,7445,7917,7396,7356,7330,7380,7317,7507.7,1383,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10398,10831,11055,10960,11879,10922,11214,11118,11013,11231,10916,11113.9,1384,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76386,78275,77927,77578,77544,77955,77850,77641,77835,77514,77298,77741.7,1385,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3364,4577,4663,4648,4666,4605,4645,4723,4628,4639,4554,4634.8,1386,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6673,7171,7741,7648,7222,7680,7301,7208,7275,7257,7216,7371.9,1387,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3461,4017,4557,4531,4058,4697,4052,4048,4032,4069,4038,4209.9,1388,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7396,8183,8650,8665,8204,8923,8101,8196,8081,8208,8229,8344.0,1389,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3234,3989,4578,4589,4001,4593,3972,4067,3924,4076,3971,4176.0,1390,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3318,4045,4682,4649,4148,4729,4144,4107,4159,4079,4025,4276.7,1391,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4599,5328,5953,6058,5361,6027,5248,5356,5241,5354,5620,5554.6,1392,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6648,7353,7863,7827,7435,7874,7436,7538,7348,7410,7373,7545.7,1393,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3372,4694,4748,4723,4799,4785,4762,4764,4733,4769,4654,4743.1,1394,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194964,199655,199255,199602,199554,199463,199358,199320,199776,199322,199701,199500.6,1395,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3832,5119,5208,5171,5262,5179,5255,5178,5272,5184,5117,5194.5,1396,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194304,198633,198764,198552,198558,198246,199117,198658,198355,198324,198868,198607.5,1397,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3404,4654,4767,4715,4799,4726,4744,4714,4701,4771,4631,4722.2,1398,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,189225,190354,190633,190721,190872,190546,191391,190772,190620,190960,190690,190755.9,1399,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3298,4580,4684,4638,4631,4590,4793,4650,4862,4632,4579,4663.9,1400,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6102,7334,7799,7786,7340,7794,7381,7341,7381,7283,7286,7472.5,1401,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3285,4073,4566,4552,4103,4599,4101,4100,4126,4111,4075,4240.6,1402,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6719,8190,8767,8659,8180,8660,7950,8173,8372,8150,8117,8321.8,1403,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3278,3932,4583,4557,3963,4676,3941,3971,3903,3976,3943,4144.5,1404,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3357,4029,4668,4646,4048,4667,4140,4052,4099,4031,4030,4241.0,1405,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4362,5363,6064,6007,5417,6019,5206,5420,5173,5426,5361,5545.6,1406,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6020,7336,7818,7773,7307,7784,7308,7328,7274,7272,7316,7451.6,1407,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3266,4646,4747,4753,4722,4712,4756,4723,4770,4687,4613,4712.9,1408,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76031,77862,78088,78133,77916,78376,78523,78263,78770,78132,77858,78192.1,1409,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76091,78595,78276,78510,78098,78508,77532,78164,78208,78273,78594,78275.8,1410,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75975,77092,77203,77107,77094,77138,77104,77197,77348,77147,77310,77174.0,1411,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5872,7215,7743,7766,7317,7747,7326,7258,7313,7262,7297,7424.4,1412,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5878,7270,7651,7643,7116,7637,7301,7111,7198,7138,7117,7318.2,1413,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4789,6304,6302,6325,6255,6343,6282,6275,6216,6239,6234,6277.5,1414,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4544,6351,6423,6245,6268,6250,6303,6435,6339,6274,6207,6309.5,1415,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5881,7359,7774,7781,7347,8048,7453,7331,7318,7397,7328,7513.6,1416,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5943,7393,7782,7771,7383,7813,7279,7372,7355,7491,7349,7498.8,1417,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11056,12149,12450,12361,12466,12222,12295,12458,12313,12447,12209,12337.0,1418,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3371,4589,4668,4784,4770,4597,4632,4682,4654,4635,4567,4657.8,1419,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6202,7216,7707,7776,7265,7738,7413,7259,7319,7255,7251,7419.9,1420,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5437,6151,6211,6189,6204,6220,6254,6117,6139,6163,6171,6181.9,1421,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6064,7319,7819,7764,7369,7836,7493,7301,7522,7356,7349,7512.8,1422,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10037,11157,10989,11076,11472,11256,11076,11079,11018,11204,11072,11139.9,1423,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76534,78754,78283,79059,78580,78604,78257,78854,78770,78870,78653,78668.4,1424,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3338,4616,4653,4914,4641,4633,4670,4651,4648,4613,4549,4658.8,1425,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6218,7277,7827,7740,7304,7744,7358,7290,7286,7284,7273,7438.3,1426,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3272,4036,4658,4571,4139,4683,4110,4066,4063,4065,4027,4241.8,1427,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7094,8186,8686,8674,8217,8637,8123,8173,8147,8203,8189,8323.5,1428,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3262,3930,4581,4606,3968,4623,3942,3962,3902,3979,3961,4145.4,1429,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3392,4042,4663,4657,4114,4642,4149,4064,4131,4041,4048,4255.1,1430,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4568,5332,6035,5976,5338,6011,5205,5440,5212,5400,5308,5525.7,1431,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6089,7428,7844,7851,7582,7991,7418,7463,7388,7511,7411,7588.7,1432,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3366,4682,4738,4720,4784,4711,4934,4749,4781,4806,4659,4756.4,1433,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194888,198865,198577,198860,199515,198931,198696,199318,198469,199344,199440,199001.5,1434,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3765,5194,5285,5179,5271,5232,5240,5218,5260,5200,5147,5222.6,1435,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194301,198075,198585,199048,198368,198026,198496,198411,198956,198562,197898,198442.5,1436,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3468,4675,4727,4792,4741,4679,4755,4674,4721,4693,4662,4711.9,1437,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188604,191220,190326,190262,190479,190275,190789,190129,190887,190621,190790,190577.8,1438,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3353,4571,4699,4653,4667,4645,4637,4617,4669,4602,4548,4630.8,1439,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6127,7339,7817,7892,7340,7862,7402,7385,7491,7298,7342,7516.8,1440,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3274,4044,4586,4584,4104,4644,4106,4158,4036,4133,4068,4246.3,1441,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6776,8931,8658,8666,8183,8630,8071,8173,8053,8182,8112,8365.9,1442,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3220,3960,4654,4573,3989,4596,3962,3971,3903,4008,3976,4159.2,1443,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3355,4038,4676,4645,4065,4685,4129,4069,4181,4045,4014,4254.7,1444,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4344,5380,6079,6105,5480,6112,5293,5479,5269,5442,5450,5608.9,1445,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6195,7300,7818,7829,7285,7779,7310,7264,7361,7326,7372,7464.4,1446,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3317,4758,4733,4773,4754,4703,4807,4734,4895,4685,4643,4748.5,1447,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76341,78351,78274,78588,78449,79076,78973,78469,78666,78576,78408,78583.0,1448,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76391,77972,77984,78275,78201,77995,78218,78437,77943,78412,77920,78135.7,1449,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75888,77382,77561,77304,77326,77236,77290,77474,77223,77160,77252,77320.8,1450,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5910,7302,7769,7783,7329,7789,7361,7310,7351,7359,7346,7469.9,1451,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5916,7374,7900,7907,7364,7838,7470,7341,7429,7441,7452,7551.6,1452,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4729,6106,6254,6215,6246,6261,6274,6375,6217,6167,6172,6228.7,1453,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4507,6274,6239,6183,6234,6264,6327,6192,6292,6193,6286,6248.4,1454,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5928,7415,7924,7920,7480,7874,7437,7431,7454,7482,7465,7588.2,1455,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6039,7455,7951,7870,7435,7916,7377,7435,7394,7473,7398,7570.4,1456,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10867,12223,12299,12236,12270,13278,12261,12331,12461,12170,12413,12394.2,1457,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3313,4586,4658,4799,4659,4609,4617,4679,4647,4613,4500,4636.7,1458,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6184,7188,7650,7667,7221,7730,7260,7242,7298,7170,7177,7360.3,1459,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5568,6138,6164,6257,6126,6190,6211,6096,6123,6139,6137,6158.1,1460,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5916,7260,7711,7612,7198,7657,7182,7274,7146,7221,7206,7346.7,1461,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11084,11201,10954,10962,11033,10935,10932,11089,10998,11366,11077,11054.7,1462,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76111,79763,79330,79761,79767,79595,79665,79557,79569,79548,79279,79583.4,1463,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3309,4573,4708,4641,4711,4640,4688,4621,4677,4659,4591,4650.9,1464,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6222,7313,7829,7835,7366,7861,7398,7344,7398,7429,7314,7508.7,1465,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3259,3985,4561,4542,4039,4585,4047,4027,4025,4071,3985,4186.7,1466,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7088,8179,8885,8683,8197,8765,8175,8251,8099,8213,8203,8365.0,1467,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3253,3965,4586,4576,3992,4687,3918,3997,3919,3993,4131,4176.4,1468,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3353,4017,4646,4660,4062,4672,4201,4041,4212,4076,4046,4263.3,1469,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4474,5392,6041,6056,5440,6073,5228,5421,5237,5464,5372,5572.4,1470,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5942,7330,7775,7856,7378,7839,7546,7403,7293,7377,7302,7509.9,1471,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4685,4749,4782,4736,4711,4749,4765,4792,4819,4695,4748.3,1472,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194465,198509,198450,198448,198533,198436,198601,198299,198765,198847,198382,198527.0,1473,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3752,5126,5214,5193,5271,5177,5218,5214,5184,5153,5124,5187.4,1474,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193987,199730,199546,199639,200015,199365,199822,199655,199345,199553,199599,199626.9,1475,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3354,4814,4867,4794,4816,4872,4835,4709,4920,4764,4674,4806.5,1476,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,189028,189776,189897,190185,189453,190160,189507,189604,189824,190090,189301,189779.7,1477,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3316,4584,4678,4650,4676,4636,4675,4656,4658,4605,4575,4639.3,1478,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6095,7323,7848,7787,7364,7800,7425,7362,7412,7393,7317,7503.1,1479,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3276,4024,4564,4576,4085,4601,4138,4058,4030,4081,4024,4218.1,1480,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6774,9093,8694,8623,8205,8710,8165,8206,8104,8151,8176,8412.7,1481,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3197,3997,4628,4644,4061,4618,3996,4024,3946,4033,4017,4196.4,1482,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3408,3999,4659,4636,4093,4672,4180,4080,4160,4033,4011,4252.3,1483,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4346,5449,6058,6137,5437,6055,5339,5444,5233,5460,5473,5608.5,1484,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6331,7358,7915,7830,7400,7859,7448,7352,7432,7439,7407,7544.0,1485,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3377,4720,4728,4763,4697,4684,4760,4710,4749,4684,4608,4710.3,1486,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76020,77140,77403,77335,77222,77352,77252,77546,77444,77210,77465,77336.9,1487,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76322,79172,79560,79308,79341,79644,79385,79588,79177,79274,78908,79335.7,1488,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76378,77361,77735,77390,77982,77227,77392,77356,77625,77531,77229,77482.8,1489,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6047,7372,7849,7890,7387,7863,7445,7383,7422,7392,7315,7531.8,1490,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5965,7351,7908,7849,7394,7863,7438,7357,7430,7391,7327,7530.8,1491,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4821,6226,6243,6239,6275,6246,6365,6236,6327,6216,6242,6261.5,1492,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4523,6191,6270,6248,6372,6233,6383,6247,6322,6253,6187,6270.6,1493,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5934,7317,7823,7763,7445,7777,7296,7357,7305,7356,7351,7479.0,1494,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5914,7378,7823,7902,7374,7763,7329,7373,7296,7299,7325,7486.2,1495,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11312,12303,12319,12154,12221,12301,12265,12233,12505,12151,12036,12248.8,1496,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3281,4585,4631,4622,4674,4779,4647,4642,4640,4632,4553,4640.5,1497,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6003,7256,7681,7672,7210,7664,7248,7303,7212,7309,7154,7370.9,1498,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5409,6112,6173,6162,6195,6159,6262,6210,6185,6142,6106,6170.6,1499,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5995,7200,7690,7635,7216,7680,7438,7211,7187,7298,7374,7392.9,1500,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10296,11083,10871,10804,11076,11102,11129,10949,11054,11255,10933,11025.6,1501,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76804,78104,77796,77947,78149,78244,77754,77762,77997,78050,77929,77973.2,1502,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3324,4586,4748,4640,4740,4697,4682,4675,4698,4622,4566,4665.4,1503,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6173,7300,7799,7778,7489,7841,7417,7410,7375,7343,7277,7502.9,1504,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3300,4399,4612,4605,4145,4619,4089,4081,4088,4167,4070,4287.5,1505,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7105,8136,8735,9216,8217,8938,8100,8182,8073,8976,8176,8474.9,1506,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3260,3956,4610,4547,3982,4644,3901,3990,3895,4012,3957,4149.4,1507,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3293,4018,4653,4657,4164,4639,4134,4056,4134,4046,4012,4251.3,1508,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4672,5354,5998,6009,5400,6043,5213,5423,5404,5379,5342,5556.5,1509,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5963,7375,7865,7854,7497,7944,7371,7422,7418,7468,7400,7561.4,1510,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3388,4712,4833,4729,4776,4731,4868,4790,4788,4711,4709,4764.7,1511,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194309,198530,198667,199162,199274,198878,198837,198867,198864,198932,198724,198873.5,1512,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3794,5102,5153,5184,5165,5187,5256,5208,5164,5116,5082,5161.7,1513,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194309,198876,198919,198823,198805,199107,199248,199243,199165,199139,199247,199057.2,1514,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3391,4681,4784,4795,4771,4777,4754,4706,4825,4697,4607,4739.7,1515,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188758,190150,190279,190007,190385,190063,190253,190414,190280,190046,190126,190200.3,1516,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3339,4632,4801,4837,4689,4606,4668,4650,4682,4632,4660,4685.7,1517,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6184,7190,7704,7706,7190,7848,7288,7339,7422,7218,7194,7409.9,1518,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3601,3970,4586,4549,4033,4591,4053,4075,4021,4065,4030,4197.3,1519,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6819,8088,8572,8603,8108,8524,7984,8110,8440,8058,8108,8259.5,1520,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3251,3929,4618,4538,3947,4600,3929,3916,3880,3938,3952,4124.7,1521,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3307,4111,4636,4637,4086,4652,4123,4042,4171,4027,3991,4247.6,1522,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4411,5329,5985,6013,5380,6013,5196,5385,5271,5426,5362,5536.0,1523,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6337,6939,7386,7392,6959,7393,6876,6954,6951,6885,6904,7063.9,1524,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3281,4669,4723,4699,4710,4776,4783,4730,4881,4707,4654,4733.2,1525,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76095,78381,77669,77819,78308,78355,77854,78333,77881,78244,78090,78093.4,1526,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76235,78307,78409,78176,78620,78460,78672,78369,78819,77954,78626,78441.2,1527,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76826,77621,77653,77599,77674,77265,77650,77512,77560,77467,77736,77573.7,1528,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5909,7317,7753,7776,7304,7812,7352,7325,7341,7315,7260,7455.5,1529,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5934,6844,7306,7329,6840,7281,6849,6854,6953,6850,6774,6988.0,1530,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4754,6296,6260,6278,6224,6194,6265,6222,6267,6162,6147,6231.5,1531,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4518,6186,6222,6189,6304,6226,6285,6300,6318,6135,6144,6230.9,1532,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5865,6883,7302,7331,6879,7338,6820,6865,6852,6901,6858,7002.9,1533,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5843,6880,7293,7301,6852,7264,6880,6908,6845,6869,6847,6993.9,1534,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10965,11951,11690,11641,11639,11718,11702,11797,11659,11776,11555,11712.8,1535,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3322,4102,4196,4107,4192,4193,4143,4102,4178,4140,4078,4143.1,1536,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6162,6639,7178,7158,6819,7180,6734,6902,6816,6737,6690,6885.3,1537,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5445,5609,5538,5570,5510,5575,5519,5601,5584,5530,5527,5556.3,1538,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5926,6902,7301,7312,6906,7368,6888,6951,6948,6896,6942,7041.4,1539,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10240,10988,11013,10952,11172,10878,11147,10990,10899,10795,11158,10999.2,1540,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76309,77946,77611,77691,77714,77733,77719,78029,77570,77711,77916,77764.0,1541,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3306,4583,4644,4639,4626,4627,4722,4617,4660,4617,4582,4631.7,1542,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6205,6816,7294,7215,6775,7329,6854,6801,6840,6819,6798,6954.1,1543,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3315,3639,4081,4077,3601,4145,3565,3573,3606,3595,3601,3748.3,1544,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7145,8098,8612,9072,8167,8850,8031,8863,8027,8118,8091,8392.9,1545,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3200,3928,4670,4577,3962,4608,3922,3927,3872,3964,3934,4136.4,1546,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3349,3999,4649,4663,4034,4638,4115,4073,4135,4078,4028,4241.2,1547,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4483,5247,5939,5925,5293,5942,5126,5312,5126,5295,5238,5444.3,1548,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5999,6939,7402,7437,6928,7514,6921,7124,7049,6953,6929,7119.6,1549,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3366,4680,4867,4767,4747,4706,4812,4733,4800,4705,4690,4750.7,1550,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194639,198777,198639,198737,198758,198631,199007,198814,198912,198840,198704,198781.9,1551,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3733,4744,4709,4731,4710,4799,4726,4695,4744,4694,4714,4726.6,1552,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194325,199132,198842,198455,198825,198567,199114,199111,198854,198764,199165,198882.9,1553,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3380,4211,4263,4246,4292,4235,4258,4236,4267,4217,4366,4259.1,1554,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188772,189317,189332,189998,189873,189163,189387,189638,189492,189579,189412,189519.1,1555,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3361,4178,4200,4179,4179,4133,4167,4163,4321,4133,4107,4176.0,1556,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6218,6915,7359,7360,6896,7352,6967,6928,6986,6960,6878,7060.1,1557,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3283,3642,4101,4112,3584,4154,3605,3608,3605,3639,3648,3769.8,1558,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6840,7741,8149,8166,7959,8163,7626,7727,7564,7695,7681,7847.1,1559,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3183,3817,4554,4485,3896,4490,3859,3870,3830,3931,3947,4067.9,1560,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3439,4073,4679,4601,4037,4691,4104,4004,4068,4019,3977,4225.3,1561,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4352,5006,5579,5541,4930,5582,4775,4940,4763,4961,4954,5103.1,1562,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6210,6825,7245,7203,6849,7292,6798,6812,6882,6866,6860,6963.2,1563,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3321,4628,4707,4698,4692,4700,4882,4694,4669,4699,4661,4703.0,1564,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76347,77623,77668,77427,77781,77489,77469,77433,77378,77435,77300,77500.3,1565,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76325,78136,77981,77922,78129,77759,78433,77806,77808,78228,78034,78023.6,1566,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76374,78272,78586,78355,78388,78387,78165,78505,78335,78529,78527,78404.9,1567,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6038,7183,7693,7669,7251,7633,7240,7216,7310,7218,7191,7360.4,1568,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5846,6879,7345,7333,6894,7360,6967,6931,6936,6893,6858,7039.6,1569,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4900,6130,6309,6225,6168,6289,6312,6212,6297,6288,6204,6243.4,1570,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4540,6226,6278,6338,6219,6296,6252,6222,6521,6232,6025,6260.9,1571,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6006,6946,7373,7343,6931,7380,6875,6931,7031,6925,6919,7065.4,1572,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5812,6947,7376,7374,6953,7383,6921,6939,6934,6953,6913,7069.3,1573,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11049,12580,12108,11608,11731,11715,11772,11936,11662,11686,11647,11844.5,1574,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3442,4136,4140,4144,4154,4118,4158,4138,4174,4141,4091,4139.4,1575,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6050,6740,7234,7248,6729,7150,6747,6701,6833,6713,6793,6888.8,1576,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5466,5563,5526,5554,5495,5542,5525,5526,5555,5515,5582,5538.3,1577,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5996,6990,7292,7310,6830,7306,6848,6835,6813,6839,6848,6991.1,1578,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10563,11007,11319,11010,11072,11334,11128,11049,11228,11074,11270,11149.1,1579,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76374,77772,77685,78298,78341,77925,78425,78379,78255,78158,78090,78132.8,1580,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3312,4544,4663,4631,4658,4596,4626,4595,4648,4631,4537,4612.9,1581,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6153,7036,7447,7452,6915,7341,6968,7025,6955,6901,6921,7096.1,1582,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3316,3568,4079,4073,3522,4170,3542,3567,3559,3619,3582,3728.1,1583,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7090,8026,8547,8691,8112,8563,8049,8074,7963,8151,8031,8220.7,1584,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3252,3889,4562,4525,3971,4547,3882,3937,3885,3948,3918,4106.4,1585,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3297,3944,4586,4652,3984,4641,4068,4008,4056,3967,3951,4185.7,1586,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4546,5322,5869,5875,5322,5914,5090,5266,5136,5306,5246,5434.6,1587,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6235,6894,7303,7324,6930,7344,6911,6864,6870,6901,6914,7025.5,1588,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3446,4691,4797,4760,4846,4694,4768,4726,4811,4777,4683,4755.3,1589,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,195144,199958,199911,199996,199554,199445,199240,199789,199966,199786,199602,199724.7,1590,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3749,4705,4733,4646,4773,4687,4674,4636,4713,4663,4649,4687.9,1591,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193864,198151,198223,198495,198435,198561,198501,198356,198928,198951,198316,198491.7,1592,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3347,4303,4289,4300,4295,4271,4329,4306,4326,4275,4244,4293.8,1593,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188681,189166,189851,189663,190039,189036,190432,189794,189591,189136,189250,189595.8,1594,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3307,4121,4189,4158,4263,4162,4186,4197,4178,4162,4119,4173.5,1595,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6045,6629,7221,7177,6651,7195,6674,6630,6686,6617,6631,6811.1,1596,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3305,3566,4066,4043,3562,4089,3557,3581,3564,3590,3589,3720.7,1597,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6798,7738,8170,8104,7741,8134,7601,7700,7547,7685,7770,7819.0,1598,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3263,3507,4133,4083,3511,4134,3445,3489,3463,3532,3508,3680.5,1599,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3300,3558,4164,4161,3600,4159,3681,3586,3678,3553,3567,3770.7,1600,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4369,4902,5510,5499,4918,5595,4736,4892,4723,4916,4952,5064.3,1601,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6150,6986,7573,7383,6972,7439,6948,6963,6972,6998,6998,7123.2,1602,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3310,4640,4750,4726,4698,4730,4755,4706,4725,4684,4656,4707.0,1603,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76341,77593,78424,78089,77690,78295,78946,77896,78504,77985,78384,78180.6,1604,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76230,77966,78102,77864,78449,78010,78526,77778,78036,78246,77816,78079.3,1605,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76483,77783,77353,77604,77785,78157,77944,77574,77864,77724,77790,77757.8,1606,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5877,6887,7314,7308,6982,7336,6933,6872,6931,6954,6837,7035.4,1607,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5897,7024,7358,7347,6896,7365,6932,6895,6964,6899,6894,7057.4,1608,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4729,6275,6217,6199,6147,6214,6247,6160,6169,6197,6119,6194.4,1609,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4556,6217,6232,6237,6212,6256,6256,6179,6290,6277,6091,6224.7,1610,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5909,7044,7377,7321,7005,7341,6907,6904,6988,6928,7011,7082.6,1611,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5897,6945,7402,7307,6931,7366,6833,6923,6889,6939,6903,7043.8,1612,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11050,11933,11723,11696,11685,11735,11758,11659,11852,11688,11678,11740.7,1613,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3268,4151,4176,4187,4233,4164,4177,4193,4273,4151,4223,4192.8,1614,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6170,6730,7152,7159,6766,7220,6764,6756,6848,6794,6753,6894.2,1615,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5428,5516,5573,5487,5499,5596,5523,5523,5481,5492,5512,5520.2,1616,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5984,6748,7174,7170,6756,7211,6744,6759,6749,6755,6737,6880.3,1617,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10125,11229,11233,11134,10960,10978,10985,10906,11318,11160,11035,11093.8,1618,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76305,77663,77600,77389,77993,77773,77666,78144,77483,77769,77439,77691.9,1619,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3301,4147,4213,4165,4240,4129,4177,4170,4198,4161,4137,4173.7,1620,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6033,6885,7318,7314,6894,7298,6956,6865,6938,6887,6872,7022.7,1621,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3279,3590,4094,4070,3564,4139,3592,3610,3570,3603,3785,3761.7,1622,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7320,7762,8161,8207,7722,8142,7599,7770,7632,7757,7737,7848.9,1623,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3232,3477,4075,4071,3461,4120,3437,3511,3528,3488,3488,3665.6,1624,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3358,3555,4145,4154,3545,4127,3760,3526,3640,3549,3633,3763.4,1625,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4531,4876,5511,5487,4931,5589,4740,4907,4797,4917,4870,5062.5,1626,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6088,6796,7257,7223,6855,7270,6776,6814,6828,6926,6960,6970.5,1627,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3384,4691,4754,4717,4743,4686,4787,4731,4742,4688,4645,4718.4,1628,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193893,198363,198844,198486,198596,198890,198770,199161,198349,199216,198749,198742.4,1629,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3743,4671,4774,4704,4913,4715,4768,4666,4746,4747,4680,4738.4,1630,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194423,197321,197542,197437,197722,198128,197353,197558,197435,197632,197454,197558.2,1631,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3372,4218,4271,4223,4255,4204,4249,4298,4307,4232,4184,4244.1,1632,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188487,189377,189567,189137,189171,189455,189461,189443,189212,189133,189351,189330.7,1633,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3299,4152,4188,4228,4213,4111,4216,4147,4203,4190,4109,4175.7,1634,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6062,6767,7229,7316,6833,7249,6897,6825,6879,6772,6810,6957.7,1635,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3261,3581,4106,4112,3568,4134,3576,3576,3562,3571,3608,3739.4,1636,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6816,7650,8177,8115,7708,8160,7578,7657,7573,7653,7637,7790.8,1637,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3260,3480,4176,4050,3451,4181,3412,3456,3414,3462,3577,3665.9,1638,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3345,3529,4152,4111,3534,4140,3627,3548,3635,3545,3525,3734.6,1639,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4415,4909,5486,5522,4967,5543,4710,4885,4715,4953,4945,5063.5,1640,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6206,6934,7372,7385,6898,7357,6871,6935,6963,6955,6945,7061.5,1641,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3315,4647,4738,4694,4678,4775,4763,4673,4689,4656,4608,4692.1,1642,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76183,78123,77474,77663,77999,77525,77786,78388,77432,77747,77744,77788.1,1643,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76280,77083,77268,77410,77452,77381,77187,77386,77298,77248,77464,77317.7,1644,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75887,77484,77730,77212,77010,77390,77602,77669,77368,77599,77494,77455.8,1645,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5887,6777,7245,7214,6794,7241,6806,6799,6850,6857,6779,6936.2,1646,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5968,6905,7283,7330,6962,7328,6943,6884,6943,6987,6880,7044.5,1647,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4860,6077,6175,6115,6194,6164,6223,6149,6104,6168,6082,6145.1,1648,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4584,6317,6251,6236,6286,6139,6275,6162,6273,6259,6193,6239.1,1649,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5822,6974,7374,7389,6972,7391,7064,6964,6921,6885,6937,7087.1,1650,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5960,6811,7241,7228,6814,7481,6801,6870,6780,6814,6834,6967.4,1651,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11154,11657,11631,11598,11745,11682,11834,12467,11721,11744,11621,11770.0,1652,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3290,4123,4190,4164,4153,4171,4144,4130,4248,4134,4097,4155.4,1653,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5951,6737,7222,7189,6770,7196,6799,6782,6827,6783,6762,6906.7,1654,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5342,5612,5529,5574,5720,5556,5776,5540,5542,5570,5535,5595.4,1655,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5833,6950,7282,7290,6986,7341,6796,6803,6796,6800,6891,6993.5,1656,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10002,11059,10963,10963,11590,11141,11421,10893,11090,10983,10943,11104.6,1657,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76044,77484,77626,77699,77465,77406,77612,77245,77896,77723,77423,77557.9,1658,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3345,4121,4145,4184,4146,4119,4209,4398,4261,4169,4230,4198.2,1659,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6151,6838,7283,7308,6910,7302,6862,6864,6890,6841,6810,6990.8,1660,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3311,3621,4145,4104,3602,4139,3748,3616,3572,3669,3585,3780.1,1661,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7159,7649,8896,8170,7696,8148,7643,7676,7578,7707,7683,7884.6,1662,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3245,3445,4062,4032,3433,4064,3388,3500,3392,3438,3437,3619.1,1663,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3388,3540,4128,4173,3538,4122,3603,3534,3680,3553,3529,3740.0,1664,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4463,4967,5525,5635,4953,5567,4755,4909,4878,4833,4905,5092.7,1665,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5883,6969,7445,7399,6971,7477,6938,6974,6930,6889,6966,7095.8,1666,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3408,4681,4733,4811,4733,4723,4755,4920,4761,4714,4666,4749.7,1667,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194370,198935,199519,198772,199081,198873,198866,198050,198776,198766,198517,198815.5,1668,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3756,4725,4699,4682,4718,4689,4812,4706,4761,4789,4671,4725.2,1669,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194294,198880,199597,198862,198956,198947,199427,199216,199124,199316,198908,199123.3,1670,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3351,4253,4282,4246,4254,4223,4268,4281,4417,4370,4232,4282.6,1671,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188988,189832,190213,189717,191015,189804,189839,189737,190008,189765,189798,189972.8,1672,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3347,4132,4185,4175,4211,4206,4195,4182,4405,4154,4151,4199.6,1673,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6134,6922,7324,7263,6852,7319,6920,6882,6898,6853,6831,7006.4,1674,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3293,3598,4101,4106,3576,4114,3622,3594,3618,3593,3652,3757.4,1675,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6857,7799,8215,8200,7759,8210,7634,7729,7677,7751,7719,7869.3,1676,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3224,3530,4275,4113,3517,4147,3485,3510,3463,3527,3520,3708.7,1677,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3364,3534,4142,4136,3538,4224,3589,3537,3610,3509,3515,3733.4,1678,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4323,4951,5477,5555,4913,5534,4764,4910,4705,4891,4907,5060.7,1679,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6161,6954,7305,7299,6849,7326,6795,6831,6821,6884,6932,6999.6,1680,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3338,4626,4690,4722,4688,4693,4699,4687,4725,4711,4596,4683.7,1681,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76234,77688,77675,77735,78131,78189,77861,77504,77907,78816,77791,77929.7,1682,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75904,77465,77412,77474,77142,77632,77477,77523,77429,77811,77598,77496.3,1683,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76392,78542,79124,78687,78271,78272,78526,78631,78723,78731,78683,78619.0,1684,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5940,6901,7394,7341,6909,7358,6937,6882,6958,6903,6854,7043.7,1685,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5880,6882,7315,7348,6927,7379,6932,6917,6982,7001,6884,7056.7,1686,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4801,6121,6219,6125,6255,6312,6219,6228,6154,6148,6102,6188.3,1687,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4562,6324,6240,6165,6274,6146,6210,6181,6404,6283,6119,6234.6,1688,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5907,6901,7417,7312,6947,7334,6901,6908,6878,6914,6904,7041.6,1689,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5764,6941,7379,7344,6929,7367,6880,6953,6941,6995,6922,7065.1,1690,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11008,11643,11560,11533,11567,11643,11688,12566,11605,11802,11678,11728.5,1691,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3248,4132,4176,4183,4196,4129,4186,4138,4190,4141,4132,4160.3,1692,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6134,6678,7148,7091,7026,7168,6747,6742,6719,6706,6671,6869.6,1693,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5476,5550,5617,5588,5512,5836,5555,5598,5759,5522,5579,5611.6,1694,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5942,6832,7305,7324,6847,7327,6876,6859,6861,6921,6907,7005.9,1695,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11028,10874,11514,11172,11190,10957,11961,11415,11127,11045,11118,11237.3,1696,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76290,78743,78315,78134,78688,77953,78449,78316,78195,78154,77857,78280.4,1697,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3333,4166,4200,4163,4216,4135,4233,4199,4222,4183,4126,4184.3,1698,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6117,6878,7290,7298,6849,7261,7008,6866,6898,6828,6858,7003.4,1699,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3284,3606,4066,4094,3575,4092,3544,3549,3558,3571,3560,3721.5,1700,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7151,7739,8195,8140,7750,8191,7618,7747,7660,7721,7719,7848.0,1701,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3247,3429,4038,4053,3436,4082,3390,3437,3381,3473,3425,3614.4,1702,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3310,3555,4154,4141,3536,4169,3672,3633,3646,3567,3559,3763.2,1703,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4502,5157,5567,5588,4985,5605,4854,4990,4820,5002,5063,5163.1,1704,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6057,6894,7264,7334,6877,7301,6844,7032,6849,6988,6908,7029.1,1705,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3399,4705,4687,4687,4693,4643,4740,4684,4742,4667,4623,4687.1,1706,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,195009,198599,198043,198175,198337,198670,198422,198844,199507,198021,198924,198554.2,1707,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3756,4652,4731,4735,4690,4651,4924,4729,4707,4633,4706,4715.8,1708,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194874,198342,198750,198629,199180,198527,198483,198517,198766,198446,198314,198595.4,1709,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3533,4255,4264,4257,4267,4331,4254,4266,4324,4278,4414,4291.0,1710,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188605,190170,190335,190588,189887,190408,190798,190953,190495,190149,190799,190458.2,1711,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3292,4252,4143,4157,4181,4150,4179,4161,4212,4141,4097,4167.3,1712,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6025,6841,7319,7198,6819,7340,6863,6816,6845,6872,6786,6969.9,1713,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3297,3587,4091,4094,3566,4105,3595,3592,3546,3608,3566,3735.0,1714,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6868,7681,8129,8114,7848,8150,7574,7725,7608,7663,7662,7815.4,1715,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3249,3612,4140,4108,3519,4140,3498,3520,3517,3592,3543,3718.9,1716,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3335,3539,4207,4152,3565,4186,3630,3558,3679,3561,3547,3762.4,1717,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4434,4951,5644,5497,4930,5512,4741,4899,4801,4932,4889,5079.6,1718,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6180,6928,7359,7354,6913,7357,6903,6932,6936,6906,6936,7052.4,1719,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3332,4631,4687,4771,4661,4718,4722,4649,4692,4787,4598,4691.6,1720,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76116,77815,77831,77601,77689,78128,77697,77651,77955,77759,77506,77763.2,1721,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75844,77162,77641,77361,77222,77514,77788,77323,77367,77579,77626,77458.3,1722,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75882,78200,78606,78370,77980,77800,78542,78697,78445,78429,78010,78307.9,1723,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5872,6784,7222,7211,6767,7220,6810,6776,6879,6799,6743,6921.1,1724,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5956,6733,7333,7140,6715,7178,6764,6712,6787,6712,6700,6877.4,1725,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4747,6146,6196,6195,6183,6251,6256,6122,6190,6218,6140,6189.7,1726,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4584,6167,6273,6146,6376,6123,6223,6207,6190,6204,6126,6203.5,1727,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5950,6855,7224,7288,6830,7372,6792,6830,6813,6828,6800,6963.2,1728,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5939,6977,7374,7352,6956,7381,6897,6988,7055,6944,6934,7085.8,1729,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11113,11546,12369,11635,11813,11552,11559,11525,11583,11620,11658,11686.0,1730,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3285,4126,4190,4123,4204,4116,4162,4159,4198,4159,4207,4164.4,1731,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5986,6772,7235,7176,6762,7216,6828,6745,6956,6783,6784,6925.7,1732,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5434,5485,5522,5537,5454,5488,5562,5524,5671,5483,5497,5522.3,1733,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5968,6820,7230,7435,6768,7284,6792,6824,6784,6784,6845,6956.6,1734,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10144,11234,11614,10755,11075,11274,11838,11002,11051,11171,12025,11303.9,1735,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76207,78044,78561,78266,78092,78146,78018,78135,78433,78426,78147,78226.8,1736,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3325,4117,4189,4106,4145,4131,4227,4149,4174,4130,4115,4148.3,1737,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6102,6849,7331,7367,6867,7296,6956,6831,6899,6884,6854,7013.4,1738,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3319,3577,4102,4122,3592,4136,3557,3555,3565,3613,3598,3741.7,1739,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7126,7712,8950,8658,7727,8138,7640,7693,7582,7706,7712,7951.8,1740,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3202,3450,4200,4114,3447,4089,3412,3478,3392,3480,3455,3651.7,1741,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3332,3568,4188,4177,3569,4146,3652,3561,3644,3560,3564,3762.9,1742,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4531,4991,5502,5618,5045,5528,4718,4912,4696,4902,4911,5082.3,1743,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6002,6846,7269,7354,6849,7296,6789,6818,6883,6916,6842,6986.2,1744,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3419,4691,4737,4644,4688,4636,4749,4698,4719,4672,4640,4687.4,1745,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193736,200307,200098,200410,199499,200283,199232,199310,201212,200291,199371,200001.3,1746,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3748,4721,4743,4693,4689,4685,4758,4680,4755,4657,4656,4703.7,1747,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194181,199037,199361,199631,198574,198973,199140,199208,199343,198957,198983,199120.7,1748,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3423,4235,4255,4231,4261,4200,4376,4242,4282,4198,4198,4247.8,1749,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188406,190197,190664,190085,190002,189964,190152,190159,190384,190315,190043,190196.5,1750,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3375,4174,4167,4165,4178,4138,4293,4156,4213,4140,4159,4178.3,1751,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6143,6874,7304,7330,6845,7316,6920,6851,6896,6877,6839,7005.2,1752,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3295,3594,4140,4080,3623,4141,3613,3592,3609,3626,3637,3765.5,1753,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6866,7681,8190,8918,7721,8150,7616,7726,7602,7721,7692,7901.7,1754,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3235,3457,4144,4043,3466,4109,3449,3507,3412,3501,3480,3656.8,1755,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3338,3537,4167,4141,3718,4149,3613,3568,3683,3548,3539,3766.3,1756,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4331,5022,5615,5578,4979,5637,4827,4963,4781,5004,5017,5142.3,1757,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6189,6932,7331,7322,6878,7376,6927,6909,6927,6961,7026,7058.9,1758,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3310,4671,4716,4751,4732,4673,4712,4685,4651,4661,4683,4693.5,1759,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75944,77172,77270,77008,77230,77545,77385,77097,77331,77057,77365,77246.0,1760,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76015,77348,77446,77398,77419,77383,77537,77109,77189,77311,77404,77354.4,1761,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75924,78343,77184,77765,77321,78018,77670,78144,77729,77836,77874,77788.4,1762,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5954,6992,7376,7344,6892,7302,6944,6993,6989,7016,6914,7076.2,1763,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5815,6807,7310,7262,6815,7279,6838,6886,6882,6995,6785,6985.9,1764,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4808,6173,6280,6223,6294,6390,6187,6177,6338,6208,6188,6245.8,1765,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4566,6167,6236,6252,6312,6240,6381,6273,6326,6306,6256,6274.9,1766,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5850,6960,7390,7378,6989,7395,6929,6992,6964,6976,6953,7092.6,1767,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5896,6884,7292,7264,6858,7266,6821,6864,6839,6903,6855,6984.6,1768,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11505,11748,11766,11756,11605,11820,11866,11734,11880,11828,11689,11769.2,1769,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3277,4092,4134,4272,4155,4089,4110,4124,4181,4093,4090,4134.0,1770,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5997,6805,7204,7189,6775,7237,6830,6722,6847,6787,6779,6917.5,1771,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5457,5540,5736,5653,5503,5566,5560,5558,5552,5569,5564,5580.1,1772,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5932,6931,7341,7443,7014,7388,6937,6855,6861,6948,6955,7067.3,1773,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10357,10885,11124,11013,11179,10996,10832,11222,11240,11155,10872,11051.8,1774,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76472,76909,77187,77130,77012,77011,77296,77590,77476,77320,77013,77194.4,1775,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3334,4101,4316,4107,4144,4122,4153,4137,4154,4131,4107,4147.2,1776,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6218,6779,7216,7166,6727,7188,6810,6726,6806,6774,6890,6908.2,1777,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3298,3598,4088,4073,3555,4107,3556,3551,3517,3560,3585,3719.0,1778,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7144,7729,8154,9065,7713,8161,7584,7696,7590,7688,7695,7907.5,1779,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3286,3444,4032,4085,3468,4098,3417,3461,3415,3454,3470,3634.4,1780,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3314,3598,4189,4182,3630,4203,3673,3603,3760,3595,3621,3805.4,1781,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4506,4944,5530,5568,4955,5603,4751,4953,4790,4940,4950,5098.4,1782,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6031,6982,7338,7388,6899,7357,6865,6898,6869,6910,6886,7039.2,1783,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3372,4795,4748,4668,4748,4693,4738,4690,4706,4771,4667,4722.4,1784,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194340,199102,198826,199453,198884,199418,198886,199034,198956,199276,199073,199090.8,1785,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3748,4721,4711,4902,4760,4740,4808,4898,4730,4690,4773,4773.3,1786,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,195983,198396,198182,198801,198463,198285,198280,197608,198161,198192,198766,198313.4,1787,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3345,4418,4279,4222,4293,4243,4265,4248,4342,4222,4183,4271.5,1788,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188707,189354,189305,188955,189237,189250,189699,189411,189115,189804,190109,189423.9,1789,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3344,4155,4213,4215,4206,4166,4170,4275,4196,4141,4098,4183.5,1790,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6227,6871,7347,7396,6901,7277,6935,6891,6924,6869,6873,7028.4,1791,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3285,3590,4113,4065,3565,4146,3567,3668,3596,3671,3657,3763.8,1792,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6801,7798,8149,8144,7712,8147,7631,7707,7822,7898,7663,7867.1,1793,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3294,3560,4099,4083,3485,4130,3532,3484,3428,3539,3521,3686.1,1794,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3333,3623,4204,4229,3625,4330,3698,3627,3699,3615,3613,3826.3,1795,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4401,4956,5581,5506,4954,5678,4817,4947,4815,4992,4998,5124.4,1796,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6212,6941,7413,7356,6945,7427,6955,6943,6906,6976,7014,7087.6,1797,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3329,4610,4656,4730,4715,4665,4710,4746,4714,4821,4705,4707.2,1798,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76304,76941,77194,77532,77236,77163,77141,77448,78110,77235,77413,77341.3,1799,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76310,79334,79656,79901,79569,79578,79479,79802,79812,79462,79804,79639.7,1800,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76350,77420,77221,77261,77227,77223,77077,77465,77128,77273,77239,77253.4,1801,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6069,6910,7387,7382,6930,7352,7012,6922,6975,6915,6890,7067.5,1802,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5882,6871,7290,7243,6876,7357,6890,6832,6911,6856,6837,6996.3,1803,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4795,6138,6265,6119,6161,6220,6219,6289,6224,6205,6225,6206.5,1804,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4509,6071,6149,6194,6313,6130,6307,6255,6248,6199,6112,6197.8,1805,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5929,6955,7412,7297,6903,7341,6860,6966,6924,6959,6902,7051.9,1806,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5894,6888,7393,7403,6895,7394,6900,7100,6902,6987,6953,7081.5,1807,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10863,11689,11837,11694,11728,11689,11638,11703,11598,11801,11592,11696.9,1808,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3277,4105,4149,4110,4112,4127,4120,4125,4155,4218,4078,4129.9,1809,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6067,6689,7061,7089,6685,7112,6665,6643,6695,6704,6627,6797.0,1810,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5461,5569,5529,5562,5634,5564,5562,5527,5542,5542,5578,5560.9,1811,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6138,6837,7231,7214,6857,7212,6761,6797,6790,6779,6825,6930.3,1812,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10198,11139,11136,11000,10932,11120,10978,11010,11100,11279,11250,11094.4,1813,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76312,77284,77742,77633,77344,77373,77296,77420,77390,77682,77205,77436.9,1814,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3315,4129,4205,4147,4272,4147,4211,4154,4236,4276,4126,4190.3,1815,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6170,6926,7386,7471,6932,7438,6963,6933,6998,6928,6898,7087.3,1816,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3280,3610,4138,4151,3612,4191,3608,3576,3587,3620,3582,3767.5,1817,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7187,7734,8278,8194,7761,8184,7682,7725,7686,7799,7737,7878.0,1818,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3227,3515,4102,4143,3518,4133,3453,3504,3468,3523,3537,3689.6,1819,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3301,3606,4212,4166,3593,4194,3679,3589,3685,3594,3603,3792.1,1820,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4473,4918,5543,5531,4920,5547,4749,4956,4792,4930,4947,5083.3,1821,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6070,6794,7210,7243,6833,7220,6735,6798,6778,6810,6871,6929.2,1822,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3352,4668,4755,4822,4698,4722,4745,4722,4761,4750,4672,4731.5,1823,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194123,199492,199065,198981,198741,198911,199527,199214,198866,199357,199073,199122.7,1824,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3750,4634,4687,4868,4680,4645,4785,4676,4719,4640,4620,4695.4,1825,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193991,198983,199507,199089,198776,199412,199194,199058,198935,199384,199409,199174.7,1826,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4209,4260,4237,4239,4199,4460,4296,4252,4203,4171,4252.6,1827,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188587,190157,190473,190183,190825,190549,190839,190181,190806,190630,190745,190538.8,1828,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3314,4150,4232,4154,4215,4136,4231,4149,4225,4100,4108,4170.0,1829,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6045,6775,7369,7306,6790,7219,6813,6810,7004,6777,6733,6959.6,1830,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3332,3603,4081,4172,3600,4102,3596,3588,3559,3614,3662,3757.7,1831,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6830,7776,8835,8788,7704,8226,7636,7687,7651,7644,7705,7965.2,1832,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3230,3434,4039,4049,3453,4087,3493,3433,3400,3456,3451,3629.5,1833,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3312,3577,4204,4205,3610,4199,3700,3624,3702,3593,3602,3801.6,1834,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4363,4889,5495,5434,4868,5494,4726,4897,4685,4887,4905,5028.0,1835,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6385,6855,7279,7263,6832,7360,6843,6844,6808,6839,6884,6980.7,1836,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3294,4613,4719,4680,4684,4678,4716,4643,4689,4637,4585,4664.4,1837,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76269,77586,77692,77328,77517,77588,77774,77533,77774,77536,77656,77598.4,1838,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76399,77842,77760,77956,77702,77902,77963,77602,78281,77957,77833,77879.8,1839,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76569,77908,78281,77883,78372,77925,77925,78213,77837,78078,77970,78039.2,1840,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5979,6827,7297,7197,6788,7436,6852,6831,6876,6820,6873,6979.7,1841,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5953,6872,7383,7362,6930,7306,6966,6921,6982,6909,6968,7059.9,1842,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4711,6227,6350,6212,6201,6208,6310,6291,6495,6169,6236,6269.9,1843,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4582,6213,6284,6226,6293,6289,6285,6302,6293,6247,6249,6268.1,1844,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5948,6857,7291,7350,6848,7299,6839,6913,6805,6989,6902,7009.3,1845,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5903,6860,7337,7308,6818,7263,6788,7035,6832,6850,6890,6998.1,1846,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10880,11562,11636,11778,12410,11793,11635,11551,11634,11735,11565,11729.9,1847,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3282,4136,4178,4122,4130,4129,4200,4145,4154,4144,4075,4141.3,1848,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5995,6865,7256,7278,6820,7216,6806,6804,6946,6796,6756,6954.3,1849,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5417,5580,5614,5732,5509,5577,5526,5516,5582,5500,5508,5564.4,1850,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5968,6819,7415,7315,6953,7321,6867,6822,6857,6922,6824,7011.5,1851,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10342,10867,11022,10920,11110,10962,11144,10975,11057,11187,11007,11025.1,1852,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76267,77515,77341,77407,77462,77870,77633,77752,77460,77840,77493,77577.3,1853,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3386,4107,4149,4165,4171,4095,4187,4134,4157,4286,4151,4160.2,1854,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6300,6976,7334,7315,6861,7298,6958,6904,6923,6887,6862,7031.8,1855,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3279,3614,4088,4113,3592,4113,3566,3585,3582,3637,3580,3747.0,1856,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7198,7720,8191,8140,7760,8190,7663,7741,7610,7758,7711,7848.4,1857,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3190,3541,4121,4123,3544,4141,3470,3542,3495,3520,3520,3701.7,1858,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3358,3576,4182,4202,3569,4231,3677,3589,3681,3587,3595,3788.9,1859,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4510,4862,5428,5503,4913,5514,4711,4886,4780,4953,4885,5043.5,1860,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5896,6926,7358,7379,6930,7382,6882,6918,6900,6953,6942,7057.0,1861,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3504,4716,4762,4717,4724,4734,4764,4758,4708,4688,4631,4720.2,1862,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194241,198760,198311,198428,198271,198473,198736,198019,199079,198659,198791,198552.7,1863,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3761,4662,4749,4660,4733,4705,4787,4716,4763,4637,4640,4705.2,1864,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193819,198624,198712,198892,198818,198670,198914,199010,199729,199314,199009,198969.2,1865,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3381,4228,4257,4241,4224,4200,4267,4225,4267,4196,4187,4229.2,1866,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188621,189471,189549,189172,189856,189223,190275,189265,189458,189224,189621,189511.4,1867,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3340,4214,4176,4143,4194,4121,4189,4292,4210,4123,4088,4175.0,1868,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6048,6863,7315,7306,6830,7314,6867,6838,6895,6813,6829,6987.0,1869,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3308,3616,4116,4105,3569,4129,3593,3596,3586,3606,3655,3757.1,1870,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6886,7701,8260,8166,7720,8173,7630,7731,7657,7690,7711,7843.9,1871,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3220,3713,4130,4133,3523,4220,3500,3522,3479,3548,3524,3729.2,1872,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3334,3569,4162,4170,3580,4165,3697,3564,3717,3568,3549,3774.1,1873,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4334,4973,5568,5550,4955,5603,4796,5085,4807,4994,5008,5133.9,1874,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6125,6987,7421,7363,6919,7404,6926,6973,6948,6985,7082,7100.8,1875,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3325,4605,4694,4664,4686,4656,4747,4691,4729,4759,4626,4685.7,1876,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76361,77118,77051,77064,77331,77493,77433,76742,77005,77130,76989,77135.6,1877,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76713,78657,77781,78403,77846,78273,77498,78508,78029,78328,78437,78176.0,1878,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75814,78135,77893,78251,78033,78567,78255,78392,78249,78159,78109,78204.3,1879,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5872,6759,7230,7195,6715,7183,6759,6920,6789,6728,6786,6906.4,1880,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5897,6994,7203,7204,6772,7232,6827,6880,6830,6799,6799,6954.0,1881,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4798,6205,6256,6340,6214,6325,6231,6200,6179,6200,6114,6226.4,1882,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4537,6199,6284,6284,6275,6200,6338,6222,6240,6357,6203,6260.2,1883,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5959,6921,7329,7585,6878,7319,6911,6888,7054,6972,6851,7070.8,1884,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5746,6913,7378,7363,6954,7356,6971,6901,6946,6967,6925,7067.4,1885,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10937,11704,11545,11637,11537,11799,11866,11621,11663,11770,11665,11680.7,1886,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3307,4167,4258,4074,4187,4075,4109,4082,4135,4256,4048,4139.1,1887,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6086,6711,7151,7178,6691,7185,6780,6700,6763,6723,6699,6858.1,1888,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5456,5514,5520,5553,5505,5572,5608,5532,5524,5514,5550,5539.2,1889,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5922,6894,7381,7285,6904,7368,6893,6888,7008,6901,6896,7041.8,1890,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10393,11068,10994,11122,10763,10997,11165,10959,11168,11289,11003,11052.8,1891,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76069,77746,77653,77893,77771,78248,77821,77912,77877,77889,77633,77844.3,1892,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3298,4122,4161,4099,4164,4123,4143,4133,4223,4132,4089,4138.9,1893,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6135,6816,7216,7247,6836,7274,6870,6855,6871,6815,6818,6961.8,1894,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3331,3595,4089,4270,3583,4097,3548,3590,3640,3562,3581,3755.5,1895,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7172,7676,8116,8097,7662,8087,7578,7640,7633,7667,7666,7782.2,1896,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3246,3515,4108,4101,3581,4315,3424,3521,3424,3510,3493,3699.2,1897,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3318,3643,4259,4199,3666,4228,3727,3619,3727,3616,3612,3829.6,1898,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4493,4931,5545,5519,4974,5607,4740,4974,4755,4949,4983,5097.7,1899,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6042,6889,7296,7374,6859,7353,6846,6903,6885,6890,6997,7029.2,1900,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3389,4626,4806,4738,4749,4807,4755,4708,4722,4651,4626,4718.8,1901,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194965,199061,199344,199027,199125,199083,198559,198904,199080,199127,199126,199043.6,1902,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3838,4608,4678,4643,4670,4687,4698,4703,4747,4632,4685,4675.1,1903,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194546,198678,198614,199261,198845,199413,199155,199246,198948,198893,198817,198987.0,1904,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3333,4230,4259,4212,4251,4194,4316,4245,4424,4232,4177,4254.0,1905,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188844,189930,190456,189910,190631,190331,190122,189666,189758,189700,190313,190081.7,1906,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3300,4146,4167,4131,4162,4123,4160,4115,4167,4233,4075,4147.9,1907,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6232,6949,7625,7289,6914,7352,7009,6924,6973,6891,6920,7084.6,1908,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3309,3600,4060,4076,3617,4094,3644,3528,3547,3584,3559,3730.9,1909,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6832,7692,8191,8198,7806,8168,7583,7729,7562,7675,7749,7835.3,1910,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3234,3517,4208,4138,3543,4157,3503,3552,3498,3555,3586,3725.7,1911,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3409,3540,4166,4176,3574,4190,3643,3559,3665,3564,3538,3761.5,1912,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4398,4970,5492,5587,4962,5566,4763,4956,4765,4990,4995,5104.6,1913,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6373,6958,7409,7404,6930,7421,6946,6973,6938,6970,6967,7091.6,1914,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3324,4640,4722,4738,4698,4677,4714,4717,4689,4683,4624,4690.2,1915,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76242,78529,79043,78441,78569,78606,78269,78257,78296,78658,78843,78551.1,1916,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75953,78238,77770,78489,77966,77961,78051,77959,78261,78352,78165,78121.2,1917,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76573,77589,77770,77794,77965,77679,77428,77288,77749,78239,77512,77701.3,1918,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5876,6846,7343,7210,6816,7269,6852,6867,6907,6864,6827,6980.1,1919,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5901,6885,7257,7283,6832,7251,6872,6798,6977,6841,6858,6985.4,1920,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4798,6130,6191,6243,6199,6146,6190,6165,6258,6236,6100,6185.8,1921,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4608,5992,6252,6126,6183,6150,6129,6175,6242,6211,6092,6155.2,1922,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5976,6906,7381,7337,6945,7364,6863,6940,6903,6976,6899,7051.4,1923,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5881,6896,7351,7347,6944,7416,6869,7114,6889,6925,7030,7078.1,1924,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11204,11717,11619,11989,11577,11889,11645,11606,11528,11554,12050,11717.4,1925,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3259,4215,4186,4135,4182,4127,4180,4165,4200,4165,4098,4165.3,1926,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6086,6786,7275,7290,6764,7249,6838,6898,6856,6830,6789,6957.5,1927,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5424,5583,5491,5516,5503,5570,5512,5536,5539,5519,5602,5537.1,1928,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5922,6915,7182,7227,6751,7232,6742,6792,6727,6770,6828,6916.6,1929,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10252,11097,11307,11044,11010,10978,11224,10984,10966,10989,11171,11077.0,1930,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76166,78157,77727,77771,78372,78874,78425,77800,78303,78197,78515,78214.1,1931,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3333,4193,4152,4145,4152,4114,4179,4155,4186,4154,4115,4154.5,1932,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6124,6862,7301,7276,6877,7360,6948,6927,6992,6894,6899,7033.6,1933,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3276,3601,4107,4140,3616,4140,3597,3598,3587,3567,3586,3753.9,1934,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7197,7718,8185,8164,7708,8132,7660,7744,7621,7724,7708,7836.4,1935,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3298,3481,4079,4089,3493,4095,3431,3458,3495,3487,3485,3659.3,1936,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3363,3586,4205,4197,3580,4179,3680,3580,3665,3592,3574,3783.8,1937,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4482,4992,5538,5573,5007,5615,4787,5018,4778,4968,4972,5124.8,1938,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5987,6877,7274,7283,6810,7284,6826,6809,6793,6856,6844,6965.6,1939,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3438,4723,4706,4718,4738,4665,4752,4728,4730,4715,4699,4717.4,1940,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194111,198703,198389,198454,198659,198129,198170,198235,197816,198314,198078,198294.7,1941,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3767,4693,4655,4581,4672,4779,4685,4650,4691,4700,4694,4680.0,1942,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193879,198761,199284,199074,199401,199089,199124,199132,198933,198754,198937,199048.9,1943,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3346,4228,4279,4245,4291,4205,4259,4311,4297,4373,4311,4279.9,1944,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188630,190312,189388,189304,190280,189473,189418,189288,189444,189345,189158,189541.0,1945,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3309,4263,4165,4228,4194,4126,4164,4143,4196,4149,4188,4181.6,1946,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6057,6913,7379,7369,6907,7358,6957,6878,6945,7007,6840,7055.3,1947,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3252,3607,4098,4291,3581,4130,3594,3583,3578,3625,3623,3771.0,1948,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6844,7647,8157,8180,7722,8176,7584,7704,7603,7676,7665,7811.4,1949,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3283,3420,4037,4051,3441,4085,3416,3547,3387,3491,3440,3631.5,1950,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3432,3583,4248,4158,3591,4348,3648,3705,3688,3565,3579,3811.3,1951,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4382,4860,5607,5464,4883,5502,4781,4839,4672,4871,4963,5044.2,1952,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6222,6899,7293,7246,6907,7290,6827,6806,6943,6848,6898,6995.7,1953,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3318,4789,4688,4661,4685,4724,4758,4688,4682,4679,4616,4697.0,1954,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76167,77494,77446,77428,77288,77275,77324,77440,77290,77238,77244,77346.7,1955,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76558,77410,77552,77432,77378,77321,77430,77600,77313,77363,77398,77419.7,1956,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76740,77341,77491,77231,77450,77083,77168,77364,77241,77258,77243,77287.0,1957,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5935,6835,7345,7285,6838,7307,6923,6835,6892,6843,6826,6992.9,1958,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5956,6702,7135,7157,6736,7141,6803,6710,6767,6707,6757,6861.5,1959,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4773,6146,6329,6193,6133,6238,6328,6156,6252,6151,6164,6209.0,1960,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4524,6143,6302,6295,6225,6136,6203,6274,6202,6197,6138,6211.5,1961,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5853,6952,7494,7350,6973,7405,6907,6972,6947,6948,6952,7090.0,1962,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5915,6822,7269,7276,6826,7231,6789,6834,6789,6857,6757,6945.0,1963,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10998,11737,11680,11608,11603,11629,11660,11738,11638,11699,11730,11672.2,1964,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3313,4159,4188,4118,4165,4138,4162,4174,4306,4143,4085,4163.8,1965,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6100,6794,7218,7228,6778,7248,6820,6982,6850,6792,6781,6949.1,1966,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5403,5544,5579,5605,5825,5549,5555,5559,5503,5516,5567,5580.2,1967,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5854,6853,7277,7315,6882,7307,6953,6869,6807,6880,6900,7004.3,1968,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10218,11017,10890,11114,10853,11036,11671,10996,11010,11081,11112,11078.0,1969,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76294,77206,77735,77262,77446,77480,77301,77371,77314,77362,77146,77362.3,1970,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3350,4155,4149,4113,4147,4103,4194,4148,4178,4157,4127,4147.1,1971,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6231,6684,7109,7112,6666,7184,6740,6686,6742,6768,6675,6836.6,1972,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3309,3559,4091,4304,3578,4123,3572,3600,3609,3626,3664,3772.6,1973,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7201,7702,8122,8143,7683,8142,7585,7687,7604,7672,7682,7802.2,1974,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3256,3496,4099,4097,3481,4098,3430,3518,3453,3540,3489,3670.1,1975,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3333,3610,4227,4206,3614,4215,3740,3598,3704,3613,3622,3814.9,1976,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4495,4913,5475,5512,4891,5519,4709,4901,4713,4921,4952,5050.6,1977,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6006,6877,7347,7344,6855,7493,6873,6900,6852,6904,6891,7033.6,1978,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3416,4653,4734,4851,4874,4686,4721,4704,4759,4687,4682,4735.1,1979,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193787,197415,197217,197938,197567,197779,197337,197532,197303,197528,197655,197527.1,1980,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3738,4759,4920,4657,4744,4696,4762,4724,4713,4690,4827,4749.2,1981,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194033,198313,197838,198303,198101,197954,198870,198120,198363,198448,198459,198276.9,1982,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3384,4221,4245,4214,4256,4215,4237,4232,4276,4203,4205,4230.4,1983,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188852,189348,189561,189388,189291,189634,189561,189139,189587,190779,189703,189599.1,1984,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3508,4149,4184,4163,4174,4144,4179,4163,4182,4129,4244,4171.1,1985,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6216,6899,7309,7325,6839,7335,6907,6925,6936,6879,6868,7022.2,1986,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3282,3586,4118,4099,3579,4125,3592,3634,3598,3681,3641,3765.3,1987,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6861,7796,8183,8221,8230,8144,7657,7749,7637,7713,7879,7920.9,1988,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3231,3493,4065,4096,3483,4103,3435,3469,3424,3591,3506,3666.5,1989,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3348,3578,4182,4315,3587,4218,3682,3654,3681,3595,3585,3807.7,1990,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4374,4972,5603,5581,4958,5582,4832,4959,4812,5046,5012,5135.7,1991,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6176,6924,7463,7363,6896,7328,6888,6941,6973,6901,6902,7057.9,1992,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3336,4617,4726,4672,4676,4753,4733,4691,4745,4660,4649,4692.2,1993,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75920,78271,77909,77696,78458,78032,78121,77851,77974,78340,77824,78047.6,1994,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76337,79150,79498,79283,79286,79315,79444,79682,79545,79143,79479,79382.5,1995,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76087,77389,77547,77060,77235,77252,77502,77095,76945,77084,77199,77230.8,1996,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6064,6883,7292,7370,6883,7303,6943,6856,7100,6909,6888,7042.7,1997,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5904,6807,7222,7195,6818,7273,6865,6795,6878,6801,6795,6944.9,1998,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4785,6100,6151,6213,6211,6201,6326,6193,6235,6127,6153,6191.0,1999,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4554,6109,6213,6099,6234,6283,6271,6213,6284,6299,6182,6218.7,2000,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5955,6954,7474,7374,6942,7391,6986,6950,6977,6958,6923,7092.9,2001,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5828,6970,7423,7352,6915,7332,7135,7110,6927,6946,6918,7102.8,2002,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11135,11746,12301,11716,11785,11769,11644,11744,11665,11601,11763,11773.4,2003,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3233,4075,4130,4094,4125,4080,4120,4090,4295,4100,4085,4119.4,2004,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6159,6743,7156,7160,6808,7137,6698,6713,6795,6722,6691,6862.3,2005,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5465,5550,5538,5621,5546,5565,5654,5543,5545,5532,5654,5574.8,2006,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6009,6863,7316,7310,6875,7347,6919,6870,6867,6902,6859,7012.8,2007,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10384,11001,11124,10941,11063,11221,11572,10982,10938,11185,10835,11086.2,2008,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76670,76939,76998,76822,77206,77162,76994,77166,76848,77321,76935,77039.1,2009,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3282,4151,4241,4169,4160,4161,4178,4153,4278,4196,4137,4182.4,2010,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6122,6786,7194,7221,7106,7221,6807,6786,6843,6814,6825,6960.3,2011,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3297,3595,4050,4078,3568,4108,3548,3584,3533,3566,3657,3728.7,2012,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7132,7740,8199,8165,7732,8195,7643,7782,7653,7745,7754,7860.8,2013,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3318,3498,4091,4125,3500,4139,3453,3512,3447,3492,3507,3676.4,2014,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3312,3588,4191,4180,3621,4189,3695,3617,3666,3585,3585,3791.7,2015,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4588,5039,5604,5637,4997,5666,4835,4997,4813,5079,4990,5165.7,2016,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6077,6890,7349,7366,6941,7413,6877,6939,6927,7030,6945,7067.7,2017,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3351,4633,4709,4688,4708,4779,4718,4677,4752,4663,4602,4692.9,2018,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194569,198953,198916,198879,198848,198873,199540,198661,198701,198915,199006,198929.2,2019,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3753,4748,4717,4668,4721,4655,4918,4685,4785,4723,4671,4729.1,2020,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194943,199219,199184,199238,198834,198844,199102,199058,199397,199205,199301,199138.2,2021,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3292,4259,4252,4189,4281,4226,4246,4293,4308,4226,4188,4246.8,2022,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188909,189294,189636,189848,189958,189873,189788,189706,190011,189962,189685,189776.1,2023,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3319,4129,4174,4141,4148,4129,4142,4122,4186,4120,4089,4138.0,2024,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5986,6907,7304,7291,6848,7360,6883,6903,6937,6962,6853,7024.8,2025,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3260,3551,4093,4055,3577,4252,3558,3606,3760,3594,3605,3765.1,2026,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6874,7668,8145,8370,7668,8106,7594,7772,7582,7668,7673,7824.6,2027,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3293,3443,3999,4009,3471,4059,3397,3429,3366,3500,3435,3610.8,2028,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3325,3576,4195,4177,3597,4247,3654,3580,3704,3575,3583,3788.8,2029,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4356,4991,5583,5594,5004,5599,4820,5021,4826,5026,5003,5146.7,2030,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6394,6953,7438,7360,6878,7389,6902,6897,6878,6942,6926,7056.3,2031,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3381,4644,4715,4685,4743,4709,4766,4689,4735,4662,4641,4698.9,2032,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76302,77437,77465,77528,77311,77704,77396,77444,77559,77273,77416,77453.3,2033,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76575,77367,77084,77537,77452,77455,77599,78214,77888,77466,77267,77532.9,2034,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75959,77534,78073,77726,78064,77522,78099,78037,78554,77515,78256,77938.0,2035,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5917,6848,7374,7285,6853,7312,6866,6863,6903,6776,6759,6983.9,2036,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5973,6749,7394,7192,6728,7185,6738,6745,6781,6684,6700,6889.6,2037,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4795,6302,6238,6278,6206,6166,6357,6228,6252,6303,6221,6255.1,2038,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4583,6222,6281,6316,6277,6242,6189,6267,6284,6214,6231,6252.3,2039,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5953,6858,7302,7282,6911,7314,6833,6955,6831,6870,6885,7004.1,2040,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5900,6947,7399,7381,6993,7423,6933,6953,6913,6959,6964,7086.5,2041,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10949,11742,11626,11587,11624,11662,12423,11910,11583,11749,11508,11741.4,2042,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3247,4117,4155,4115,4185,4089,4145,4116,4153,4108,4071,4125.4,2043,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6167,6888,7269,7515,6828,7271,6882,6849,6887,6830,6857,7007.6,2044,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5449,5570,5460,5521,5464,5526,5517,5494,5459,5537,5497,5504.5,2045,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5983,6833,7299,7284,6832,7306,6815,6838,6820,6840,6871,6973.8,2046,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10332,11057,11128,11136,11107,11315,11771,11165,11332,11441,11157,11260.9,2047,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76482,78353,78223,78423,78411,78226,78116,78282,78455,77984,78039,78251.2,2048,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3335,4244,4167,4124,4185,4106,4176,4127,4156,4144,4079,4150.8,2049,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6317,6879,7204,7214,6885,7259,6831,6793,6917,6763,6795,6954.0,2050,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3313,3598,4090,4128,3601,4142,3563,3601,3585,3613,3598,3751.9,2051,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7146,7692,8294,8113,7706,8158,7603,7716,7647,7700,7675,7830.4,2052,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3199,3502,4091,4126,3499,4112,3433,3512,3442,3530,3515,3676.2,2053,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3361,3551,4159,4155,3553,4133,3651,3585,3625,3563,3670,3764.5,2054,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4466,4968,5473,5572,4932,5617,4783,4968,4782,4996,4995,5108.6,2055,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6008,6897,7273,7277,6900,7335,6867,6882,6967,6977,6868,7024.3,2056,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3387,4637,4781,4652,4684,4692,4709,4697,4727,4682,4633,4689.4,2057,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,195442,199031,198714,198486,198962,198839,198733,198866,199469,198778,198200,198807.8,2058,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3729,4696,4716,4725,4781,4713,4762,4738,4756,4674,4844,4740.5,2059,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194348,199654,199135,199006,199216,198928,199629,199516,199546,199176,198877,199268.3,2060,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3389,4224,4225,4227,4242,4219,4250,4255,4283,4217,4190,4233.2,2061,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188621,189445,189487,189424,189530,189535,189631,189319,189447,189487,189514,189481.9,2062,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3333,4173,4286,4172,4201,4264,4202,4158,4288,4142,4099,4198.5,2063,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6201,6935,7375,7288,6933,7309,6947,6864,6994,6810,6861,7031.6,2064,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3283,3621,4112,4110,3610,4131,3636,3683,3604,3639,3633,3777.9,2065,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6835,7749,8173,8222,7752,8177,7642,7926,7610,7696,7725,7867.2,2066,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3269,3454,4047,4041,3489,4040,3428,3464,3411,3469,3461,3630.4,2067,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3370,3692,4145,4131,3536,4156,3606,3548,3622,3534,3525,3749.5,2068,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4413,5005,5600,5642,5013,5584,4833,5005,4844,5040,5030,5159.6,2069,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6172,6892,7209,7235,6858,7301,6772,6771,6749,6823,6811,6942.1,2070,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3328,4593,4671,4711,4808,4694,4719,4654,4705,4637,4623,4681.5,2071,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76006,77974,77287,77313,77544,77333,77731,77445,77364,77369,77324,77468.4,2072,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76418,76974,77328,77336,77346,77584,77594,77457,77309,77645,77274,77384.7,2073,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76158,77882,77951,77838,78292,77946,77925,78045,78249,77452,78318,77989.8,2074,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6065,6902,7338,7349,6896,7362,6912,6861,6957,6891,6893,7036.1,2075,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5985,6831,7318,7224,6870,7300,6853,6818,6875,6808,6757,6965.4,2076,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4830,6160,6192,6206,6235,6191,6281,6138,6188,6199,6141,6193.1,2077,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4536,6181,6169,6199,6307,6161,6325,6252,6220,6190,6126,6213.0,2078,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5870,6946,7362,7379,6947,7401,6944,6931,7088,6927,6966,7089.1,2079,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5844,6900,7309,7264,6881,7402,6869,6886,6869,6906,6919,7020.5,2080,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11626,11758,11736,12601,11706,11483,11498,11559,11643,11571,11677,11723.2,2081,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3269,4126,4140,4123,4206,4122,4149,4134,4177,4108,4081,4136.6,2082,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6281,6823,7215,7205,6765,7268,6842,6817,6881,6813,6818,6944.7,2083,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5430,5510,5549,5583,5564,5513,5535,5509,5663,5668,5529,5562.3,2084,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5961,6830,7306,7282,6847,7398,6851,6864,6826,6925,6992,7012.1,2085,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10125,10995,10970,11006,11205,11180,10896,10934,11063,10795,10966,11001.0,2086,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76578,77580,77533,77333,77425,77175,77316,77326,77501,77312,77470,77397.1,2087,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3350,4141,4161,4152,4183,4126,4210,4200,4370,4145,4201,4188.9,2088,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6241,6967,7393,7326,6943,7353,6976,6945,7091,7039,6969,7100.2,2089,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3315,3550,4045,4072,3547,4148,3524,3616,3541,3564,3565,3717.2,2090,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7136,7687,8150,8105,7694,8166,7616,7694,7594,7693,7658,7805.7,2091,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3249,3467,4040,4065,3469,4097,3417,3446,3411,3418,3465,3629.5,2092,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3407,3536,4143,4113,3554,4195,3635,3538,3670,3558,3540,3748.2,2093,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4492,4962,5526,5549,4947,5766,4791,4950,4756,4970,4920,5113.7,2094,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6089,6889,7295,7329,6852,7411,6836,6902,6857,6876,6933,7018.0,2095,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3367,4625,4720,4708,4690,4667,4715,4653,4808,4626,4688,4690.0,2096,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194576,197788,198332,198778,198108,198220,198615,198245,198220,197960,197333,198159.9,2097,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3756,4869,4754,4723,4783,4762,4796,4787,4800,4700,4710,4768.4,2098,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194919,198509,198117,198416,198273,198068,198478,198268,198381,197878,198643,198303.1,2099,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3370,4305,4236,4294,4317,4247,4220,4219,4280,4417,4168,4270.3,2100,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,189073,191044,191089,190733,190657,190842,191193,190833,190564,190591,190602,190814.8,2101,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3360,4139,4182,4175,4199,4152,4201,4185,4229,4182,4150,4179.4,2102,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6148,6847,7329,7340,6874,7312,6919,6857,6935,6869,6860,7014.2,2103,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3311,3534,4061,4069,3565,4347,3586,3513,3540,3618,3590,3742.3,2104,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6810,7717,8145,8163,7713,8185,7639,7682,7587,7638,7677,7814.6,2105,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3239,3552,4114,4129,3509,4129,3495,3550,3470,3530,3517,3699.5,2106,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3342,3520,4147,4181,3573,4128,3639,3571,3678,3552,3535,3752.4,2107,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4403,5014,5666,5582,4971,5616,4815,4987,4817,4997,4966,5143.1,2108,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6309,7126,7366,7354,6961,7340,6909,6926,6911,6979,6939,7081.1,2109,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3274,4613,4664,4674,4739,4678,4727,4677,4691,4650,4601,4671.4,2110,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76655,79546,79816,79710,79531,79862,79882,79548,79280,79104,79982,79626.1,2111,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76426,78017,78004,78609,77940,77973,78234,77865,78873,77962,78152,78162.9,2112,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76370,77360,77279,77532,77717,77609,77092,77464,77550,77316,77048,77396.7,2113,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5980,6999,7355,7294,6925,7390,6949,6902,7055,6931,6887,7068.7,2114,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5916,6910,7394,7375,6928,7351,6958,6938,6956,6914,6919,7064.3,2115,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4738,6154,6193,6191,6295,6184,6320,6133,6159,6177,6178,6198.4,2116,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4514,6182,6317,6256,6224,6227,6366,6157,6284,6171,6117,6230.1,2117,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6016,7023,7406,7497,7066,7457,6949,6987,6932,7034,6958,7130.9,2118,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5983,6952,7478,7409,7026,7383,6935,6966,6952,6972,6960,7103.3,2119,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11016,11813,11617,11783,11633,11648,11729,11735,11950,11764,12388,11806.0,2120,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3257,4118,4174,4190,4165,4104,4140,4136,4200,4148,4077,4145.2,2121,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5899,6805,7187,7210,6720,7275,6811,6721,6800,6755,6720,6900.4,2122,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5432,5497,5520,5535,5568,5552,5560,5528,5548,5572,5546,5542.6,2123,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5961,6790,7286,7258,6771,7222,6959,6994,6703,6912,6826,6972.1,2124,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10102,10954,11027,11119,10878,10904,11405,10978,11014,12063,11102,11144.4,2125,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76130,77784,77597,77342,77736,77319,78047,77520,77618,77376,77520,77585.9,2126,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3312,4158,4181,4145,4168,4131,4199,4161,4203,4392,4145,4188.3,2127,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6314,6861,7253,7162,6787,7188,6887,6869,6835,6767,6817,6942.6,2128,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3306,3621,4120,4095,3596,4135,3585,3609,3585,3620,3614,3758.0,2129,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7063,7698,8131,8123,7679,8108,7583,7664,7586,7671,7698,7794.1,2130,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3272,3511,4068,4076,3465,4085,3438,3473,3430,3473,3499,3651.8,2131,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3384,3554,4153,4166,3638,4180,3664,3607,3643,3579,3567,3775.1,2132,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4552,4905,5556,5520,4914,5564,4729,4924,4732,4969,4916,5072.9,2133,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6048,6905,7339,7602,6907,7340,6878,6949,6863,6914,6927,7062.4,2134,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3354,4661,4730,4738,4676,4647,4726,4731,4792,4809,4627,4713.7,2135,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194135,198881,198551,198769,199069,198809,198519,199409,198765,198824,198659,198825.5,2136,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3743,4740,4747,4670,4757,4698,4805,4721,4769,4733,4683,4732.3,2137,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194500,199141,198902,198860,198873,198938,199179,198338,199075,199295,199020,198962.1,2138,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3342,4338,4296,4226,4260,4250,4257,4380,4279,4233,4237,4275.6,2139,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,189060,190476,190626,190756,190771,190600,190891,191074,190590,190334,191052,190717.0,2140,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3361,4134,4177,4158,4170,4129,4167,4214,4176,4134,4084,4154.3,2141,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6089,6806,7235,7483,6822,7253,6843,6840,6860,6781,6794,6971.7,2142,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3295,3589,4070,4099,3594,4093,3607,3609,3579,3547,3600,3738.7,2143,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6815,7683,8187,8101,7700,8197,7634,7679,7627,7717,7677,7820.2,2144,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3292,3482,4082,4077,3492,4140,3457,3497,3439,3513,3514,3669.3,2145,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3380,3568,4219,4171,3568,4198,3645,3648,3711,3555,3548,3783.1,2146,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4421,4916,5528,5497,5004,5592,4742,4908,4681,4975,4948,5079.1,2147,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6220,6901,7267,7252,6823,7350,6848,6844,6843,6860,6869,6985.7,2148,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3336,4666,4715,4690,4686,4878,4669,4658,4679,4657,4692,4699.0,2149,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76019,77832,77470,77193,77086,77532,77327,77194,77225,77574,77242,77367.5,2150,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76330,77078,77520,77410,77105,77152,77439,77240,77103,77002,77417,77246.6,2151,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75893,77368,77893,77544,78121,77772,78076,77635,77685,77986,77599,77767.9,2152,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5968,6905,7360,7198,6852,7437,6864,6857,6947,6845,6918,7018.3,2153,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5943,6690,7121,7103,6693,7104,6716,6727,6723,6661,6690,6822.8,2154,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4972,6147,6307,6247,6341,6239,6302,6249,6256,6237,6247,6257.2,2155,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4559,6037,6275,6229,6225,6319,6256,6173,6195,6229,6107,6204.5,2156,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5975,6859,7275,7275,6886,7295,6835,6840,6865,6883,6830,6984.3,2157,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5914,6887,7294,7291,6828,7594,6814,6922,6865,6966,6963,7042.4,2158,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11144,11576,11482,11662,11682,11999,11819,11672,12580,11651,11792,11791.5,2159,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3339,4142,4175,4133,4169,4113,4161,4169,4186,4134,4095,4147.7,2160,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6154,6877,7344,7464,6914,7318,6906,6836,6938,6880,6863,7034.0,2161,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5451,5565,5494,5486,5475,5484,5587,5591,5525,5517,5516,5524.0,2162,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5958,6941,7354,7385,6887,7374,6886,6898,6940,6928,6968,7056.1,2163,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11136,11184,11030,11142,10926,11206,11672,11094,11068,11010,11118,11145.0,2164,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76012,77197,77289,77209,77264,77138,77150,77439,77379,77233,77248,77254.6,2165,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3352,4100,4159,4130,4132,4157,4154,4108,4193,4128,4172,4143.3,2166,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6178,6704,7101,7149,6713,7103,6726,6667,6743,6746,6661,6831.3,2167,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3296,3566,4055,4083,3557,4078,3535,3538,3539,3536,3526,3701.3,2168,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7155,7787,8234,9030,7729,8181,7696,7702,7621,7707,7714,7940.1,2169,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3251,3496,4066,4092,3476,4089,3415,3456,3426,3487,3463,3646.6,2170,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3391,3578,4165,4181,3556,4147,3652,3555,3759,3565,3572,3773.0,2171,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4459,4956,5558,5611,4979,5605,4775,5099,4781,4982,4958,5130.4,2172,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6152,6948,7383,7403,6949,7483,6925,7056,6876,6958,6910,7089.1,2173,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3405,4636,4720,4750,4721,4664,4735,4711,4727,4674,4645,4698.3,2174,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194526,198601,198636,198283,198302,198130,198316,201339,198871,198742,198838,198805.8,2175,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3784,4752,4828,4743,4682,4676,4740,4810,4748,4664,4637,4728.0,2176,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194222,197953,198464,198040,198793,199700,198751,198064,197670,198603,198562,198460.0,2177,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4203,4267,4215,4234,4213,4274,4290,4257,4195,4178,4232.6,2178,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188840,189245,189238,189594,189248,189504,189416,189987,189787,189740,189265,189502.4,2179,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3395,4181,4171,4173,4384,4139,4174,4363,4247,4145,4108,4208.5,2180,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6101,6899,7278,7347,6816,7255,6902,6945,6817,6780,6815,6985.4,2181,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3265,3614,4117,4087,3605,4130,3638,3601,3577,3612,3639,3762.0,2182,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6852,7636,8158,8119,7642,8110,7574,7663,7557,7647,7650,7775.6,2183,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3267,3485,4071,4074,3484,4083,3448,3526,3444,3487,3520,3662.2,2184,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3352,3536,4135,4151,3557,4144,3613,3543,3625,3513,3525,3734.2,2185,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4343,4995,5538,5481,4900,5524,4731,4888,4728,4939,4865,5058.9,2186,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6274,6861,7317,7281,6882,7317,6912,6875,6818,6882,6928,7007.3,2187,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3333,4702,4692,4668,4686,4732,4705,4660,4719,4751,4584,4689.9,2188,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76019,77988,78243,78104,77965,78075,78456,77993,78377,78044,78256,78150.1,2189,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76436,77228,77792,77997,77159,77818,77635,77376,77531,77600,77155,77529.1,2190,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76683,77510,77959,77752,77716,77768,78014,78159,78394,78723,77672,77966.7,2191,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5902,6863,7329,7294,6829,7290,6871,6867,6909,7254,6830,7033.6,2192,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5953,6782,7170,7210,6763,7231,6820,6764,6878,6762,6753,6913.3,2193,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4709,6144,6278,6182,6153,6247,6468,6188,6300,6250,6143,6235.3,2194,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4514,6176,6230,6298,6182,6188,6466,6191,6279,6212,6203,6242.5,2195,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5839,6983,7475,7428,6974,7414,6913,6976,6942,7021,6975,7110.1,2196,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5771,6997,7410,7422,6930,7404,6985,7029,6986,7027,6967,7115.7,2197,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10911,11886,12619,11631,11693,11702,11711,11554,11926,11732,11812,11826.6,2198,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3300,4159,4109,4187,4132,4264,4090,4099,4234,4149,4051,4147.4,2199,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6005,6854,7323,7314,6842,7284,6892,6860,6935,6806,6887,6999.7,2200,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5429,5597,5539,5617,5523,5563,5587,5602,5482,5543,5527,5558.0,2201,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6020,6879,7325,7335,6898,7404,6856,6891,6880,6901,6917,7028.6,2202,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10426,11226,11023,10758,11190,10878,10942,11216,10947,10975,11143,11029.8,2203,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76084,77220,77655,77448,77330,77199,77200,77423,77227,77424,77292,77341.8,2204,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3341,4130,4181,4132,4172,4130,4183,4158,4421,4244,4116,4186.7,2205,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6101,6704,7146,7161,6880,7158,6759,6740,6921,6732,6749,6895.0,2206,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3270,3572,4097,4085,3703,4126,3567,3583,3577,3548,3535,3739.3,2207,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7177,7713,8148,8129,7663,8216,7599,7613,7602,7649,7647,7797.9,2208,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3248,3448,4044,4067,3437,4061,3403,3466,3404,3448,3447,3622.5,2209,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3307,3546,4126,4105,3530,4198,3623,3569,3646,3549,3551,3744.3,2210,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4514,5093,5515,5512,4902,5531,4804,5020,4695,4941,4880,5089.3,2211,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6032,6974,7374,7350,6925,7376,6853,6991,6891,6797,6909,7044.0,2212,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3405,4773,4799,4762,4760,4821,4766,4740,4723,4749,4742,4763.5,2213,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194535,197051,197300,197211,197477,197228,197487,197077,197214,196960,197132,197213.7,2214,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3739,4753,4735,4731,4744,4738,4791,4755,4839,4724,4734,4754.4,2215,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194413,198618,201709,198898,198883,198659,199072,198907,198885,198420,198826,199087.7,2216,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3319,4241,4265,4247,4281,4224,4271,4277,4453,4336,4374,4296.9,2217,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,189190,189705,190112,189887,189765,189411,189962,189571,190561,189857,189473,189830.4,2218,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3303,4201,4150,4295,4145,4098,4144,4101,4153,4238,4133,4165.8,2219,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6148,6690,7167,7136,6794,7152,6752,6688,6765,6682,6704,6853.0,2220,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3303,3573,4134,4050,3595,4129,3595,3560,3561,3604,3726,3752.7,2221,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6811,7684,8149,8731,7773,8127,7670,7684,7675,7691,7717,7890.1,2222,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3264,3459,4054,4022,3455,4094,3417,3436,3393,3478,3462,3627.0,2223,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3398,3498,4110,4155,3518,4096,3591,3536,3611,3507,3511,3713.3,2224,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4355,4893,5476,5479,4927,5498,4706,4876,4736,5013,4923,5052.7,2225,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6154,6881,7292,7273,6872,7383,6811,6827,6835,6858,6895,6992.7,2226,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3291,4664,4939,4742,4703,4718,4777,4696,4806,4710,4669,4742.4,2227,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76140,77726,77967,78009,77752,77995,78251,78095,78303,78171,77892,78016.1,2228,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76213,77527,77835,78051,78270,77874,78232,77591,77915,77516,78008,77881.9,2229,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76348,77877,79120,78582,78464,78546,78804,78700,78635,78750,78486,78596.4,2230,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5917,6870,7278,7299,6784,7267,6856,6972,6861,6827,6833,6984.7,2231,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5814,6835,7377,7226,6822,7270,6902,6847,6994,6838,6829,6994.0,2232,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4694,6104,6286,6180,6210,6203,6262,6155,6192,6206,6259,6205.7,2233,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4575,6296,6284,6232,6275,6133,6236,6181,6417,6226,6271,6255.1,2234,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5928,6948,7400,7330,6965,7374,6896,7032,6916,6950,6942,7075.3,2235,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5827,6931,7375,7357,6985,7369,6898,6983,6917,6991,6933,7073.9,2236,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11086,11671,11517,11568,11763,11740,11723,11662,11744,12081,11705,11717.4,2237,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3241,4177,4222,4065,4125,4073,4126,4117,4217,4120,4031,4127.3,2238,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6133,6761,7184,7126,6745,7147,6747,6751,6792,6754,6714,6872.1,2239,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5396,5546,5518,5591,5520,5517,5593,5536,5520,5752,5542,5563.5,2240,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5953,6799,7199,7234,6793,7434,6780,6826,6776,6778,6791,6941.0,2241,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10178,10851,10843,11151,10892,10917,10987,11097,11107,11712,11132,11068.9,2242,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76491,76884,77080,77210,77187,77285,77103,76944,77041,77131,76971,77083.6,2243,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3358,4128,4208,4167,4203,4122,4180,4144,4215,4166,4112,4164.5,2244,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6132,6821,7253,7249,6915,7263,6876,6767,6882,6919,6909,6985.4,2245,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3285,3726,4062,4092,3594,4105,3576,3548,3581,3577,3591,3745.2,2246,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7102,7679,8153,8149,7716,8146,7626,7674,7663,7723,7724,7825.3,2247,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3295,3441,4009,4041,3496,4029,3345,3424,3349,3429,3455,3601.8,2248,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3350,3619,4214,4223,3690,4179,3682,3619,3693,3688,3604,3821.1,2249,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4508,4884,5505,5493,4900,5722,4843,4943,4746,4939,4920,5089.5,2250,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6117,6966,7350,7395,6933,7413,6905,6993,6924,6940,6948,7076.7,2251,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3384,4643,4738,4676,4743,4687,4740,4709,4729,4749,4647,4706.1,2252,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194209,198031,198074,197658,198324,198444,197797,198104,197696,198022,197950,198010.0,2253,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3835,4680,4758,4710,4708,4715,4816,4670,4752,4659,4663,4713.1,2254,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194681,199282,199295,199236,199715,198635,199069,199349,199420,199425,199049,199247.5,2255,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3338,4234,4257,4315,4266,4233,4305,4289,4305,4221,4200,4262.5,2256,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188576,189855,190251,189654,189329,189704,189815,189072,190052,189433,189536,189670.1,2257,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3424,4214,4224,4226,4222,4185,4310,4214,4235,4165,4217,4221.2,2258,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6047,6766,7239,7190,6886,7202,6790,6783,6834,6748,6743,6918.1,2259,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3276,3626,4095,4094,3614,4182,3578,3596,3602,3636,3731,3775.4,2260,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6803,7701,8120,8115,7676,8131,7550,7705,7567,7679,7642,7788.6,2261,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3404,3564,4150,4125,3541,4184,3518,3547,3512,3579,3543,3726.3,2262,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3435,3602,4210,4211,3603,4216,3709,3605,3690,3599,3604,3804.9,2263,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4375,4904,5494,5449,4880,5522,4721,4878,4754,4926,4934,5046.2,2264,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6324,6811,7276,7238,6827,7272,6785,6857,6781,6842,6818,6950.7,2265,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3323,4669,4781,4747,4848,4746,4894,4707,4735,4710,4647,4748.4,2266,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76723,77002,77628,77741,77398,77624,77378,77274,77443,77211,77486,77418.5,2267,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75789,77384,77525,77682,77391,77603,77421,77447,77697,77310,77407,77486.7,2268,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76344,77469,77130,77016,77204,77116,77265,77237,77199,77086,77086,77180.8,2269,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5802,6903,7264,7287,6910,7323,6867,6837,6911,6825,6827,6995.4,2270,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5980,6705,7182,7123,6787,7137,6779,6696,6768,6752,6646,6857.5,2271,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4752,6191,6570,6215,6286,6139,6298,6165,6246,6168,6110,6238.8,2272,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4468,6177,6262,6321,6238,6140,6155,6247,6305,6157,6169,6217.1,2273,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5913,6934,7398,7327,6970,7386,6921,6918,6910,6978,7118,7086.0,2274,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5806,6969,7435,7425,6949,7423,6864,6942,6945,6910,6937,7079.9,2275,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10893,11699,12032,11637,11542,11614,11924,11584,11718,11613,11772,11713.5,2276,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3283,4089,4146,4091,4148,4066,4135,4135,4152,4255,4074,4129.1,2277,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6170,6800,7230,7261,6789,7234,6842,6802,6872,6819,6806,6945.5,2278,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5484,5514,5551,5533,5535,5549,5559,5534,5539,5516,5527,5535.7,2279,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5866,6919,7368,7394,6991,7381,6896,6925,6919,6939,6979,7071.1,2280,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10257,11091,11081,11115,11341,10917,11340,11075,11016,10936,10914,11082.6,2281,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76780,78396,78451,78762,78409,78310,78386,78271,78423,78235,78309,78395.2,2282,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3323,4129,4128,4169,4212,4104,4381,4175,4182,4122,4223,4182.5,2283,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6184,6717,7233,7159,6691,7134,6756,6799,6743,6699,6804,6873.5,2284,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3331,3607,4064,4117,3574,4109,3567,3609,3634,3566,3630,3747.7,2285,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7191,7662,8107,8113,7675,8120,8400,7668,7574,7627,7682,7862.8,2286,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3224,3498,4144,4120,3529,4168,3452,3512,3460,3515,3525,3692.3,2287,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3359,3571,4169,4151,3561,4142,3740,3568,3657,3556,3571,3768.6,2288,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4500,4907,5501,5674,5039,5535,4692,4925,4702,4885,4900,5076.0,2289,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5977,6974,7404,7413,6967,7393,6977,6954,6931,6963,6966,7094.2,2290,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3377,4668,4724,4723,4793,4702,4785,4704,4732,4694,4647,4717.2,2291,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194109,198208,198451,198221,198485,198015,198412,198332,198960,198295,198316,198369.5,2292,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3743,4707,4675,4681,4718,4670,4717,4664,4824,4657,4689,4700.2,2293,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193908,198882,198729,198693,199156,199296,199355,199208,199331,199836,198772,199125.8,2294,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3351,4162,4281,4234,4242,4179,4229,4264,4263,4184,4150,4218.8,2295,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188782,189652,189888,189980,190476,189999,190029,189932,189913,189876,189361,189910.6,2296,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3351,4153,4145,4135,4189,4111,4235,4134,4147,4097,4072,4141.8,2297,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6143,6905,7584,7308,6828,7313,6896,6846,6891,7042,6991,7060.4,2298,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3274,3608,4070,4064,3580,4108,3683,3591,3738,3589,3554,3758.5,2299,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6876,7698,8163,8209,7706,8212,7556,7671,7633,7655,7689,7819.2,2300,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3271,3469,4044,4035,3444,4059,3483,3441,3402,3488,3455,3632.0,2301,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3366,3519,4138,4167,3531,4126,3629,3539,3648,3515,3530,3734.2,2302,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4323,4942,5538,5551,4935,5597,4721,4952,4741,4910,5091,5097.8,2303,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6130,6796,7255,7190,6812,7273,6768,6792,6807,6831,6805,6932.9,2304,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3355,4688,4674,4658,4747,4862,4706,4650,4719,4659,4612,4697.5,2305,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76088,78359,78689,78845,78536,78428,78338,78528,78554,78790,78271,78533.8,2306,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75962,77618,77797,77469,78119,78272,78272,77611,77854,77700,77826,77853.8,2307,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76128,77450,77917,77726,77121,78003,77702,77693,78134,77882,77537,77716.5,2308,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5959,6772,7423,7334,6767,7338,6834,6751,6802,6801,6743,6956.5,2309,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5780,6849,7242,7227,6778,7272,6868,6863,6842,6835,6849,6962.5,2310,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4726,6125,6237,6213,6139,6115,6217,6079,6187,6119,6138,6156.9,2311,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4512,6135,6205,6272,6222,6121,6185,6231,6176,6171,6037,6175.5,2312,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5938,6894,7363,7351,6920,7370,6893,6928,6919,6948,6977,7056.3,2313,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5843,7030,7422,7403,7035,7415,6963,6982,6967,6979,6987,7118.3,2314,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11059,11599,11582,11644,11697,11933,11712,11799,11572,11952,11778,11726.8,2315,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3256,4117,4109,4095,4127,4085,4084,4088,4174,4100,4048,4102.7,2316,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6249,6661,7136,7138,6706,7134,6748,6748,6721,6706,6682,6838.0,2317,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5455,5520,5543,5556,5530,5539,5650,5545,5528,5592,5556,5555.9,2318,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5947,6897,7324,7393,6844,7329,6833,6870,6845,6839,6968,7014.2,2319,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10198,10996,11015,11058,11017,11720,10956,11177,11153,11157,10940,11118.9,2320,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76199,78297,77926,78414,78541,77537,78401,77639,78014,78116,78459,78134.4,2321,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3275,4160,4186,4136,4196,4168,4190,4178,4190,4168,4139,4171.1,2322,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6051,6827,7254,7337,6801,7399,6873,6828,6902,6907,6819,6994.7,2323,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3391,3591,4105,4120,3604,4125,3575,3583,3618,3600,3598,3751.9,2324,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7162,7685,8150,8115,7697,8129,7556,7673,7610,7836,7655,7810.6,2325,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3282,3443,4035,4064,3466,4066,3377,3463,3388,3441,3446,3618.9,2326,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3369,3517,4304,4118,3536,4114,3620,3540,3655,3584,3586,3757.4,2327,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4517,4931,5471,5526,5023,5513,4707,4947,4723,4932,4905,5067.8,2328,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6126,6867,7263,7359,6832,7228,6772,6819,6816,6906,6845,6970.7,2329,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4650,4733,4676,4698,4658,4840,4660,4742,4646,4624,4692.7,2330,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194473,197822,198035,198444,198086,198117,198195,198608,198192,199161,198253,198291.3,2331,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3758,4699,4714,4693,4800,4739,4754,4723,4923,4679,4650,4737.4,2332,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193600,198680,198113,198613,198373,198068,198228,198236,198264,197897,198270,198274.2,2333,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3337,4250,4292,4322,4413,4241,4289,4321,4325,4266,4213,4293.2,2334,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188511,189168,189117,189622,189962,189351,189359,189530,189905,189366,189727,189510.7,2335,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3309,4187,4190,4175,4315,4148,4200,4204,4229,4181,4141,4197.0,2336,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6012,6788,7284,7276,6814,7254,6834,6847,6846,6798,6760,6950.1,2337,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3311,3546,4097,4060,3542,4104,3557,3706,3537,3612,3662,3742.3,2338,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6801,7690,8121,8134,7667,8160,7569,7779,7583,7687,7643,7803.3,2339,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3272,3444,4041,4030,3460,4056,3417,3462,3389,3474,3473,3624.6,2340,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3369,3529,4126,4127,3554,4128,3636,3540,3632,3540,3675,3748.7,2341,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4336,4895,5478,5456,4885,5370,4712,4889,4707,4952,4880,5022.4,2342,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6161,6912,7416,7284,6869,7322,6853,6842,6864,6917,6869,7014.8,2343,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3370,4791,4665,4673,4697,4653,4690,4666,4709,4774,4586,4690.4,2344,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76239,78171,78657,78431,78177,78525,78520,78380,78224,78409,78197,78369.1,2345,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76009,77710,77561,77486,77224,77224,77404,77398,77239,77474,77299,77401.9,2346,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76806,77531,77115,77382,77109,77029,77367,77510,77184,77286,76926,77243.9,2347,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5891,6861,7284,7296,6879,7348,6891,6843,6902,6828,6837,6996.9,2348,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5843,6814,7236,7248,6793,7521,6827,6827,7030,6920,6812,7002.8,2349,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4727,6138,6188,6349,6217,6099,6321,6136,6158,6044,6122,6177.2,2350,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4530,6058,6189,6185,6254,6213,6255,6175,6259,6249,6133,6197.0,2351,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5907,6946,7371,7290,7012,7443,6925,6936,6917,6949,6903,7069.2,2352,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6111,6813,7249,7385,6796,7278,6733,6808,6795,6865,6803,6952.5,2353,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10899,11562,11804,11696,11605,11764,11641,11634,11726,11746,11875,11705.3,2354,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3246,4104,4162,4215,4113,4182,4262,4339,4145,4098,4117,4173.7,2355,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6245,6801,7254,7206,6773,7180,6824,6796,6830,6776,6741,6918.1,2356,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5469,5552,5590,5599,5547,5557,5611,5552,5564,5552,5571,5569.5,2357,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5918,6971,7315,7327,6940,7309,6885,6867,6852,6815,6926,7020.7,2358,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10067,11348,11159,10828,10991,11394,11209,10890,11004,10784,10859,11046.6,2359,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75991,77589,77837,77710,77935,78136,77213,77666,77857,77832,77444,77721.9,2360,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3286,4164,4172,4126,4193,4138,4199,4159,4197,4328,4279,4195.5,2361,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6117,6852,7400,7262,6857,7393,6946,6872,6933,6863,6832,7021.0,2362,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3282,3620,4118,4139,3607,4147,3590,3620,3592,3597,3593,3762.3,2363,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7148,7733,8201,8129,7695,8200,7640,7726,7590,7744,7732,7839.0,2364,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3320,3443,4051,4059,3467,4136,3384,3430,3381,3445,3498,3629.4,2365,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3409,3512,4085,4101,3585,4138,3602,3517,3595,3521,3632,3728.8,2366,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4475,4960,5518,5521,4924,5693,4754,4886,4724,4897,4950,5082.7,2367,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6122,6867,7296,7320,6884,7373,6886,6937,6876,6876,6886,7020.1,2368,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3395,4621,4843,4662,4725,4703,4731,4657,4710,4756,4638,4704.6,2369,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,195091,198323,198255,198575,198353,198413,198665,198258,198702,197952,198732,198422.8,2370,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3759,4716,4696,4686,4683,4751,4798,4770,4810,4678,4698,4728.6,2371,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194519,198324,198800,198473,198596,198576,198899,198648,198754,199029,198362,198646.1,2372,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4233,4244,4211,4251,4202,4278,4237,4248,4198,4206,4230.8,2373,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188742,189384,190119,190088,189265,189960,190203,189551,190060,190293,189991,189891.4,2374,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3343,4159,4274,4147,4191,4218,4182,4190,4229,4132,4110,4183.2,2375,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6061,6764,7275,7175,6781,7182,6809,6753,6804,6796,6757,6909.6,2376,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3280,3607,4106,4103,3563,4129,3589,3567,3624,3603,3621,3751.2,2377,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6810,7734,8184,8151,8457,8171,7560,7724,7603,7680,7661,7892.5,2378,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3229,3444,4038,4024,3432,4065,3436,3421,3381,3442,3437,3612.0,2379,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3412,3496,4079,4135,3503,4096,3590,3520,3599,3504,3479,3700.1,2380,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4324,4961,5520,5513,4917,5581,4859,4935,4827,4975,4997,5108.5,2381,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6204,6927,7375,7334,6896,7400,6860,6881,6972,6892,6917,7045.4,2382,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3313,4800,4691,4713,4711,4709,4755,4713,4679,4680,4674,4712.5,2383,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76133,77681,78152,77993,77923,77630,78441,78380,77926,77609,77566,77930.1,2384,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76391,78453,77986,77969,77959,78362,78235,78135,78039,78133,78084,78135.5,2385,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76052,77132,77136,77247,77035,77180,77278,77292,76954,76704,77658,77161.6,2386,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5896,6880,7275,7208,6822,7356,6846,6804,6874,6814,6781,6966.0,2387,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5962,6624,7133,7095,6669,7103,6681,6605,6732,6617,6637,6789.6,2388,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4836,6144,6131,6221,6312,6226,6449,6187,6241,6243,6084,6223.8,2389,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4517,6123,6254,6178,6220,6237,6206,6212,6170,6171,6241,6201.2,2390,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5874,6998,7325,7450,6869,7313,6833,6882,6840,6879,6884,7027.3,2391,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5905,6894,7350,7278,6868,7325,6858,6951,6917,6874,6893,7020.8,2392,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10810,11733,11718,11603,12121,11758,11709,11754,12388,11781,11598,11816.3,2393,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3276,4055,4106,4077,4106,4121,4085,4094,4128,4071,4046,4088.9,2394,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6153,6910,7341,7286,6849,7362,6935,6967,6959,6891,6852,7035.2,2395,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5493,5512,5560,5562,5520,5557,5569,5505,5503,5521,5549,5535.8,2396,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5949,7029,7392,7379,6987,7429,6931,7167,6936,6981,7004,7123.5,2397,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11115,10968,11214,11211,11080,11178,11158,11056,11243,10897,11025,11103.0,2398,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75977,77223,77384,77981,77240,77307,77350,77621,77657,77575,77482,77482.0,2399,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3321,4095,4160,4159,4286,4084,4149,4128,4146,4110,4088,4140.5,2400,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6109,6791,7198,7177,6877,7247,6793,6728,6959,6797,6845,6941.2,2401,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3308,3631,4136,4114,3597,4118,3563,3609,3582,3594,3617,3756.1,2402,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7121,7699,8107,8114,7689,8213,7588,7685,7578,7761,7669,7810.3,2403,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3295,3440,4028,4050,3445,4042,3369,3404,3360,3426,3410,3597.4,2404,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3377,3514,4103,4106,3543,4133,3626,3568,3577,3512,3485,3716.7,2405,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4474,4877,5500,5473,4897,5493,4693,4892,4717,4913,4878,5033.3,2406,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5989,6871,7315,7310,6884,7318,6909,6920,7127,6888,6881,7042.3,2407,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3387,4654,4767,4691,4721,4726,4727,4678,4714,4660,4653,4699.1,2408,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194853,197618,197603,197771,198444,197846,198187,198102,197906,198388,197988,197985.3,2409,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3714,4754,4746,4711,4743,4712,4769,4748,4776,4694,4728,4738.1,2410,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194642,199075,199449,199472,199799,198747,199377,199047,199095,198660,199708,199242.9,2411,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3387,4230,4227,4219,4273,4204,4234,4223,4255,4219,4259,4234.3,2412,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188534,190070,190040,190185,190506,190387,190386,190206,190309,190324,190189,190260.2,2413,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3404,4107,4265,4095,4113,4130,4128,4124,4145,4121,4052,4128.0,2414,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6052,6677,7242,7282,6741,7267,6767,6766,6770,6710,6735,6895.7,2415,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3376,3563,4121,4124,3572,4139,3581,3592,3806,3582,3592,3767.2,2416,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6777,7703,8135,8164,7697,8130,7580,7707,7658,7694,7690,7815.8,2417,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3260,3475,4081,4080,3490,4155,3446,3485,3429,3477,3510,3662.8,2418,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3388,3500,4112,4132,3530,4106,3607,3514,3615,3502,3532,3715.0,2419,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4406,4897,5537,5566,4985,5515,4860,4971,4919,4911,4937,5109.8,2420,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6213,6965,7324,7272,6822,7334,6958,6827,6820,6920,6896,7013.8,2421,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3301,4612,4675,4712,4767,4693,4701,4753,4730,4674,4619,4693.6,2422,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,77149,78885,79262,79384,79075,79042,79463,79336,78972,79135,78811,79136.5,2423,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76042,77607,77293,77416,78127,77888,77995,77816,77678,77265,78198,77728.3,2424,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76788,77472,77243,77369,77221,77281,77570,77334,77398,77366,77410,77366.4,2425,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6001,6734,7151,7318,6765,7164,6821,6739,6951,6747,6712,6910.2,2426,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5802,6877,7425,7354,6861,7270,6894,6829,7008,6835,6852,7020.5,2427,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4682,6112,6217,6184,6275,6193,6299,6198,6218,6214,6130,6204.0,2428,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4535,6140,6180,6192,6230,6186,6140,6170,6201,6126,6170,6173.5,2429,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5975,6850,7283,7237,6832,7283,6796,6847,6806,6841,6822,6959.7,2430,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5889,6866,7308,7299,6875,7357,6788,6810,6772,6828,6873,6977.6,2431,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11131,11499,11750,11548,11634,11657,11601,11740,11700,12269,11723,11712.1,2432,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3285,4116,4169,4118,4169,4106,4181,4157,4265,4158,4072,4151.1,2433,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6068,6855,7364,7333,6898,7418,6939,6860,7096,6884,6982,7062.9,2434,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5488,5713,5521,5576,5517,5553,5540,5515,5491,5505,5604,5553.5,2435,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6005,6866,7272,7312,6893,7330,6841,6871,6874,6896,6930,7008.5,2436,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10188,11075,11091,10924,11017,10958,10962,11204,11311,11172,11005,11071.9,2437,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76149,78172,78279,78470,77880,77976,78238,77939,78304,78347,78129,78173.4,2438,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3345,4111,4156,4118,4157,4115,4157,4154,4244,4180,4121,4151.3,2439,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6220,6825,7223,7263,6833,7216,6842,6784,6873,6790,6822,6947.1,2440,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3299,3579,4075,4086,3569,4116,3561,3603,3572,3573,3574,3730.8,2441,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7132,7701,8131,8142,7717,8137,7577,7701,7571,7719,7675,7807.1,2442,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3266,3472,4068,4058,3428,4074,3374,3429,3398,3484,3433,3621.8,2443,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3368,3582,4174,4140,3569,4128,3655,3566,3668,3559,3560,3760.1,2444,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4542,5001,5711,5545,4954,5545,4735,4950,4969,4968,4995,5137.3,2445,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5918,6929,7265,7322,6934,7345,6854,6848,6854,6865,7030,7024.6,2446,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3358,4653,4693,4755,4710,4748,4738,4756,4736,4697,4625,4711.1,2447,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194240,199127,199802,199259,199301,198902,198983,199039,199026,199041,199104,199158.4,2448,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3823,4892,4746,4851,4776,4686,4780,4748,4736,4751,4700,4766.6,2449,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194581,198826,198415,199064,199253,199195,199367,199052,199095,198891,198891,199004.9,2450,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3386,4213,4366,4316,4322,4193,4227,4207,4232,4167,4176,4241.9,2451,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,189256,189274,189228,189100,189402,189437,189035,188982,189158,189422,189421,189245.9,2452,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3325,4113,4194,4149,4169,4138,4180,4169,4162,4260,4144,4167.8,2453,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6049,6822,7603,7343,6832,7263,6861,6815,7029,6869,6814,7025.1,2454,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3397,3519,4047,4137,3557,4048,3669,3580,3533,3583,3595,3726.8,2455,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6862,7685,8149,8302,7688,8127,7595,8543,7571,7677,7682,7901.9,2456,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3251,3476,4082,4071,3483,4101,3463,3474,3420,3500,3497,3656.7,2457,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3314,3525,4133,4152,3538,4118,3634,3539,3642,3545,3543,3736.9,2458,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4454,4937,5517,5492,4930,5646,4748,4902,4877,4942,4922,5091.3,2459,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6220,6943,7359,7368,6962,7394,6987,6930,6884,7104,6941,7087.2,2460,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3333,4639,4900,4703,4755,4722,4748,4715,4715,4672,4778,4734.7,2461,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76063,77414,77420,77751,77645,77581,77538,77526,77718,77672,77415,77568.0,2462,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75753,77671,78172,78607,78189,78108,78225,78344,78339,77954,77594,78120.3,2463,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76121,76785,77010,77013,77558,77102,77219,76888,77085,77301,77169,77113.0,2464,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5917,6764,7250,7262,6810,7242,6844,6770,6825,6823,6766,6935.6,2465,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5872,6744,7231,7250,6772,7218,6790,6738,6785,6818,6749,6909.5,2466,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4764,6187,6303,6156,6285,6146,6195,6357,6229,6310,6137,6230.5,2467,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4493,6240,6225,6192,6244,6120,6316,6286,6106,6189,6244,6216.2,2468,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5762,6846,7286,7219,6856,7232,6811,6831,6842,6898,6792,6961.3,2469,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5904,6997,7305,7346,6924,7334,6879,6999,6876,6887,6860,7040.7,2470,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11221,11647,11760,11757,12137,11711,11602,11928,11643,11536,11729,11745.0,2471,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3263,4107,4130,4143,4186,4083,4120,4084,4148,4107,4046,4115.4,2472,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6054,6851,7387,7246,6864,7287,6878,6832,6872,6853,6830,6990.0,2473,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5472,5475,5482,5523,5475,5573,5529,5515,5540,5463,5561,5513.6,2474,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5865,6852,7266,7319,6815,7317,6915,6844,6811,6890,6931,6996.0,2475,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10099,11134,11431,11231,10894,11102,11194,11185,10912,10978,10864,11092.5,2476,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75902,78307,78272,77925,78055,78214,78087,78485,78217,78083,78071,78171.6,2477,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3309,4113,4112,4108,4135,4097,4153,4117,4160,4093,4069,4115.7,2478,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6129,6787,7267,7233,6806,7248,6859,6807,6865,6795,6896,6956.3,2479,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3297,3629,4071,4123,3578,4173,3604,3590,3568,3579,3567,3748.2,2480,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7114,7679,8156,9099,7687,8136,7599,7667,7598,7714,7642,7897.7,2481,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3209,3463,4066,4084,3456,4084,3391,3431,3395,3477,3455,3630.2,2482,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3387,3529,4117,4170,3549,4167,3651,3519,3596,3613,3531,3744.2,2483,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4525,4983,5540,5573,4961,5563,4793,4967,4768,5025,4979,5115.2,2484,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5978,6886,7333,7330,6903,7377,6884,6896,6879,6960,6970,7041.8,2485,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3381,4636,4731,4715,4722,4720,4750,4707,4707,4822,4658,4716.8,2486,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194745,198871,198746,199070,198466,198250,198563,198769,198346,199027,199284,198739.2,2487,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3727,4701,4790,4722,4825,4823,4803,4672,4720,4723,4679,4745.8,2488,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194700,198222,198327,198626,197938,197998,198399,198236,198189,198097,198405,198243.7,2489,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3329,4263,4230,4194,4240,4164,4217,4234,4340,4179,4147,4220.8,2490,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188497,189536,189356,189529,190227,190016,189699,189405,189909,189683,189530,189689.0,2491,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3329,4140,4182,4162,4192,4127,4188,4157,4370,4172,4156,4184.6,2492,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6105,6777,7245,7247,6795,7268,6854,6949,7005,6783,6801,6972.4,2493,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3311,3579,4083,4093,3629,4117,3612,3593,3592,3606,3612,3751.6,2494,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6821,7701,8159,9009,7664,8099,7589,7692,7602,7673,7635,7882.3,2495,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3393,3468,4024,4015,3447,4057,3559,3428,3441,3444,3441,3632.4,2496,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3303,3520,4116,4135,3538,4113,3635,3530,3627,3526,3527,3726.7,2497,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4329,4977,5536,5607,4909,5545,4715,4935,4720,4967,4975,5088.6,2498,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6321,6865,7348,7284,6828,7289,6847,6810,6771,6870,6932,6984.4,2499,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3323,4664,4714,4704,4697,4762,4716,4677,4698,4676,4627,4693.5,2500,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76100,77684,78376,77922,78134,77938,77954,78340,78266,78242,78199,78105.5,2501,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76085,77398,77569,77465,77189,77587,77393,77145,77542,77156,77049,77349.3,2502,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75964,78426,78860,78203,78350,77833,78609,79273,78497,78584,78162,78479.7,2503,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5992,6927,7339,7235,6855,7276,6900,6841,6896,6901,6842,7001.2,2504,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5926,6784,7184,7210,6783,7208,6810,6845,6878,6771,6754,6922.7,2505,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4776,6157,6272,6199,6224,6182,6213,6061,6169,6097,6114,6168.8,2506,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4542,6249,6278,6391,6238,6204,6189,6266,6206,6205,6155,6238.1,2507,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5897,6950,7388,7378,6997,7395,6946,6969,7016,6920,6954,7091.3,2508,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5867,6917,7344,7351,6932,7390,6849,6914,6896,6896,6937,7042.6,2509,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10923,12279,11670,11678,11611,11727,11698,11763,11725,11695,11600,11744.6,2510,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3427,4081,4098,4136,4108,4083,4148,4093,4138,4121,4044,4105.0,2511,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6059,6715,7171,7149,6697,7151,6728,6746,6751,6729,6681,6851.8,2512,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5444,5627,5498,5564,5538,5513,5526,5530,5508,5543,5496,5534.3,2513,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5878,6908,7413,7306,6888,7398,6892,6957,6854,6939,6958,7051.3,2514,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10578,11058,11179,11021,11123,10980,11194,11101,11064,11394,11084,11119.8,2515,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76350,77349,76910,77637,77637,77264,76956,77191,77438,77373,77055,77281.0,2516,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3371,4157,4163,4155,4163,4208,4209,4149,4210,4150,4125,4168.9,2517,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6223,6882,7146,7166,6722,7117,6699,6715,6752,6807,6716,6872.2,2518,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3301,3599,4112,4089,3576,4138,3601,3608,3567,3595,3606,3749.1,2519,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7186,7670,8997,8151,7690,8182,7544,7639,7576,7678,7700,7882.7,2520,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3187,3457,4051,4050,3437,4057,3384,3440,3397,3465,3577,3631.5,2521,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3312,3534,4178,4080,3527,4103,3647,3528,3643,3534,3679,3745.3,2522,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4426,4909,5568,5485,4959,5523,4761,4911,4737,4936,4950,5073.9,2523,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6250,6945,7357,7437,6966,7415,6935,6938,6964,6924,6939,7082.0,2524,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3467,4663,4793,4743,4849,4820,4811,4704,4768,4674,4668,4749.3,2525,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194548,199090,199096,198640,198899,199869,198999,198807,199626,199139,198777,199094.2,2526,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3762,4722,4741,4692,4692,4819,4774,4769,4879,4657,4676,4742.1,2527,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194991,199025,198452,198908,198471,198538,198583,198775,198891,198879,198465,198698.7,2528,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3380,4242,4286,4201,4249,4317,4312,4229,4266,4214,4219,4253.5,2529,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188849,189786,190043,190363,189755,189835,190014,190519,189784,189652,189675,189942.6,2530,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3418,4241,4156,4221,4130,4129,4167,4137,4172,4205,4083,4164.1,2531,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6099,6749,7216,7175,6770,7182,6774,6716,6790,6770,6722,6886.4,2532,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3305,3639,4108,4088,3611,4158,3633,3609,3605,3643,3623,3771.7,2533,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6832,7711,8150,8188,7680,8161,7608,7720,7640,7720,7663,7824.1,2534,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3297,3444,4106,4030,3417,4023,3395,3428,3393,3454,3433,3612.3,2535,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3316,3632,4097,4160,3536,4133,3584,3548,3660,3514,3507,3737.1,2536,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4352,4876,5526,5438,4887,5500,4701,4872,4717,4893,4944,5035.4,2537,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6122,6834,7271,7206,6818,7254,6852,6839,6767,6878,6877,6959.6,2538,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3312,4607,4693,4668,4692,4683,4728,4721,4700,4643,4620,4675.5,2539,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75957,78686,78625,78517,77531,78113,78972,78182,78330,78451,78372,78377.9,2540,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76023,77139,77425,77232,77266,77222,77461,77416,77513,77484,77419,77357.7,2541,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,75962,78044,77738,77756,77907,77780,78011,78059,78200,77722,77981,77919.8,2542,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5932,6806,7309,7260,6786,7222,6833,6933,6902,6777,6677,6950.5,2543,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5778,6872,7290,7267,6871,7328,6904,6854,6898,6827,6897,7000.8,2544,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4708,6091,6239,6199,6223,6189,6199,6197,6167,6160,6147,6181.1,2545,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4510,6080,6225,6112,6183,6197,6186,6149,6264,6122,6127,6164.5,2546,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5931,6789,7294,7265,6818,7229,6775,6753,6791,6871,6799,6938.4,2547,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5930,6966,7380,7327,6941,7442,6922,6968,6922,6995,6937,7080.0,2548,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",11081,11559,11606,11817,11547,11846,11634,11711,11598,11672,11721,11671.1,2549,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3273,4136,4158,4102,4119,4084,4255,4298,4153,4135,4097,4153.7,2550,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6137,6890,7287,7265,6864,7310,6924,6847,6958,6879,6860,7008.4,2551,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5449,5548,5531,5575,5533,5521,5585,5565,5641,5653,5567,5571.9,2552,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5939,6853,7304,7328,6937,7310,6858,6903,6821,6934,6949,7019.7,2553,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10270,11055,10907,11005,11042,11060,11131,11202,11089,10955,11200,11064.6,2554,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76607,77822,77731,77669,77692,78060,77720,78053,77694,78076,77858,77837.5,2555,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3304,4133,4155,4136,4182,4141,4155,4154,4183,4145,4136,4152.0,2556,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6070,6791,7309,7329,6830,7232,6860,6845,6870,6774,6855,6969.5,2557,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3291,3585,4100,4113,3646,4141,3601,3582,3592,3608,3547,3751.5,2558,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7078,7696,8184,8139,7710,8142,7602,7703,7631,7721,7725,7825.3,2559,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3193,3432,4051,4050,3458,4085,3385,3433,3392,3448,3455,3618.9,2560,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3299,3561,4180,4168,3581,4160,3708,3588,3669,3566,3587,3776.8,2561,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4466,4963,5503,5536,4923,5541,4734,5007,4719,4915,4917,5075.8,2562,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5962,6976,7271,7316,6801,7295,6948,6854,6997,6848,6884,7019.0,2563,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3368,4628,4700,4666,4732,4631,4684,4669,4740,4653,4602,4670.5,2564,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194353,197599,197665,197237,197277,197341,197558,197295,197500,197240,197298,197401.0,2565,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3740,4715,4798,4695,4808,4692,4819,4788,4756,4717,4678,4746.6,2566,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,194239,199580,199881,199787,199699,199564,199521,199363,199436,199908,199700,199643.9,2567,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3365,4201,4236,4244,4259,4199,4223,4205,4262,4212,4293,4233.4,2568,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,188670,190351,190435,190031,190981,190239,190288,190023,190975,190562,190552,190443.7,2569,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3282,4110,4180,4168,4213,4236,4185,4158,4217,4151,4123,4174.1,2570,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6171,6834,7264,7248,6806,7227,6872,6853,6864,6777,6835,6958.0,2571,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3271,3570,4073,4068,3591,4124,3564,3570,3540,3593,3606,3729.9,2572,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6820,7662,8159,8144,7651,8117,7599,7693,7616,7632,7664,7793.7,2573,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3222,3519,4117,4122,3545,4183,3491,3557,3513,3607,3563,3721.7,2574,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3288,3566,4158,4163,3565,4272,3641,3571,3657,3573,3562,3772.8,2575,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4321,4970,5578,5533,4960,5547,4760,4947,4742,4975,4947,5095.9,2576,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6260,6788,7239,7212,6842,7371,6782,6776,6802,6812,6809,6943.3,2577,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3362,4612,4677,4711,4676,4664,4767,4680,4664,4681,4598,4673.0,2578,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76271,77029,77632,77214,77202,77536,77264,77463,77359,77368,77269,77333.6,2579,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76517,77759,77740,77307,77946,77512,77534,77319,76958,77790,77862,77572.7,2580,1370
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76406,77680,77591,77540,77287,77264,77508,77661,77302,77321,77429,77458.3,2581,1370
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5916,6902,7315,7206,6851,7267,6840,6857,6913,6891,6828,6987.0,2582,1362
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5850,6686,7154,7133,6714,7135,6790,6768,6754,6714,6712,6856.0,2583,1362
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4705,6009,6153,6256,6175,6198,6225,6182,6185,6153,6095,6163.1,2584,1375
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<c10::complex<float>, c10::complex<float>, c10::complex<float>, binary_internal::MulFunctor<c10::complex<float>>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4525,6169,6174,6115,6145,6110,6192,6196,6158,6103,6052,6141.4,2585,1375
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5890,6983,7318,7284,6890,7299,6876,6864,6897,6896,6866,7017.3,2586,1368
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5849,6869,7313,7301,6858,7317,6824,6901,6868,6850,6901,7000.2,2587,1368
"std::enable_if<T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 1, 1, 1, 0, 7, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10966,11603,11738,11816,11755,12158,11592,11732,11797,11656,11841,11768.8,2588,1379
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3263,4121,4151,4106,4145,4146,4134,4130,4171,4155,4096,4135.5,2589,1380
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6081,6871,7319,7278,6842,7324,6903,6837,6926,6854,6838,6999.2,2590,1362
"void <unnamed>::softmax_warp_forward<float, float, float, 9, 0, 0>(T2 *, const T1 *, int, int, int, const bool *, int, bool)",5487,5529,5718,5558,5535,5569,5573,5559,5512,5571,5592,5571.6,2591,1382
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5955,6975,7467,7384,6967,7385,6954,7002,6958,6873,6968,7093.3,2592,1368
"std::enable_if<!T7, void>::type internal::kernel<int, int, __half, __half, __half, float, 0, 1, 0, 0, 6, 0, cublasGemvParams<cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<const __half>, cublasGemvTensorStridedBatched<__half>, float>>(T13)",10385,11111,10915,11045,11158,11055,10939,11184,11075,10887,10988,11035.7,2593,1384
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,76826,77238,77286,77112,77285,77192,77219,76972,77357,77195,77047,77190.3,2594,1370
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3308,4094,4108,4132,4134,4100,4144,4209,4171,4098,4080,4127.0,2595,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6183,6704,7176,7173,6774,7163,6746,6715,6828,6704,6693,6867.6,2596,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3285,3574,4073,4044,3694,4108,3554,3606,3772,3570,3566,3756.1,2597,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",7151,7771,8181,8178,7726,8154,7631,7695,7636,7779,7740,7849.1,2598,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3211,3511,4084,4111,3487,4316,3427,3488,3434,3501,3475,3683.4,2599,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3355,3633,4232,4196,3625,4188,3700,3622,3859,3615,3668,3833.8,2600,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4478,4928,5507,5504,4939,5553,4692,4954,4771,4909,4940,5069.7,2601,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",5951,6858,7282,7309,6866,7295,6815,6856,6810,6762,6864,6971.7,2602,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3447,4644,4706,4750,4704,4714,4713,4686,4720,4625,4630,4689.2,2603,1369
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,195234,198028,198623,199236,198299,198645,198147,198417,198947,198630,198440,198541.2,2604,1395
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3713,4703,4744,4670,4746,4619,4706,4736,4827,4695,4675,4712.1,2605,1396
ampere_fp16_s16816gemm_fp16_64x64_ldg8_f2f_stages_64x5_tn,193797,198375,198927,198425,198353,199362,198761,198687,198605,198312,198651,198645.8,2606,1395
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3384,4309,4310,4225,4234,4278,4225,4259,4265,4194,4202,4250.1,2607,1369
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_tn,187577,189426,189181,189844,189547,189489,189444,189444,189338,189251,189306,189427.0,2608,1399
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<c10::Half>, detail::Array<char *, 3>>(int, T2, T3)",3357,4149,4189,4184,4184,4134,4201,4176,4220,4152,4147,4173.6,2609,1386
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6119,6766,7149,7199,6857,7260,6808,6748,6803,6739,6726,6905.5,2610,1362
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3255,3595,4076,4092,3601,4114,3615,3600,3581,3586,3651,3751.1,2611,1363
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float>, unsigned int, float, 4>>(T3)",6834,7710,8230,8136,7696,8167,7610,7711,7615,7700,7661,7823.6,2612,1364
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, detail::Array<char *, 2>>(int, T2, T3)",3224,3579,4124,4128,3552,4166,3507,3560,3486,3563,3595,3726.0,2613,8
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3397,3571,4176,4167,3585,4174,3661,3586,3658,3573,3557,3770.8,2614,9
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4342,4927,5481,5453,4927,5501,4713,4879,4721,4942,4942,5048.6,2615,1367
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 20)]::operator ()() const::[lambda(c10::Half) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6159,6840,7234,7222,6781,7232,6790,6795,6764,6805,6770,6923.3,2616,1368
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<c10::Half, c10::Half, c10::Half, binary_internal::MulFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",3336,4612,4675,4713,4728,4665,4698,4654,4674,4717,4677,4681.3,2617,1369
void cutlass::Kernel<cutlass_80_tensorop_f16_s16816gemm_relu_f16_256x64_32x4_tn_align8>(T1::Params),530974,535333,534240,534443,534548,537108,534943,535277,535426,534499,536488,535230.5,2618,2618
"void splitKreduce_kernel<32, 16, int, __half, __half, float, __half, 1, 0, 0>(cublasSplitKParams<T6>, const T4 *, const T5 *, T5 *, const T6 *, const T6 *, const T7 *, const T4 *, T7 *, void *, long, T6 *, int *)",9375,10007,9967,10059,9984,10044,10511,9920,10069,9933,10019,10051.3,2619,2619
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",6759,6887,7297,7286,6988,7290,6897,6837,6873,6825,6847,7002.7,2620,1362
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3688,4294,4450,4292,4313,4292,4330,4301,4363,4315,4247,4319.7,2621,1327
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, T2 *, int)",34663,35057,35258,35719,35131,35325,35346,35194,36240,36624,35520,35541.4,2622,1328
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, cuda::IntDivider<unsigned int>)",3453,4239,4239,4227,4265,4209,4309,4241,4277,4245,4172,4242.3,2623,1329
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, int>(T4 *, const T3 *, T4, int, int)",6619,7451,7579,7477,7602,7555,7511,7526,7549,7497,7518,7526.5,2624,1330
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, int>(T2 *)",3658,4353,4426,4425,4411,4442,4501,4399,4424,4380,4371,4413.2,2625,1331
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",19876,20580,20806,20751,20821,20659,20654,20907,20514,20698,20579,20696.9,2626,1332
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",18705,20444,20328,20807,20507,20473,20712,20712,20647,20476,20722,20582.8,2627,1332
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",18635,20625,20364,20521,20533,20454,20444,20429,20515,20440,20519,20484.4,2628,1332
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cub::OpaqueType<8>, int>::Policy800, 1, float, cub::OpaqueType<8>, int, int>(T6 *, T6 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T5, int, int)",17805,19457,19734,19607,19525,19644,19476,19511,19898,19754,19419,19602.5,2629,1332
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",2797,3924,3973,3963,3987,3939,4011,3992,3991,3943,3972,3969.5,2630,1336
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float>::Policy600, float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, int>(T2, T3, T4, int, T5, T6, T7)",6781,7838,7888,7771,7711,7853,7978,7865,7774,8002,7713,7839.3,2631,1337
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, detail::Array<char *, 3>>(int, T2, T3)",3960,4720,4807,4816,4795,4785,4828,4760,4927,4752,4710,4790.0,2632,1338
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3627,4407,4532,4472,4450,4381,4623,4427,4459,4432,4394,4457.7,2633,1339
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::masked_fill_kernel<bool>(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 14)]::operator ()() const::[lambda(float, bool) (instance 1)], detail::Array<char *, 3>>(int, T2, T3)",4138,4758,4745,4788,4749,4784,4808,4745,4809,4805,4777,4776.8,2634,1340
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4>>(T3)",15033,15709,15727,15628,16048,15629,15637,15741,15711,15657,15629,15711.6,2635,1341
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl<native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",5416,6168,6233,6200,6194,6178,6226,6162,6209,6164,6090,6182.4,2636,1342
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4>>(T3)",15308,16357,16216,16259,16322,16295,16381,16406,16506,16431,16149,16332.2,2637,1343
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3287,4766,4838,4801,4860,4805,4883,4814,4812,4891,4720,4819.0,2638,1339
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4>>(T3)",15092,16135,16801,16254,16224,16372,16391,16221,16482,16147,16215,16324.2,2639,1345
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], detail::Array<char *, 2>>(int, T2, T3)",3264,4783,4831,4842,4839,4921,4828,4813,4894,4830,4780,4836.1,2640,1339
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, detail::Array<char *, 3>>(int, T2, T3)",3395,4715,4825,4740,4810,4766,4869,4775,4787,4746,4738,4777.1,2641,1347
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4>>(T3)",14648,15910,16006,16068,16024,16192,16037,15915,16021,16095,15862,16013.0,2642,1341
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, detail::Array<char *, 2>>(int, T2, T3)",3256,4818,4740,4772,4742,4763,4787,4734,4760,4727,4729,4757.2,2643,1349
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(long) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T3, T4, T5, T6)",3987,5203,5316,5277,5280,5307,5320,5243,5266,5248,5213,5267.3,2644,1350
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4>>(T3)",6043,6471,6535,6560,6531,6557,6554,6515,6510,6512,6500,6524.5,2645,1351
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, 4, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, T5)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, 4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, 4, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, T5)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(int, at::PhiloxCudaState, T3, T4)",4443,5075,5105,5108,5101,5093,5094,5043,5217,5069,5073,5097.8,2646,1352
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, detail::Array<char *, 3>>(int, T2, T3)",4839,5328,5364,5411,5340,5342,5354,5421,5380,5340,5425,5370.5,2647,1353
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4>>(T3)",22549,23116,22879,22616,23327,22887,22770,22975,22983,23404,22774,22973.1,2648,1354
"void native::_scatter_gather_elementwise_kernel<128, 4, void native::_cuda_scatter_gather_internal_kernel<0, native::OpaqueType<8>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",4738,5267,5345,5323,5347,5311,5348,5318,5296,5291,5303,5314.9,2649,1355
"void native::unrolled_elementwise_kernel<native::<unnamed>::where_kernel_impl(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 8)]::operator ()() const::[lambda(bool, long, long) (instance 1)], detail::Array<char *, 4>, TrivialOffsetCalculator<3, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T3, T4, T5, T6)",3405,4190,4224,4250,4255,4205,4274,4216,4230,4220,4168,4223.2,2650,2650
"void native::unrolled_elementwise_kernel<native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], detail::Array<char *, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T3, T4, T5, T6)",3256,4066,4097,4150,4089,4085,4089,4109,4078,4120,4027,4091.0,2651,2651
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, detail::Array<char *, 2>>(int, T2, T3)",3457,3637,4193,4177,3655,4205,3706,3697,3683,3642,3666,3826.1,2652,1
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, detail::Array<char *, 3>>(int, T2, T3)",3414,4208,4289,4433,4277,4390,4275,4228,4348,4294,4202,4294.4,2653,1347
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, detail::Array<char *, 3>>(int, T2, T3)",3417,4184,4217,4191,4225,4190,4198,4204,4219,4185,4172,4198.5,2654,1360
